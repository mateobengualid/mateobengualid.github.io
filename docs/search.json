[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Closing remarks",
    "section": "",
    "text": "There’s a lot left! This work did enough to present the Malliavin Derivative and Clark-Ocone formula, but it did very little else. There are three things that I’ve excluded, this is long as it is.\nFirst of all, Malliavin Derivatives make it simpler to work with stochastic variances. That is, imagine \\(\\sigma\\) being an Ito process. If you don’t have a solution, you need to run a computer program to estimate your process and expected value. It’s more tractable to use the techniques above, rather than simulating and estimating the evolution of \\(N\\).\nSecondly, we can use an integration by parts to flip between a function derivative and the Skorohod integral. In the case of non-anticipatory processes, the formula is easy to compute because it’s just an Ito integral. This makes it, in turn, easier to calculate/estimate derivatives of functions of processes against other processes. For example, the derivative of an insurance payoff for some asset against the price of the asset is called \\(\\Delta\\). Switching to less risky assets to reduce this derivative is called delta-hedging. When this derivative is zero, changes on the asset’s price don’t affect the insurance payoff anymore and the insurance is considered delta-neutral.\nA final point is that Skorohod integrals also work for anticipatory integrals. We haven’t touched those here because they aren’t proper Ito integrals and it was already too much content, but this is also where Malliavin Calculus shines.\n\n\n\nWhat a ride. I’ll be honest, when I started I wasn’t even thinking of making it this far. It took me months to reach a point where I feel comfortable writing this. I hope that you got to learn a bit about Malliavin Calculus, like I did. If you want to continue and prefer a more theoretical treatment, I left links to all interesting sources for pre-work, before Malliavin Calculus, and I guess Nualart, Oksendal or Malliavin himself for the actual topic. For more practical matters, I can’t recommend Alos (2021) enough. It’s way ahead of the rest.\nI’m finally thanking you for reading all of this. I echo Bret Victor when he said that ideas shouldn’t die, and the mere fact that you reached this point proves that this subject can survive another day.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681."
  },
  {
    "objectID": "summary.html#is-there-anything-else",
    "href": "summary.html#is-there-anything-else",
    "title": "Closing remarks",
    "section": "",
    "text": "There’s a lot left! This work did enough to present the Malliavin Derivative and Clark-Ocone formula, but it did very little else. There are three things that I’ve excluded, this is long as it is.\nFirst of all, Malliavin Derivatives make it simpler to work with stochastic variances. That is, imagine \\(\\sigma\\) being an Ito process. If you don’t have a solution, you need to run a computer program to estimate your process and expected value. It’s more tractable to use the techniques above, rather than simulating and estimating the evolution of \\(N\\).\nSecondly, we can use an integration by parts to flip between a function derivative and the Skorohod integral. In the case of non-anticipatory processes, the formula is easy to compute because it’s just an Ito integral. This makes it, in turn, easier to calculate/estimate derivatives of functions of processes against other processes. For example, the derivative of an insurance payoff for some asset against the price of the asset is called \\(\\Delta\\). Switching to less risky assets to reduce this derivative is called delta-hedging. When this derivative is zero, changes on the asset’s price don’t affect the insurance payoff anymore and the insurance is considered delta-neutral.\nA final point is that Skorohod integrals also work for anticipatory integrals. We haven’t touched those here because they aren’t proper Ito integrals and it was already too much content, but this is also where Malliavin Calculus shines."
  },
  {
    "objectID": "summary.html#last-words",
    "href": "summary.html#last-words",
    "title": "Closing remarks",
    "section": "",
    "text": "What a ride. I’ll be honest, when I started I wasn’t even thinking of making it this far. It took me months to reach a point where I feel comfortable writing this. I hope that you got to learn a bit about Malliavin Calculus, like I did. If you want to continue and prefer a more theoretical treatment, I left links to all interesting sources for pre-work, before Malliavin Calculus, and I guess Nualart, Oksendal or Malliavin himself for the actual topic. For more practical matters, I can’t recommend Alos (2021) enough. It’s way ahead of the rest.\nI’m finally thanking you for reading all of this. I echo Bret Victor when he said that ideas shouldn’t die, and the mere fact that you reached this point proves that this subject can survive another day.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681."
  },
  {
    "objectID": "question.html",
    "href": "question.html",
    "title": "The question",
    "section": "",
    "text": "As I mentioned previously, Malliavin Calculus isn’t a topic that can easily relate to everyday things. Most authors I’ve checked don’t detail too much on why an object like it exists, or the Clark-Ocone formula. Instead, they go to the Hormander condition, which is meaningless for our purposes.\nIf Malliavin Calculus is called the extension of calculus of variations to stochastic processes, then the time has come to discuss stochastic processes and martingales.\n\n\nWe can think of stochastic processes as a sequence of random variables that are indexed by time. I’ll start with a very simple case, the one-dimensional random walk (also known as the drunkard’s walk):\n\\[\n\\begin{aligned}\n\\mathbb{P}(\\{&X_i=+1\\})=0.5 \\\\\n\\mathbb{P}(\\{&X_i=-1\\})=0.5 \\\\\n&X_0=0 \\\\\n&Z_n=\\sum^{n}_{i=1}X_i \\\\\n\\end{aligned}\n\\]\nThis is very simple: at time \\(i\\), after \\(\\Delta t\\) has passed, the drunkard take a step \\(X_i\\), which can be either up or down the street with equal probability. The position \\(Z\\) at \\(t\\) is simply the result of all the steps the drunkard has taken before. As it stands, each movement “up” can be considered a “success”, so this sum follows a binomial distribution centered at \\(0\\).\nLet’s consider something else: let the random walk take more frequent and shorter steps. In the language of the symbols above, \\(\\Delta t\\) and \\(X_i\\) are made smaller. As the steps become infinitesimals, the process becomes continuous. This is how a path may look like when \\(\\Delta t=0.1,\\,0.01,\\,0.001\\):\n\n\nCode\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Left\nh &lt;- 0.01\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nCode\n# Middle\nh &lt;- 0.001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nCode\n# Right\nh &lt;- 0.0001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nA one-dimensional random walk from \\(0\\) to \\(t\\), in a similar fashion to the Central Limit Theorem, will converge to a normal variable:\n\\[\nZ_t\\sim \\mathcal{N}(\\mu=0,\\sigma^2=t)\n\\]\nThese continuous-time stochastic processes are called Brownian motions or Wiener processes. They are denoted as \\(B_t\\) or \\(W_t\\) and fulfill a set of conditions:\n\n\\(B_0 = 0\\)\nIncrements are independent, that is, \\((B_{t+s} - B_t)\\) doesn’t depend on earlier values \\(B_r, \\, r &lt; t\\)\nIncrements are Gaussian, that is, \\((B_{t+s} - B_t) \\sim \\mathcal{N}(\\mu=0,\\sigma^2=s)\\)\n\\(B_t\\) is continuous at \\(t\\). A bit circular, I know.\n\nThere’s a catch, though. Even though they are continuous, these functions aren’t differentiable. You kind of see it from the previous path graphs, with how jagged they become as the indices, or steps, shrink. It also makes sense if you think about the way we constructed the process: when you are at a point in time \\(t\\), you don’t know from where you randomly came. Did you arrive from a smaller or bigger value at \\(t-\\Delta t\\)? There’s no way to make sense of \\(\\frac{\\partial Z_t}{\\partial t}\\).\n\n\nThe drunkard’s walk is a very simple case of a stochastic process. What about more complicated random variables or functions of these variables?\nWe start from a simple substitution: we can’t do \\(\\frac{\\partial Z_t}{\\partial t}\\) but we “can” pass the \\(dt\\) as a multiplication, like we do with total derivatives, and refer to just \\(dZ_t\\). In general, we would like to express a minuscule change in the random variable being composed of something that changes very little in time and a little “noise”. In short, something like this:\n\\[\ndZ_t = a(.)dt + b(.)dB_t\n\\]\nFor starters, we can assume the functions \\(a\\) and \\(b\\) above are only functions of time. We then integrate over time and reach the definition of an Ito process:\n\\[\n\\begin{aligned}\n\\int_0^tdZ_t &= Z_t - Z_0 = \\int_0^t\\mu_sds + \\int_0^t\\sigma_sdB_s \\\\\n\\end{aligned}\n\\]\nThis representation is nice because the random variable \\(Z_t\\) has a mean that depends on something that changes along time, and has a variance tied to the noise. Having said that, we need a way to think about \\(dB_t\\) . For that, we can assume something simple, that instead of a continuum of \\(dB_t\\), there’s a list of discrete \\(t_i\\) and discrete increments \\(\\Delta B_{t_i}\\), so now we deal with:\n\\[\n\\sigma_{t_{i}} * (B_{t_i}-B_{t_{i-1}})\n\\]\nWe can calculate the above because that difference of Brownian motions can be transformed into a normal distribution that we can manipulate. To show how this help us, we can do the following calculation and confirm that the expected value of \\(Z\\) only depends on the first term:\n\\[\n\\mathbb{E}\\left[ \\int_0^t \\sigma_s \\, dB_s\\right]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[B_{t_{i}}-B_{t_{i-1}}\\right ]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[\\mathcal{N}(0,t_{i}-t_{i-1})\\right ]=\n0\n\\]\nUsing this approach, we can show that Ito processes satisfy:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[X_t \\right]&=\\int_0^t\\mu_s\\,ds\\\\\n\\mathbb{Var}\\left[X_t \\right]&=\\int_0^t\\sigma_s^2\\,ds\\\\\n\\end{aligned}\n\\]\nOther ways we can deal with this \\(B_t\\) is with Ito’s isometry, which allows you to exchange the \\(dB_t\\) into a more workable \\(dt\\):\n\\[\n\\mathbb{E}\\left[ \\left(\\int_0^t X_s \\, dB_s\\right)^2\\right]=\\mathbb{E} \\left[ \\int_0^t X_s^2\\,ds\\right ]\n\\]\nWith these tools, we can calculate a mean and a variance for every point in time in a process. But there’s an even more powerful tool in our arsenal: Ito’s lemma, or Ito’s formula. In order to present this, we start with an Ito process for a random variable, say \\(X_t\\):\n\\[\n\\begin{aligned}\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_t \\\\\nX_t &= X_0 + \\int_0^t\\mu_s\\,ds + \\int_0^t\\sigma_s\\,dB_s \\\\\n\\end{aligned}\n\\]\nNow, we want something more involved. Something like:\n\\[\n\\begin{aligned}\nY_t&=f(t,X_t) \\\\\\\\\ndY_t &= a(t,X_t)\\,dt + b(t,X_t)\\,dB_t \\\\\\\\\nwith&\\\\\\\\\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_s \\\\\n\\end{aligned}\n\\]\nNotice that we can’t just do the typical chain rule from calculus. That is, we still can’t do something like:\n\\[\n\\frac{\\partial Y_t}{\\partial t}=\\frac{\\partial Y_t}{\\partial X_t}\\frac{\\partial X_t}{\\partial t}\n\\]\nBut we can prove that there’s an alternative chain rule we can apply, called Ito’s lemma:\n\\[\n\\begin{aligned}\ndf(t,X_t) &=\\frac{\\partial f}{\\partial t}\\,dt + \\mu_t \\frac{\\partial f}{\\partial x}\\,dt+\\sigma_t \\frac{\\partial f}{\\partial x}\\,dB_t + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\,dt\\\\\ndf(t,X_t) &=\\underbrace{\\left(\\frac{\\partial f}{\\partial t} + \\mu_t \\frac{\\partial f}{\\partial x} + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\right)}_{a(t,X_t)}dt+ \\underbrace{\\left(\\sigma_t \\frac{\\partial f}{\\partial x}\\right)}_{b(t,X_t)}dB_t\\\\\n\\end{aligned}\n\\]\nThe first equation almost looks like a Taylor expansion up to the 2nd derivative, and in informal proofs that’s what’s going on. The second equation shows the explicit expressions for the \\(a(t,X_t)\\) and \\(b(t,X_t)\\) functions we mentioned before. This is great, because we can still split the “trend” component and the “noise” component for more complicated random processes. It also means that the “trend” is affected by how strong the “noise” is. Finally, notice that a non-random function with \\(\\sigma_t=0\\) reverts to a classical total derivative and chain rule.\n\n\n\nSome stochastic processes present additional properties. One of those “some” are the martingales. They are either discrete or continuous-time processes that satisfy:\n\n\\(\\mathbb{E}[|X_t|]&lt;\\infty, \\forall t \\ge 0\\) . This means that the process always has a finite value.\n\\(\\mathbb{E}[X_{t+s}|X_t]=X_t, \\forall t \\le s\\). This means that the expected value for future realizations of the process is whatever value you have right now.\n\nThe drunkard’s walk is an example of a martingale: at any time, it’s equally likely it will go up or down, so the expected value is wherever you are at that point in time. Brownian motions are also martingales: increments follow a normal distribution, so the expected value of the increment is \\(0\\). Other examples of typical martingales are betting black or red at the roulette, or a stock price in the short term.\nThere’s a result called the Martingale Representation Theorem, which states that any random variable \\(X\\) can be written in terms of another process \\(C\\), with values known in advance, like so:\n\\[\nX = \\mathbb{E}\\left[X\\right] + \\int_0^\\infty C_s\\,dB_s\n\\]\nThis is valuable for finance people because it means that any investment strategy (which is a random process) can be replicated with a different investment strategy (another process), but with lower volatility (and probably higher initial cost!). This theorem is less valuable because it doesn’t give any means to calculate it, we can’t apply a derivative and try to extract that \\(dB_t\\)\nA second representation, from Rogers and Williams (2000), establishes that martingales can be represented as Ito integrals:\n\\[\nM_t = M_0 + \\int_0^t \\alpha_s\\,dB_s\n\\]\nIn a limited sense, \\(\\alpha_t\\) can be thought as \\(\\frac{\\partial M_t}{\\partial t}\\) because if we integrate it up to \\(t\\) we recover the final point, but it’s not quite what we are looking for.\nAnd it’s always frustrating. We have been trying to find a way to calculate derivatives on these random processes, Brownian motions and martingales, but it’s elusive. And the thing is, we kind of know that is possible. Indeed, let’s go back to our first continuous random process, the one-dimensional Wiener process. We managed to reach the point were we can say that \\(W_t\\) had a normal distribution. So, nothing prevents us from taking a derivative over that, right?\n\\[\n\\begin{aligned}\nW_t& \\sim \\mathcal{N}(0,t) \\\\\nW(x, t)& = \\frac{1}{\\sqrt{2 \\pi t}} e^{-x^2/(2t)} \\\\\n\\frac{\\partial W}{\\partial t}& = \\frac{e^{-x^2/(2t)}\\,t^{-5/2} \\left(x^2-t\\right)}{2\\sqrt{2 \\pi }}\n\\end{aligned}\n\\]\nAnd there we have it. Ugly as it may be, we have constructed a derivative for how the density of these random variables evolve with time, although we don’t know if it’s even useful. Let’s plot it both the density and the derivative in 3D.\n\n\nCode\noptions(rgl.useNULL=TRUE)\nrgl::setupKnitr(autoprint = TRUE)\nh = 200\nWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)/sqrt(2*pi*t))\n  }\n}\ndWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)*t^(-5/2)*(x^2-t)/sqrt(8*pi))\n  }\n}\nWt &lt;- Vectorize(Wt)\ndWt &lt;- Vectorize(dWt)\n\ntimes &lt;- seq(from=0, to=5, length.out=h)\nxes &lt;- seq(from=-5, to=5, length.out=h)\n\nW &lt;- outer(xes, times, Wt)\n# persp(xes, times, W, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\n# open3d(windowRect=c(50,50,800,800))\npalette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\")) \ncol.table &lt;- palette(256)\ncol.ind &lt;- cut(W, 256)\npersp3d(x=xes, y=times, z=W, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Time\", zlab=\"Density\")\n\n\n\n\n\n\n\nCode\n# rglwidget()\n\ndW &lt;- outer(xes, times, dWt)\n# persp(xes, times, dW, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\ncol.ind &lt;- cut(dW, 256)\npersp3d(x=xes, y=times, z=dW, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Time\", zlab=\"Derivative of density\")\n\n\n\n\n\n\nCode\n# rglwidget()\n\n\n\n\n\n\nAt this point, we have seen enough. We know what we want: a way to calculate derivatives over random variables and Wiener processes “in a certain sense” that’s useful. That’s what Malliavin calculus is set to do.\n\n\n\n\n\nRogers, L. C. G., and David Williams. 2000. Diffusions, Markov Processes and Martingales. 2nd ed. Vol. 2. Cambridge Mathematical Library. Cambridge University Press. https://doi.org/10.1017/CBO9780511805141."
  },
  {
    "objectID": "question.html#stochastic-processes",
    "href": "question.html#stochastic-processes",
    "title": "The question",
    "section": "",
    "text": "We can think of stochastic processes as a sequence of random variables that are indexed by time. I’ll start with a very simple case, the one-dimensional random walk (also known as the drunkard’s walk):\n\\[\n\\begin{aligned}\n\\mathbb{P}(\\{&X_i=+1\\})=0.5 \\\\\n\\mathbb{P}(\\{&X_i=-1\\})=0.5 \\\\\n&X_0=0 \\\\\n&Z_n=\\sum^{n}_{i=1}X_i \\\\\n\\end{aligned}\n\\]\nThis is very simple: at time \\(i\\), after \\(\\Delta t\\) has passed, the drunkard take a step \\(X_i\\), which can be either up or down the street with equal probability. The position \\(Z\\) at \\(t\\) is simply the result of all the steps the drunkard has taken before. As it stands, each movement “up” can be considered a “success”, so this sum follows a binomial distribution centered at \\(0\\).\nLet’s consider something else: let the random walk take more frequent and shorter steps. In the language of the symbols above, \\(\\Delta t\\) and \\(X_i\\) are made smaller. As the steps become infinitesimals, the process becomes continuous. This is how a path may look like when \\(\\Delta t=0.1,\\,0.01,\\,0.001\\):\n\n\nCode\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Left\nh &lt;- 0.01\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nCode\n# Middle\nh &lt;- 0.001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nCode\n# Right\nh &lt;- 0.0001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Time') +\n  ylab('Z')\n\n\n\n\n\nA one-dimensional random walk from \\(0\\) to \\(t\\), in a similar fashion to the Central Limit Theorem, will converge to a normal variable:\n\\[\nZ_t\\sim \\mathcal{N}(\\mu=0,\\sigma^2=t)\n\\]\nThese continuous-time stochastic processes are called Brownian motions or Wiener processes. They are denoted as \\(B_t\\) or \\(W_t\\) and fulfill a set of conditions:\n\n\\(B_0 = 0\\)\nIncrements are independent, that is, \\((B_{t+s} - B_t)\\) doesn’t depend on earlier values \\(B_r, \\, r &lt; t\\)\nIncrements are Gaussian, that is, \\((B_{t+s} - B_t) \\sim \\mathcal{N}(\\mu=0,\\sigma^2=s)\\)\n\\(B_t\\) is continuous at \\(t\\). A bit circular, I know.\n\nThere’s a catch, though. Even though they are continuous, these functions aren’t differentiable. You kind of see it from the previous path graphs, with how jagged they become as the indices, or steps, shrink. It also makes sense if you think about the way we constructed the process: when you are at a point in time \\(t\\), you don’t know from where you randomly came. Did you arrive from a smaller or bigger value at \\(t-\\Delta t\\)? There’s no way to make sense of \\(\\frac{\\partial Z_t}{\\partial t}\\).\n\n\nThe drunkard’s walk is a very simple case of a stochastic process. What about more complicated random variables or functions of these variables?\nWe start from a simple substitution: we can’t do \\(\\frac{\\partial Z_t}{\\partial t}\\) but we “can” pass the \\(dt\\) as a multiplication, like we do with total derivatives, and refer to just \\(dZ_t\\). In general, we would like to express a minuscule change in the random variable being composed of something that changes very little in time and a little “noise”. In short, something like this:\n\\[\ndZ_t = a(.)dt + b(.)dB_t\n\\]\nFor starters, we can assume the functions \\(a\\) and \\(b\\) above are only functions of time. We then integrate over time and reach the definition of an Ito process:\n\\[\n\\begin{aligned}\n\\int_0^tdZ_t &= Z_t - Z_0 = \\int_0^t\\mu_sds + \\int_0^t\\sigma_sdB_s \\\\\n\\end{aligned}\n\\]\nThis representation is nice because the random variable \\(Z_t\\) has a mean that depends on something that changes along time, and has a variance tied to the noise. Having said that, we need a way to think about \\(dB_t\\) . For that, we can assume something simple, that instead of a continuum of \\(dB_t\\), there’s a list of discrete \\(t_i\\) and discrete increments \\(\\Delta B_{t_i}\\), so now we deal with:\n\\[\n\\sigma_{t_{i}} * (B_{t_i}-B_{t_{i-1}})\n\\]\nWe can calculate the above because that difference of Brownian motions can be transformed into a normal distribution that we can manipulate. To show how this help us, we can do the following calculation and confirm that the expected value of \\(Z\\) only depends on the first term:\n\\[\n\\mathbb{E}\\left[ \\int_0^t \\sigma_s \\, dB_s\\right]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[B_{t_{i}}-B_{t_{i-1}}\\right ]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[\\mathcal{N}(0,t_{i}-t_{i-1})\\right ]=\n0\n\\]\nUsing this approach, we can show that Ito processes satisfy:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[X_t \\right]&=\\int_0^t\\mu_s\\,ds\\\\\n\\mathbb{Var}\\left[X_t \\right]&=\\int_0^t\\sigma_s^2\\,ds\\\\\n\\end{aligned}\n\\]\nOther ways we can deal with this \\(B_t\\) is with Ito’s isometry, which allows you to exchange the \\(dB_t\\) into a more workable \\(dt\\):\n\\[\n\\mathbb{E}\\left[ \\left(\\int_0^t X_s \\, dB_s\\right)^2\\right]=\\mathbb{E} \\left[ \\int_0^t X_s^2\\,ds\\right ]\n\\]\nWith these tools, we can calculate a mean and a variance for every point in time in a process. But there’s an even more powerful tool in our arsenal: Ito’s lemma, or Ito’s formula. In order to present this, we start with an Ito process for a random variable, say \\(X_t\\):\n\\[\n\\begin{aligned}\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_t \\\\\nX_t &= X_0 + \\int_0^t\\mu_s\\,ds + \\int_0^t\\sigma_s\\,dB_s \\\\\n\\end{aligned}\n\\]\nNow, we want something more involved. Something like:\n\\[\n\\begin{aligned}\nY_t&=f(t,X_t) \\\\\\\\\ndY_t &= a(t,X_t)\\,dt + b(t,X_t)\\,dB_t \\\\\\\\\nwith&\\\\\\\\\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_s \\\\\n\\end{aligned}\n\\]\nNotice that we can’t just do the typical chain rule from calculus. That is, we still can’t do something like:\n\\[\n\\frac{\\partial Y_t}{\\partial t}=\\frac{\\partial Y_t}{\\partial X_t}\\frac{\\partial X_t}{\\partial t}\n\\]\nBut we can prove that there’s an alternative chain rule we can apply, called Ito’s lemma:\n\\[\n\\begin{aligned}\ndf(t,X_t) &=\\frac{\\partial f}{\\partial t}\\,dt + \\mu_t \\frac{\\partial f}{\\partial x}\\,dt+\\sigma_t \\frac{\\partial f}{\\partial x}\\,dB_t + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\,dt\\\\\ndf(t,X_t) &=\\underbrace{\\left(\\frac{\\partial f}{\\partial t} + \\mu_t \\frac{\\partial f}{\\partial x} + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\right)}_{a(t,X_t)}dt+ \\underbrace{\\left(\\sigma_t \\frac{\\partial f}{\\partial x}\\right)}_{b(t,X_t)}dB_t\\\\\n\\end{aligned}\n\\]\nThe first equation almost looks like a Taylor expansion up to the 2nd derivative, and in informal proofs that’s what’s going on. The second equation shows the explicit expressions for the \\(a(t,X_t)\\) and \\(b(t,X_t)\\) functions we mentioned before. This is great, because we can still split the “trend” component and the “noise” component for more complicated random processes. It also means that the “trend” is affected by how strong the “noise” is. Finally, notice that a non-random function with \\(\\sigma_t=0\\) reverts to a classical total derivative and chain rule.\n\n\n\nSome stochastic processes present additional properties. One of those “some” are the martingales. They are either discrete or continuous-time processes that satisfy:\n\n\\(\\mathbb{E}[|X_t|]&lt;\\infty, \\forall t \\ge 0\\) . This means that the process always has a finite value.\n\\(\\mathbb{E}[X_{t+s}|X_t]=X_t, \\forall t \\le s\\). This means that the expected value for future realizations of the process is whatever value you have right now.\n\nThe drunkard’s walk is an example of a martingale: at any time, it’s equally likely it will go up or down, so the expected value is wherever you are at that point in time. Brownian motions are also martingales: increments follow a normal distribution, so the expected value of the increment is \\(0\\). Other examples of typical martingales are betting black or red at the roulette, or a stock price in the short term.\nThere’s a result called the Martingale Representation Theorem, which states that any random variable \\(X\\) can be written in terms of another process \\(C\\), with values known in advance, like so:\n\\[\nX = \\mathbb{E}\\left[X\\right] + \\int_0^\\infty C_s\\,dB_s\n\\]\nThis is valuable for finance people because it means that any investment strategy (which is a random process) can be replicated with a different investment strategy (another process), but with lower volatility (and probably higher initial cost!). This theorem is less valuable because it doesn’t give any means to calculate it, we can’t apply a derivative and try to extract that \\(dB_t\\)\nA second representation, from Rogers and Williams (2000), establishes that martingales can be represented as Ito integrals:\n\\[\nM_t = M_0 + \\int_0^t \\alpha_s\\,dB_s\n\\]\nIn a limited sense, \\(\\alpha_t\\) can be thought as \\(\\frac{\\partial M_t}{\\partial t}\\) because if we integrate it up to \\(t\\) we recover the final point, but it’s not quite what we are looking for.\nAnd it’s always frustrating. We have been trying to find a way to calculate derivatives on these random processes, Brownian motions and martingales, but it’s elusive. And the thing is, we kind of know that is possible. Indeed, let’s go back to our first continuous random process, the one-dimensional Wiener process. We managed to reach the point were we can say that \\(W_t\\) had a normal distribution. So, nothing prevents us from taking a derivative over that, right?\n\\[\n\\begin{aligned}\nW_t& \\sim \\mathcal{N}(0,t) \\\\\nW(x, t)& = \\frac{1}{\\sqrt{2 \\pi t}} e^{-x^2/(2t)} \\\\\n\\frac{\\partial W}{\\partial t}& = \\frac{e^{-x^2/(2t)}\\,t^{-5/2} \\left(x^2-t\\right)}{2\\sqrt{2 \\pi }}\n\\end{aligned}\n\\]\nAnd there we have it. Ugly as it may be, we have constructed a derivative for how the density of these random variables evolve with time, although we don’t know if it’s even useful. Let’s plot it both the density and the derivative in 3D.\n\n\nCode\noptions(rgl.useNULL=TRUE)\nrgl::setupKnitr(autoprint = TRUE)\nh = 200\nWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)/sqrt(2*pi*t))\n  }\n}\ndWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)*t^(-5/2)*(x^2-t)/sqrt(8*pi))\n  }\n}\nWt &lt;- Vectorize(Wt)\ndWt &lt;- Vectorize(dWt)\n\ntimes &lt;- seq(from=0, to=5, length.out=h)\nxes &lt;- seq(from=-5, to=5, length.out=h)\n\nW &lt;- outer(xes, times, Wt)\n# persp(xes, times, W, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\n# open3d(windowRect=c(50,50,800,800))\npalette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\")) \ncol.table &lt;- palette(256)\ncol.ind &lt;- cut(W, 256)\npersp3d(x=xes, y=times, z=W, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Time\", zlab=\"Density\")\n\n\n\n\n\n\n\nCode\n# rglwidget()\n\ndW &lt;- outer(xes, times, dWt)\n# persp(xes, times, dW, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\ncol.ind &lt;- cut(dW, 256)\npersp3d(x=xes, y=times, z=dW, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Time\", zlab=\"Derivative of density\")\n\n\n\n\n\n\nCode\n# rglwidget()"
  },
  {
    "objectID": "question.html#conclusion",
    "href": "question.html#conclusion",
    "title": "The question",
    "section": "",
    "text": "At this point, we have seen enough. We know what we want: a way to calculate derivatives over random variables and Wiener processes “in a certain sense” that’s useful. That’s what Malliavin calculus is set to do.\n\n\n\n\n\nRogers, L. C. G., and David Williams. 2000. Diffusions, Markov Processes and Martingales. 2nd ed. Vol. 2. Cambridge Mathematical Library. Cambridge University Press. https://doi.org/10.1017/CBO9780511805141."
  },
  {
    "objectID": "measuretheory.html",
    "href": "measuretheory.html",
    "title": "Measure theory",
    "section": "",
    "text": "After calculus of variations, we need to divert further to a topic somewhat related to integration. Some pieces will be harder to follow otherwise.\n\n\nYou may have grown accustomed to calling “integration” to something like \\(\\int_{a}^{b}fdx\\) , but that’s actually just the Riemann integration. Ok, it “just” powers 99% of all real-life integration, but there are many other specialized integrals that can handle special situations like discontinuities or holes in \\(f\\), such as the Riemann-Stieltjes integral, the Henstock-Kurzweil integral, and the Lebesgue integral. The last one is where we will concentrate the most.\nWe start with a seemingly unrelated problem: the size of a set. Let’s say we have a set of \\(\\mathbb{N}\\) and we want to know how big it is: we may, for example, just count how many elements are there in the set:\n\\[\n\\begin{aligned}\n&\\#\\{\\pi,e,25\\} = 3\\\\\n&\\#\\{\\} = 0 \\\\\n&\\#\\{1,2,3,..\\} = \\infty\n\\end{aligned}\n\\]\nIn a sense, \\(\\#\\) is a function that receives a set with a combination of elements from \\(\\mathbb{N}\\) and outputs a numeric value. In the literature, the elements belong to a set \\(\\Omega\\) and the combinations of those elements belong to a set of sets \\(\\Sigma\\) , also called a sigma-algebra. More formally, \\(\\# : \\Sigma \\to \\mathbb{N}\\).\n\\(\\#\\) is called a measure. Measures are normally referred as \\(\\mu\\), and fulfill roughly two conditions:\n\n\\(\\mu(s) \\ge 0 ,\\, \\forall s \\in \\Sigma\\), that is, they are always positive. This condition can be relaxed, though, into having “signed measures”.\nIf \\(A_1 \\cap A_2 = \\{\\} \\implies {\\mu (A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)}\\). This means that the “size” of a set is the same as the sum of the sizes of its subsets.\n\nThere are many measures, with different properties, that are defined to operate over “measurable sets”, namely the pair \\((\\Omega,\\Sigma)\\). You have already seen the counting measure. The Borel measure, which we will use interchangeably with the Lebesgue measure1, can be defined as:\n\\[\n\\lambda((a,b])=b-a\n\\]\nIf the set is a composition of intervals, it can be split into as many sums as we need, so:\n\\[\n\\lambda([0,2]\\cup(12,20))=\\lambda([0,2])+\\lambda((12,20))=(2-0)+(20-12)=10\n\\]\nIt can also be reasonably extended to multidimensional cases:\n\\[\n\\lambda^2((0,\\pi]\\times(2,4])=\\lambda((0,\\pi])*\\lambda((2,4])=(\\pi-0)*(4-2)=\\pi*2=2\\pi\n\\]\n\n\n\nWe will now do something daring: have you noticed that definite integrals work over an interval (a set) and the result is a number? Yes, an integral is a (signed) measure2. This will require a bit of rethinking of what integrating really means, as well as changing our notation for the integral.\nIn the world we all know, we do Riemann integration, \\(\\int_{a}^{b}fdx\\). This means:\n\n\\(I=\\left[a,b\\right]\\) will select the portion of the function’s domain, \\(\\Omega\\) , to integrate. With the language we have used above, \\(I\\subset \\Omega,\\, I\\in \\Sigma\\)\nWe split \\(I\\) into partitions, typically using a single partition size \\(\\Delta x\\), and come up with a list of values \\(\\left\\{x_0=a, x_1, …, x_n=b\\right\\} \\in I\\)\nFor each partition \\(x_i\\) we evaluate it with \\(f(x_i)\\) to obtain a list of evaluations \\(f_0, f_1, ..., f_n\\)\nWe calculate an approximation of the integral by making each of these values a rectangle of height \\(f_i\\) and predefined width \\(\\Delta x\\), and summing over all rectangles.\nThe integral, if it exists, is the limit of this sum when the partition’s norm tends to zero.\n\nHere’s how it looks like:\n\n\nCode\nlibrary(ggplot2)\nlibrary(broom)\n\nf &lt;- function(x) x^3 - 3*x^2 + x +4\n\n# Define the interval [a, b] for integration\na &lt;- 0\nb &lt;- 3\n\n# Number of rectangles for approximation\nn &lt;- 24\n\n# Generate x values and corresponding function values\nx_values &lt;- seq(a, b, length.out = n+1)\ny_values &lt;- f(x_values)\n\n# Create a data frame for ggplot\ndf &lt;- data.frame(x = x_values, y = y_values)\n\n# Calculate rectangle heights\ndf$rect_heights &lt;- c(0,f(x_values)[2:length(x_values)])\n\n# Calculate total width of the bars to fill the x-axis\ntotal_width &lt;- b - a\n\n# Create a ggplot with rectangles\np &lt;- ggplot(df, aes(x = x, y = rect_heights)) +\n    geom_col(width=(total_width/n), fill = \"skyblue\", color = \"black\", just = 1, alpha=0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Riemann Integration Demonstration\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\nPowerful as it is, this can be improved. For starters, we can only integrate intervals over a real domain, \\(\\Omega =\\mathbb{R}\\) . For functions with many variables, we also need to integrate over many real domains, for example \\(\\int_{x_a}^{x_b}\\int_{y_a}^{y_b}\\int_{z_a}^{z_b}f(x,y,z)\\,dz\\,dy\\,dx\\) .\nNotice that we could get rid of these restrictions if we integrate over the only real line that’s guaranteed to exist: the one of the codomain or image. Kind of like a stack of dishes, for each height we measure the domain that falls under it. This is called Lebesgue integration, it’s written as \\(\\int_{s} f\\, d\\lambda\\) , and it means:\n\n\\(s\\) will select a portion of the function’s domain, \\(\\Omega\\) , to integrate. With the language we have used above, \\(s\\subset \\Omega,\\, s\\in \\Sigma\\)\nWe split the image of the function, \\(f^{-1}\\) into partitions, and we obtain the images \\(f_0,f_1,…,\\infty\\)\nFor each of these partitions, we obtain the set of values of the domain that have a function value at least that height: \\(f^{-1}_t = \\{\\omega \\in s\\, / \\, f(\\omega) &gt; t\\}\\in\\Sigma\\). Notice that these sets should be measurable and that \\(f_{\\infty} = \\{\\}\\), so that the integral is bounded.\nWe calculate an approximation of the integral by making each of these sets a group of “volumes” of predefined height \\(f_t\\) and base \\(\\mu(f^{-1}_t)\\), and summing over all rectangles.\nAdding up all the measured sets, all the slices of heights, will yield a final value, which behaves as a measure\nThe integral, if it exists, is the supremum of all the sum calculations that can be achieved by splitting the image into smaller and smaller partitions\n\nHere’s how this mess looks like:\n\n\nCode\nA &lt;- 1\nB &lt;- -3\nC &lt;- 1\nD &lt;- 4\nf &lt;- function(x) A*x^3 + B*x^2 + C*x + D\ndfdx &lt;- function(x) A*3*x^2 + B*2*x + C\n\n# Define the domain [left, right] for integration\nleft &lt;- 0\nright &lt;- 3\n\n# Number of image partitions\nmax_y &lt;- 7\nn &lt;- 28\ndelta_y &lt;- max_y / n\n\n# Generate x values and corresponding function values\ny_values &lt;- seq(0, max_y, length.out = n + 1)\n\n\nfind_real_roots_of_cubic &lt;- function(A, B, C, D, tolerance = 1e-10) {\n  # Find the roots using polyroot()\n  roots &lt;- polyroot(c(D, C, B, A))\n  \n  # Extract real parts of the roots\n  real_parts &lt;- Re(roots)\n  \n  # Filter out complex roots (where the imaginary part is close to zero)\n  real_roots &lt;- real_parts[abs(Im(roots)) &lt; tolerance]\n  \n  return(real_roots)\n}\n\ncalculate_intervals_for_measure &lt;- function(A, B, C, D, lower_bound, upper_bound) {\n  # Find the real roots \n  roots &lt;- find_real_roots_of_cubic(A, B, C, D)\n  roots &lt;- sort(roots)\n  \n  # The first interval should start on the lower bound if the function is decreasing \n  intervals &lt;- data.frame(a = double(), b = double())\n  current_left &lt;- lower_bound\n  \n  # Then, build every pair of (f' &gt; 0, f' &lt; 0).\n  for (i in (1:length(roots))) {\n    # Stop if you have gone beyond the boundary.\n    if (roots[i] &gt; upper_bound) {\n      break;\n    }\n    \n    if (!is.na(current_left)) {\n      possible_right &lt;- roots[i]\n      if (dfdx(possible_right) &lt; 0) {\n        if (current_left &lt; possible_right) {\n          # Add an interval.\n          intervals[nrow(intervals) + 1,] &lt;- c(current_left, possible_right)\n          current_left &lt;- NA\n        } else {\n          # This is closing an interval to the left of the lower bound. Skip.\n        }\n      } else {\n        # Another increasing left would be the start of an interval to the left of the lower bound\n        # or to the right of the lower bound. So, just keep the maximum.\n        # It could also be a missed root in between, but we will disregard this option.\n        current_left &lt;- max(current_left, possible_right)\n      }\n    } else {\n      possible_left &lt;- roots[i]\n      if (dfdx(possible_left) &gt; 0) {\n        if (possible_left &lt; upper_bound) {\n          # The opening of a new interval. As long as it's not beyond the upper bound, use it.\n          current_left &lt;- possible_left\n        }\n      } else {\n        # A decreasing function, without a left boundary, can be discarded\n      }\n    }\n  }\n    \n  # If there's an open interval after processing, close it at the upper bound.\n  if (!is.na(current_left)) {\n    intervals[nrow(intervals) + 1,] &lt;- c(current_left, upper_bound)\n  }\n  \n  return(intervals)\n}\n\n# Create a data frame for ggplot\nrectangles &lt;- data.frame(\n  xmin = double(),\n  xmax = double(),\n  ymin = double(),\n  ymax = double())\n\n# Calculate all rectangles\nfor(y in y_values) {\n  intervals &lt;- calculate_intervals_for_measure(A, B, C, D - y, left, right)\n  for (i in (1:nrow(intervals))) {\n    interval &lt;- intervals[i,]\n    rectangles[nrow(rectangles) + 1,] &lt;- c(interval[1], interval[2], max(0, y - delta_y), y)\n  }\n}\n\n# Create a ggplot with rectangles\np &lt;- ggplot() +\n    geom_rect(data = rectangles,\n          aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n          fill = \"skyblue\",\n          colour = \"darkgrey\",\n          alpha = 0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Lebesgue Integration Demonstration\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\n\n\n\nAs a final example of a measure, the n-dimensional Gaussian measure, with mean 0 and standard deviation 1, is defined as:\n\\[\n\\gamma^{n} (A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x)\n\\]\nAgain, for every possible value of \\(x \\in A\\), we will measure all the image sets that result from those values and we add up all those measure results. This particular function is really great because for \\(x\\rightarrow\\pm \\infty\\), the measure is still a number. It’s also called a probability measure because \\(\\gamma^n(\\Omega)=1\\), that is, the total measured area under the whole domain is 1 or 100%. If you have done a bit of probability, the function \\(\\mathbb{P}\\) was a probability measure all along.\nThis is a lot to digest, I know. Just read it until it clicks. It took me 3 years of meditating on the subject after all!"
  },
  {
    "objectID": "measuretheory.html#a-primer-on-measure-theory",
    "href": "measuretheory.html#a-primer-on-measure-theory",
    "title": "Measure theory",
    "section": "",
    "text": "You may have grown accustomed to calling “integration” to something like \\(\\int_{a}^{b}fdx\\) , but that’s actually just the Riemann integration. Ok, it “just” powers 99% of all real-life integration, but there are many other specialized integrals that can handle special situations like discontinuities or holes in \\(f\\), such as the Riemann-Stieltjes integral, the Henstock-Kurzweil integral, and the Lebesgue integral. The last one is where we will concentrate the most.\nWe start with a seemingly unrelated problem: the size of a set. Let’s say we have a set of \\(\\mathbb{N}\\) and we want to know how big it is: we may, for example, just count how many elements are there in the set:\n\\[\n\\begin{aligned}\n&\\#\\{\\pi,e,25\\} = 3\\\\\n&\\#\\{\\} = 0 \\\\\n&\\#\\{1,2,3,..\\} = \\infty\n\\end{aligned}\n\\]\nIn a sense, \\(\\#\\) is a function that receives a set with a combination of elements from \\(\\mathbb{N}\\) and outputs a numeric value. In the literature, the elements belong to a set \\(\\Omega\\) and the combinations of those elements belong to a set of sets \\(\\Sigma\\) , also called a sigma-algebra. More formally, \\(\\# : \\Sigma \\to \\mathbb{N}\\).\n\\(\\#\\) is called a measure. Measures are normally referred as \\(\\mu\\), and fulfill roughly two conditions:\n\n\\(\\mu(s) \\ge 0 ,\\, \\forall s \\in \\Sigma\\), that is, they are always positive. This condition can be relaxed, though, into having “signed measures”.\nIf \\(A_1 \\cap A_2 = \\{\\} \\implies {\\mu (A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)}\\). This means that the “size” of a set is the same as the sum of the sizes of its subsets.\n\nThere are many measures, with different properties, that are defined to operate over “measurable sets”, namely the pair \\((\\Omega,\\Sigma)\\). You have already seen the counting measure. The Borel measure, which we will use interchangeably with the Lebesgue measure1, can be defined as:\n\\[\n\\lambda((a,b])=b-a\n\\]\nIf the set is a composition of intervals, it can be split into as many sums as we need, so:\n\\[\n\\lambda([0,2]\\cup(12,20))=\\lambda([0,2])+\\lambda((12,20))=(2-0)+(20-12)=10\n\\]\nIt can also be reasonably extended to multidimensional cases:\n\\[\n\\lambda^2((0,\\pi]\\times(2,4])=\\lambda((0,\\pi])*\\lambda((2,4])=(\\pi-0)*(4-2)=\\pi*2=2\\pi\n\\]"
  },
  {
    "objectID": "measuretheory.html#connection-between-measures-and-integrals",
    "href": "measuretheory.html#connection-between-measures-and-integrals",
    "title": "Measure theory",
    "section": "",
    "text": "We will now do something daring: have you noticed that definite integrals work over an interval (a set) and the result is a number? Yes, an integral is a (signed) measure2. This will require a bit of rethinking of what integrating really means, as well as changing our notation for the integral.\nIn the world we all know, we do Riemann integration, \\(\\int_{a}^{b}fdx\\). This means:\n\n\\(I=\\left[a,b\\right]\\) will select the portion of the function’s domain, \\(\\Omega\\) , to integrate. With the language we have used above, \\(I\\subset \\Omega,\\, I\\in \\Sigma\\)\nWe split \\(I\\) into partitions, typically using a single partition size \\(\\Delta x\\), and come up with a list of values \\(\\left\\{x_0=a, x_1, …, x_n=b\\right\\} \\in I\\)\nFor each partition \\(x_i\\) we evaluate it with \\(f(x_i)\\) to obtain a list of evaluations \\(f_0, f_1, ..., f_n\\)\nWe calculate an approximation of the integral by making each of these values a rectangle of height \\(f_i\\) and predefined width \\(\\Delta x\\), and summing over all rectangles.\nThe integral, if it exists, is the limit of this sum when the partition’s norm tends to zero.\n\nHere’s how it looks like:\n\n\nCode\nlibrary(ggplot2)\nlibrary(broom)\n\nf &lt;- function(x) x^3 - 3*x^2 + x +4\n\n# Define the interval [a, b] for integration\na &lt;- 0\nb &lt;- 3\n\n# Number of rectangles for approximation\nn &lt;- 24\n\n# Generate x values and corresponding function values\nx_values &lt;- seq(a, b, length.out = n+1)\ny_values &lt;- f(x_values)\n\n# Create a data frame for ggplot\ndf &lt;- data.frame(x = x_values, y = y_values)\n\n# Calculate rectangle heights\ndf$rect_heights &lt;- c(0,f(x_values)[2:length(x_values)])\n\n# Calculate total width of the bars to fill the x-axis\ntotal_width &lt;- b - a\n\n# Create a ggplot with rectangles\np &lt;- ggplot(df, aes(x = x, y = rect_heights)) +\n    geom_col(width=(total_width/n), fill = \"skyblue\", color = \"black\", just = 1, alpha=0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Riemann Integration Demonstration\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\nPowerful as it is, this can be improved. For starters, we can only integrate intervals over a real domain, \\(\\Omega =\\mathbb{R}\\) . For functions with many variables, we also need to integrate over many real domains, for example \\(\\int_{x_a}^{x_b}\\int_{y_a}^{y_b}\\int_{z_a}^{z_b}f(x,y,z)\\,dz\\,dy\\,dx\\) .\nNotice that we could get rid of these restrictions if we integrate over the only real line that’s guaranteed to exist: the one of the codomain or image. Kind of like a stack of dishes, for each height we measure the domain that falls under it. This is called Lebesgue integration, it’s written as \\(\\int_{s} f\\, d\\lambda\\) , and it means:\n\n\\(s\\) will select a portion of the function’s domain, \\(\\Omega\\) , to integrate. With the language we have used above, \\(s\\subset \\Omega,\\, s\\in \\Sigma\\)\nWe split the image of the function, \\(f^{-1}\\) into partitions, and we obtain the images \\(f_0,f_1,…,\\infty\\)\nFor each of these partitions, we obtain the set of values of the domain that have a function value at least that height: \\(f^{-1}_t = \\{\\omega \\in s\\, / \\, f(\\omega) &gt; t\\}\\in\\Sigma\\). Notice that these sets should be measurable and that \\(f_{\\infty} = \\{\\}\\), so that the integral is bounded.\nWe calculate an approximation of the integral by making each of these sets a group of “volumes” of predefined height \\(f_t\\) and base \\(\\mu(f^{-1}_t)\\), and summing over all rectangles.\nAdding up all the measured sets, all the slices of heights, will yield a final value, which behaves as a measure\nThe integral, if it exists, is the supremum of all the sum calculations that can be achieved by splitting the image into smaller and smaller partitions\n\nHere’s how this mess looks like:\n\n\nCode\nA &lt;- 1\nB &lt;- -3\nC &lt;- 1\nD &lt;- 4\nf &lt;- function(x) A*x^3 + B*x^2 + C*x + D\ndfdx &lt;- function(x) A*3*x^2 + B*2*x + C\n\n# Define the domain [left, right] for integration\nleft &lt;- 0\nright &lt;- 3\n\n# Number of image partitions\nmax_y &lt;- 7\nn &lt;- 28\ndelta_y &lt;- max_y / n\n\n# Generate x values and corresponding function values\ny_values &lt;- seq(0, max_y, length.out = n + 1)\n\n\nfind_real_roots_of_cubic &lt;- function(A, B, C, D, tolerance = 1e-10) {\n  # Find the roots using polyroot()\n  roots &lt;- polyroot(c(D, C, B, A))\n  \n  # Extract real parts of the roots\n  real_parts &lt;- Re(roots)\n  \n  # Filter out complex roots (where the imaginary part is close to zero)\n  real_roots &lt;- real_parts[abs(Im(roots)) &lt; tolerance]\n  \n  return(real_roots)\n}\n\ncalculate_intervals_for_measure &lt;- function(A, B, C, D, lower_bound, upper_bound) {\n  # Find the real roots \n  roots &lt;- find_real_roots_of_cubic(A, B, C, D)\n  roots &lt;- sort(roots)\n  \n  # The first interval should start on the lower bound if the function is decreasing \n  intervals &lt;- data.frame(a = double(), b = double())\n  current_left &lt;- lower_bound\n  \n  # Then, build every pair of (f' &gt; 0, f' &lt; 0).\n  for (i in (1:length(roots))) {\n    # Stop if you have gone beyond the boundary.\n    if (roots[i] &gt; upper_bound) {\n      break;\n    }\n    \n    if (!is.na(current_left)) {\n      possible_right &lt;- roots[i]\n      if (dfdx(possible_right) &lt; 0) {\n        if (current_left &lt; possible_right) {\n          # Add an interval.\n          intervals[nrow(intervals) + 1,] &lt;- c(current_left, possible_right)\n          current_left &lt;- NA\n        } else {\n          # This is closing an interval to the left of the lower bound. Skip.\n        }\n      } else {\n        # Another increasing left would be the start of an interval to the left of the lower bound\n        # or to the right of the lower bound. So, just keep the maximum.\n        # It could also be a missed root in between, but we will disregard this option.\n        current_left &lt;- max(current_left, possible_right)\n      }\n    } else {\n      possible_left &lt;- roots[i]\n      if (dfdx(possible_left) &gt; 0) {\n        if (possible_left &lt; upper_bound) {\n          # The opening of a new interval. As long as it's not beyond the upper bound, use it.\n          current_left &lt;- possible_left\n        }\n      } else {\n        # A decreasing function, without a left boundary, can be discarded\n      }\n    }\n  }\n    \n  # If there's an open interval after processing, close it at the upper bound.\n  if (!is.na(current_left)) {\n    intervals[nrow(intervals) + 1,] &lt;- c(current_left, upper_bound)\n  }\n  \n  return(intervals)\n}\n\n# Create a data frame for ggplot\nrectangles &lt;- data.frame(\n  xmin = double(),\n  xmax = double(),\n  ymin = double(),\n  ymax = double())\n\n# Calculate all rectangles\nfor(y in y_values) {\n  intervals &lt;- calculate_intervals_for_measure(A, B, C, D - y, left, right)\n  for (i in (1:nrow(intervals))) {\n    interval &lt;- intervals[i,]\n    rectangles[nrow(rectangles) + 1,] &lt;- c(interval[1], interval[2], max(0, y - delta_y), y)\n  }\n}\n\n# Create a ggplot with rectangles\np &lt;- ggplot() +\n    geom_rect(data = rectangles,\n          aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n          fill = \"skyblue\",\n          colour = \"darkgrey\",\n          alpha = 0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Lebesgue Integration Demonstration\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)"
  },
  {
    "objectID": "measuretheory.html#gaussian-measures",
    "href": "measuretheory.html#gaussian-measures",
    "title": "Measure theory",
    "section": "",
    "text": "As a final example of a measure, the n-dimensional Gaussian measure, with mean 0 and standard deviation 1, is defined as:\n\\[\n\\gamma^{n} (A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x)\n\\]\nAgain, for every possible value of \\(x \\in A\\), we will measure all the image sets that result from those values and we add up all those measure results. This particular function is really great because for \\(x\\rightarrow\\pm \\infty\\), the measure is still a number. It’s also called a probability measure because \\(\\gamma^n(\\Omega)=1\\), that is, the total measured area under the whole domain is 1 or 100%. If you have done a bit of probability, the function \\(\\mathbb{P}\\) was a probability measure all along.\nThis is a lot to digest, I know. Just read it until it clicks. It took me 3 years of meditating on the subject after all!"
  },
  {
    "objectID": "measuretheory.html#footnotes",
    "href": "measuretheory.html#footnotes",
    "title": "Measure theory",
    "section": "",
    "text": "The Lebesgue outer measure has a more complex definition that avoids some pathological results that the Borel measure has in certain measurable sets. In “reasonable” sets where the Borel measure is defined, the Lebesgue measure coincides.↩︎\nThe converse, that any (signed) measure is always an integral, is also true under certain conditions. This is the consequence of the Radon-Nikodym theorem.↩︎"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nThis web book is built around Malliavin Calculus and the Clark-Ocone formula. After many months of frustration, I figured the main obstacle with learning the topic is the emphasis on mathematical rigor over pedagogical clarity, so I hope to bridge that gap. I’m assuming just basic knowledge of algebra, analysis and probability.\nI will start with developing what Malliavin calculus was meant to address. I will approach it in an indirect, meandering way. After documenting situations were a problem exists, the need for a solution will generate a “vacuum” of sorts. Following that, again indirectly, I’ll lay the foundation step by step. Finally, the vacuum will be filled.\nAs mentioned, pedagogical clarity is the guiding factor. I’ll disregard proofs if I don’t see them important. Shortcuts will be taken liberally. Some pieces will lead nowhere or be there just to round up a concept. I may even admit when I’m ignorant about something and leave it like that.\nTruth is, I’m not a mathematician, a statistician or an economist. I’m just trying to understand an obscure topic.\nNow, it’s time to start."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nTo understand Malliavin Calculus, you don’t just understand the formulas and their proofs. Malliavin Calculus is the answer to a question, and knowing the answer and the path to it isn’t enough.\nYou need to understand the question.\nThis entire web book was created so I can explain the topic to myself, and learn this obscure topic as a consequence of it. If you watched “12 Monkeys” or “Arrival” you know exactly what I’m talking about. Just follow along and both you and I will (hopefully) learn.\nThis web book was created using Quarto and RStudio, the last IDE you’ll ever need. To learn more about Quarto books visit https://quarto.org/docs/books. To learn more about RStudio IDE visit https://posit.co/products/open-source/rstudio/. I also use R over Python because I like it better for Math/Statistics topics.\nFinally, I dedicate this work to Pablo Azcue, may his memory be a blessing. He probably never knew, but he was the one that made me love real analysis and stochastic processes."
  },
  {
    "objectID": "cameronmartin.html",
    "href": "cameronmartin.html",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "Whew, that was too much algebra! But we needed to introduce infinite-dimensional vector spaces in order to understand what a Cameron-Martin space is. Like before, you’ll find Alessandra Lunardi (2015) has more mathematical rigor, which we ditched long ago in favor of pedagogical clarity. The gap is significant, though. If you browse Wikipedia, the number of concepts you need to learn to even make sense of a sentence is hard. Hopefully, this will give you enough background on Cameron-Martin to proceed to the Malliavin Derivative.\n\n\nWe mentioned last time that we would solve the problem of calculating length and distance of infinite-dimensional vectors (such as functions) by changing the measure from Lebesgue to Gaussian. There’s another reason for that choice, encapsulated in Wikipedia contributors (2024). The Lebesgue measure is the only measure in finite-dimensional spaces that’s:\n\nLocally finite, that is, every set around a point has a finite measure. \\(\\lambda(N_x) &lt; +\\infty\\)\nTranslation invariant, that is, moving a set on a certain direction \\(d\\) keeps the measure value intact. \\(\\lambda(\\{N_x\\}=\\lambda(\\{N_x \"+\" d\\})\\)\nStrictly positive, that is, if \\(A \\neq \\emptyset\\), then \\(\\lambda(A)&gt;0\\)\n\nFor infinite dimensions, there’s no equivalent1. In fact, for most of these spaces the only locally finite, translation invariant measure is the trivial measure \\(\\mu(A)=0, \\forall A\\) .\nSo, we turn to the Gaussian measure, which has exponential tails that can squash function values if they are far away from the center2. But that means we need to address other problems. In particular, the lack of translation invariance.\n\n\n\nTo better illustrate this issue, let’s assume some kind of Riemann integration like so:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx\n\\]\nWe will now make a change of variable due to a translation \\(x \\rightarrow x +h\\), then the area under the curve will not have changed, it just shifted to the side:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx = \\int_{-\\infty}^{+\\infty}f(x+h)dx\n\\]\nThis is supported by the underlying Lebesgue measure, which is also invariant under an arbitrary translation:\n\\[\n\\lambda([a+h,b+h])=(b-h)-(a-h)=b-a=\\lambda([a,b])\n\\]\nAnd it finally be confirmed visually. Look at these functions that kind of resemble ghosts. Regardless of the shift, they have the same area under the curve:\n\n\nCode\nlibrary(ggplot2)\n\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\ny_1 &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h\n)\n\n# ggplot(data = df, mapping = aes(time)) +\n#   geom_area(mapping = aes(y=density_y, color=\"green\"), alpha = 0.5, show.legend = FALSE) +\n#   geom_area(mapping = aes(y=density_y_plus), alpha = 0.5, show.legend = FALSE)\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=density_y, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=density_y_plus, fill=\"f(X+5)\"), alpha = 0.5) +\n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\"))\n\n\n\n\n\nUnfortunately, the Gaussian measure doesn’t allow that. Let’s remember the \\(n\\)-dimensional or 1-dimensional cases for a standard, centered Gaussian measure.\n\\[\n\\begin{aligned}\n\\gamma^{n}(A) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x) \\\\\n\\gamma(A) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{A} \\exp \\left( - \\frac{1}{2} x^{2} \\right) \\, \\mathrm{d} \\lambda (x)\n\\end{aligned}\n\\]\nLet’s use the Gaussian measure (or a weight) for the functions above, and see how they modify the area under both functions:\n\n\nCode\nlibrary(ggplot2)\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\nweight &lt;- dnorm(x)\ny &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_weighted &lt;- y * weight\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\ny_plus_h_weighted &lt;- y_plus_h * weight\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h,\n  weight=weight\n)\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=y_weighted, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=y_plus_h_weighted, fill=\"f(X+5)\"), alpha = 0.5) + \n  geom_line(mapping = aes(y=weight, colour=\"Weight\"),linetype = 2) + \n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\")) + \n  scale_colour_manual(\"\",values=c(\"black\"),labels=c(\"Weight\"))\n\n\n\n\n\nCode\n  #theme(legend.position = \"none\")\n\n\nAs you can see, the first function had plenty of area in the middle of the weight, so it retains quite a bit. The shifted function instead has shrunk. Now, even though the area has changed, we could in theory recover the factor by which it has changed. With finite dimensions, this is doable, but it’s challenging in infinite dimensions.\nThe main idea here is that you are allowed to perform these translations in infinite dimensions and arrive to a calculation that still works. The only requirement is that the translation comes from a “smaller” space, the Cameron-Martin space, and only those translations make sense and are allowed.\n\n\n\nAlthough it sounds mysterious, it’s actually kind of straightforward, and you can follow the approach from Wikipedia contributors (2023) and Alessandra Lunardi (2015). Let’s go back to the inner product instead of using the norm, to understand what’s going on, and we will use a finite \\(n\\)-dimensional space:\n\\[\n\\gamma^{n}(A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx\n\\]\nNow, we can replace \\(A\\) with a shifted \\(A-h\\) and see how far that takes us:\n\\[\n\\begin{aligned}\n\\gamma^{n}(A-h) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x-h,x-h \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) * \\exp \\left( - \\frac{1}{2} \\left(-2\\langle x,h \\rangle_{\\mathbb{R}^{n}} + \\langle h,h \\rangle_{\\mathbb{R}^{n}}\\right) \\right)\\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\underbrace{\\exp \\left( - \\frac{1}{2} \\| x \\|^2_{\\mathbb{R}^{n}} \\right)}_{\\text{Gaussian Meassure}} * \\underbrace{\\exp \\left(  \\langle x,h \\rangle_{\\mathbb{R}^{n}} - \\frac{1}{2} \\| h \\|^2_{\\mathbb{R}^{n}}\\right)}_{\\text{\"Change of variable\"}} \\, dx \\\\\n\\end{aligned}\n\\]\nSo, a Gaussian measure for a translated set is the measure for the original set, multiplied by an extra factor to perform the “change of variable”. That extra factor is called the Radon-Nikodym derivative because it expresses how a measure changes when another changes. In this case, we will denote it as the one that transforms the centered Gaussian measure into the \\(h\\)-Translated Gaussian measure, symbolized as \\(\\frac{\\partial(T_h)_*(\\gamma)}{d\\gamma}(x)\\)\nNow, let’s point out once again that, if there’s a space \\(E\\) and a measure \\(\\mu\\) that’s locally finite and equivalent to itself after any translation “change of variables”, then either \\(E\\) is finite-dimensional, as shown above, or \\(\\mu\\) is the trivial measure \\(\\mu(A) = 0,\\, \\forall A\\). We can also already see from the expression above that if \\(h\\) is infinite-dimensional then there’s the potential to make this integral tend to infinity. Fortunately for us, we can sidestep this by only expecting equivalence under some translations, namely translations that are elements of a Cameron-Martin space, also called Cameron-Martin directions.\nWe start from an infinite-dimensional space \\(H\\), our Cameron-Martin space. We will have \\(h \\in H\\), with a mapping \\(i(h):H\\rightarrow E\\), and \\(i(H) \\subseteq E\\). These \\(i(H)\\) will be our Cameron-Martin directions. We will impose additional restrictions on \\(h\\). For starters, and based on the Radon-Nikodym derivative we see above, we need at least \\(\\|h\\|^2_H &lt; \\infty\\). Then, we need to decide what \\(\\langle h, x \\rangle\\) even means and what to do with it. In fact, this isn’t a true inner product because \\(h \\in H\\) and \\(x \\in E\\) (remember, the whole point of \\(H\\) is to reduce the space!). In short, what’s going on with that fake inner product is that there’s a mapping for every \\(h\\) to a function in the space of functions \\(I(h): H \\rightarrow L^2\\), and \\(I(h)(x)\\) is what will count as the “inner product” \\(\\langle h, x \\rangle^\\sim\\). 3\n\n\n\nAll of the above is pretty arid, so let’s take a look at one example of a infinite-dimensional space and its corresponding Cameron-Martin space. I won’t try to explain how this space was obtained, there’s a lengthy derivation in Alessandra Lunardi (2015) .\n\n\nRecall the space of infinite sequences? It’s an infinite-dimensional space and we denoted it \\(\\mathbb{R}^{\\mathbb{N}}:=\\mathbb{R}^{\\infty}\\), with countable cardinality. Now, let’s consider the space of sequences that vanish at infinity, with the exotic symbol \\(\\mathbb{R}_c^{\\infty}\\) and its elements will have the even more exotic symbol \\(\\xi\\in\\mathbb{R}_c^{\\infty}\\) . So, by definition, we know \\(\\lim_{k\\rightarrow \\infty}\\xi_k = 0\\).\nNow, we establish a correspondence between these sequences and functions, very straightforward: \\(\\xi \\rightarrow f, \\text{with }f(x) = \\sum^\\infty_{k=1}\\xi_k x_k\\) , and we will limit this to the sums that are finite, in other words \\(f(x)&lt;\\infty\\) or \\(f(x) \\in L^2\\). Notice that when we measure the first term of this series with a Gaussian measure, we will be simplifying a lot:\n\\[\n\\int_X \\xi_1 x_1 d\\gamma(x_1)=\\xi_1 \\int_{-\\infty}^{+\\infty} x_1d\\gamma(x_1)=\\xi_1 *\\mathbb{E}[\\mathcal{N}(\\mu=0,\\sigma^2=1)]=0\n\\]\nNow, you can do this for all \\(x_k\\) and find the same result. This is no coincidence, and it’s the reason why we used the Gaussian measure for infinite dimensions. In fact, \\(\\gamma\\) for the infinite-dimensional case will have mean \\(\\mu=0\\) and variance/covariance \\(B_\\gamma(\\xi,\\xi)=\\|\\xi\\|_{\\ell^2}\\).\nThis last statement is also useful because we can use it to arrive from the norm of a function using the Gaussian measure to its value. I won’t prove it now, but \\(\\|f\\|^2_{L^2(X,\\gamma)}=\\|\\xi\\|^2_{\\ell^2}\\). Now, if we take a \\(h\\in \\mathbb{R}^\\infty\\), we can show (but we won’t) that by having \\(h\\in H = \\ell^2\\) instead, this is enough for the functions above to be measured and to always obtain a value. So, the Cameron-Martin space is \\(\\ell^2\\).\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. “Infinite Dimensional Analysis.” 2015. http://dmi.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nWikipedia contributors. 2023. “Cameron–Martin Theorem — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Cameron%E2%80%93Martin_theorem.\n\n\n———. 2024. “Infinite-Dimensional Lebesgue Measure — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Infinite-dimensional_Lebesgue_measure."
  },
  {
    "objectID": "cameronmartin.html#gaussian-measures",
    "href": "cameronmartin.html#gaussian-measures",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "We mentioned last time that we would solve the problem of calculating length and distance of infinite-dimensional vectors (such as functions) by changing the measure from Lebesgue to Gaussian. There’s another reason for that choice, encapsulated in Wikipedia contributors (2024). The Lebesgue measure is the only measure in finite-dimensional spaces that’s:\n\nLocally finite, that is, every set around a point has a finite measure. \\(\\lambda(N_x) &lt; +\\infty\\)\nTranslation invariant, that is, moving a set on a certain direction \\(d\\) keeps the measure value intact. \\(\\lambda(\\{N_x\\}=\\lambda(\\{N_x \"+\" d\\})\\)\nStrictly positive, that is, if \\(A \\neq \\emptyset\\), then \\(\\lambda(A)&gt;0\\)\n\nFor infinite dimensions, there’s no equivalent1. In fact, for most of these spaces the only locally finite, translation invariant measure is the trivial measure \\(\\mu(A)=0, \\forall A\\) .\nSo, we turn to the Gaussian measure, which has exponential tails that can squash function values if they are far away from the center2. But that means we need to address other problems. In particular, the lack of translation invariance."
  },
  {
    "objectID": "cameronmartin.html#translation-invariance",
    "href": "cameronmartin.html#translation-invariance",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "To better illustrate this issue, let’s assume some kind of Riemann integration like so:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx\n\\]\nWe will now make a change of variable due to a translation \\(x \\rightarrow x +h\\), then the area under the curve will not have changed, it just shifted to the side:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx = \\int_{-\\infty}^{+\\infty}f(x+h)dx\n\\]\nThis is supported by the underlying Lebesgue measure, which is also invariant under an arbitrary translation:\n\\[\n\\lambda([a+h,b+h])=(b-h)-(a-h)=b-a=\\lambda([a,b])\n\\]\nAnd it finally be confirmed visually. Look at these functions that kind of resemble ghosts. Regardless of the shift, they have the same area under the curve:\n\n\nCode\nlibrary(ggplot2)\n\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\ny_1 &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h\n)\n\n# ggplot(data = df, mapping = aes(time)) +\n#   geom_area(mapping = aes(y=density_y, color=\"green\"), alpha = 0.5, show.legend = FALSE) +\n#   geom_area(mapping = aes(y=density_y_plus), alpha = 0.5, show.legend = FALSE)\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=density_y, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=density_y_plus, fill=\"f(X+5)\"), alpha = 0.5) +\n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\"))\n\n\n\n\n\nUnfortunately, the Gaussian measure doesn’t allow that. Let’s remember the \\(n\\)-dimensional or 1-dimensional cases for a standard, centered Gaussian measure.\n\\[\n\\begin{aligned}\n\\gamma^{n}(A) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x) \\\\\n\\gamma(A) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{A} \\exp \\left( - \\frac{1}{2} x^{2} \\right) \\, \\mathrm{d} \\lambda (x)\n\\end{aligned}\n\\]\nLet’s use the Gaussian measure (or a weight) for the functions above, and see how they modify the area under both functions:\n\n\nCode\nlibrary(ggplot2)\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\nweight &lt;- dnorm(x)\ny &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_weighted &lt;- y * weight\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\ny_plus_h_weighted &lt;- y_plus_h * weight\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h,\n  weight=weight\n)\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=y_weighted, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=y_plus_h_weighted, fill=\"f(X+5)\"), alpha = 0.5) + \n  geom_line(mapping = aes(y=weight, colour=\"Weight\"),linetype = 2) + \n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\")) + \n  scale_colour_manual(\"\",values=c(\"black\"),labels=c(\"Weight\"))\n\n\n\n\n\nCode\n  #theme(legend.position = \"none\")\n\n\nAs you can see, the first function had plenty of area in the middle of the weight, so it retains quite a bit. The shifted function instead has shrunk. Now, even though the area has changed, we could in theory recover the factor by which it has changed. With finite dimensions, this is doable, but it’s challenging in infinite dimensions.\nThe main idea here is that you are allowed to perform these translations in infinite dimensions and arrive to a calculation that still works. The only requirement is that the translation comes from a “smaller” space, the Cameron-Martin space, and only those translations make sense and are allowed."
  },
  {
    "objectID": "cameronmartin.html#the-cameron-martin-space",
    "href": "cameronmartin.html#the-cameron-martin-space",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "Although it sounds mysterious, it’s actually kind of straightforward, and you can follow the approach from Wikipedia contributors (2023) and Alessandra Lunardi (2015). Let’s go back to the inner product instead of using the norm, to understand what’s going on, and we will use a finite \\(n\\)-dimensional space:\n\\[\n\\gamma^{n}(A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx\n\\]\nNow, we can replace \\(A\\) with a shifted \\(A-h\\) and see how far that takes us:\n\\[\n\\begin{aligned}\n\\gamma^{n}(A-h) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x-h,x-h \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) * \\exp \\left( - \\frac{1}{2} \\left(-2\\langle x,h \\rangle_{\\mathbb{R}^{n}} + \\langle h,h \\rangle_{\\mathbb{R}^{n}}\\right) \\right)\\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\underbrace{\\exp \\left( - \\frac{1}{2} \\| x \\|^2_{\\mathbb{R}^{n}} \\right)}_{\\text{Gaussian Meassure}} * \\underbrace{\\exp \\left(  \\langle x,h \\rangle_{\\mathbb{R}^{n}} - \\frac{1}{2} \\| h \\|^2_{\\mathbb{R}^{n}}\\right)}_{\\text{\"Change of variable\"}} \\, dx \\\\\n\\end{aligned}\n\\]\nSo, a Gaussian measure for a translated set is the measure for the original set, multiplied by an extra factor to perform the “change of variable”. That extra factor is called the Radon-Nikodym derivative because it expresses how a measure changes when another changes. In this case, we will denote it as the one that transforms the centered Gaussian measure into the \\(h\\)-Translated Gaussian measure, symbolized as \\(\\frac{\\partial(T_h)_*(\\gamma)}{d\\gamma}(x)\\)\nNow, let’s point out once again that, if there’s a space \\(E\\) and a measure \\(\\mu\\) that’s locally finite and equivalent to itself after any translation “change of variables”, then either \\(E\\) is finite-dimensional, as shown above, or \\(\\mu\\) is the trivial measure \\(\\mu(A) = 0,\\, \\forall A\\). We can also already see from the expression above that if \\(h\\) is infinite-dimensional then there’s the potential to make this integral tend to infinity. Fortunately for us, we can sidestep this by only expecting equivalence under some translations, namely translations that are elements of a Cameron-Martin space, also called Cameron-Martin directions.\nWe start from an infinite-dimensional space \\(H\\), our Cameron-Martin space. We will have \\(h \\in H\\), with a mapping \\(i(h):H\\rightarrow E\\), and \\(i(H) \\subseteq E\\). These \\(i(H)\\) will be our Cameron-Martin directions. We will impose additional restrictions on \\(h\\). For starters, and based on the Radon-Nikodym derivative we see above, we need at least \\(\\|h\\|^2_H &lt; \\infty\\). Then, we need to decide what \\(\\langle h, x \\rangle\\) even means and what to do with it. In fact, this isn’t a true inner product because \\(h \\in H\\) and \\(x \\in E\\) (remember, the whole point of \\(H\\) is to reduce the space!). In short, what’s going on with that fake inner product is that there’s a mapping for every \\(h\\) to a function in the space of functions \\(I(h): H \\rightarrow L^2\\), and \\(I(h)(x)\\) is what will count as the “inner product” \\(\\langle h, x \\rangle^\\sim\\). 3"
  },
  {
    "objectID": "cameronmartin.html#example-of-a-cameron-martin-space",
    "href": "cameronmartin.html#example-of-a-cameron-martin-space",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "All of the above is pretty arid, so let’s take a look at one example of a infinite-dimensional space and its corresponding Cameron-Martin space. I won’t try to explain how this space was obtained, there’s a lengthy derivation in Alessandra Lunardi (2015) .\n\n\nRecall the space of infinite sequences? It’s an infinite-dimensional space and we denoted it \\(\\mathbb{R}^{\\mathbb{N}}:=\\mathbb{R}^{\\infty}\\), with countable cardinality. Now, let’s consider the space of sequences that vanish at infinity, with the exotic symbol \\(\\mathbb{R}_c^{\\infty}\\) and its elements will have the even more exotic symbol \\(\\xi\\in\\mathbb{R}_c^{\\infty}\\) . So, by definition, we know \\(\\lim_{k\\rightarrow \\infty}\\xi_k = 0\\).\nNow, we establish a correspondence between these sequences and functions, very straightforward: \\(\\xi \\rightarrow f, \\text{with }f(x) = \\sum^\\infty_{k=1}\\xi_k x_k\\) , and we will limit this to the sums that are finite, in other words \\(f(x)&lt;\\infty\\) or \\(f(x) \\in L^2\\). Notice that when we measure the first term of this series with a Gaussian measure, we will be simplifying a lot:\n\\[\n\\int_X \\xi_1 x_1 d\\gamma(x_1)=\\xi_1 \\int_{-\\infty}^{+\\infty} x_1d\\gamma(x_1)=\\xi_1 *\\mathbb{E}[\\mathcal{N}(\\mu=0,\\sigma^2=1)]=0\n\\]\nNow, you can do this for all \\(x_k\\) and find the same result. This is no coincidence, and it’s the reason why we used the Gaussian measure for infinite dimensions. In fact, \\(\\gamma\\) for the infinite-dimensional case will have mean \\(\\mu=0\\) and variance/covariance \\(B_\\gamma(\\xi,\\xi)=\\|\\xi\\|_{\\ell^2}\\).\nThis last statement is also useful because we can use it to arrive from the norm of a function using the Gaussian measure to its value. I won’t prove it now, but \\(\\|f\\|^2_{L^2(X,\\gamma)}=\\|\\xi\\|^2_{\\ell^2}\\). Now, if we take a \\(h\\in \\mathbb{R}^\\infty\\), we can show (but we won’t) that by having \\(h\\in H = \\ell^2\\) instead, this is enough for the functions above to be measured and to always obtain a value. So, the Cameron-Martin space is \\(\\ell^2\\).\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. “Infinite Dimensional Analysis.” 2015. http://dmi.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nWikipedia contributors. 2023. “Cameron–Martin Theorem — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Cameron%E2%80%93Martin_theorem.\n\n\n———. 2024. “Infinite-Dimensional Lebesgue Measure — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Infinite-dimensional_Lebesgue_measure."
  },
  {
    "objectID": "cameronmartin.html#footnotes",
    "href": "cameronmartin.html#footnotes",
    "title": "Cameron-Martin spaces",
    "section": "",
    "text": "Strictly speaking, you can get an analogue, but the space must be non-separable and the measure won’t be sigma-finite. The spaces we deal with will normally be separable. In particular, Hilbert spaces (spaces with inner products that are complete under the metric induced by the inner product) are separable if there’s an orthonormal basis on \\(\\mathbb{N}\\).↩︎\nThis is a consequence of Fernique’s Theorem↩︎\nThis is called the Paley-Wiener integral. We won’t need to mention or refer to this again because it agrees with the Ito integral when both are defined, similar to the Borel and Lebesgue measures.↩︎"
  },
  {
    "objectID": "clarkocone.html",
    "href": "clarkocone.html",
    "title": "Applications and in-depth cases",
    "section": "",
    "text": "Up until now, Malliavin calculus has been mostly a game or procedure we apply to stochastic processes. We will dive deeper and reach some interesting results.\n\n\nLet’s consider a random process \\(N_t\\) that fluctuates around a value \\(\\mu\\) and corrects itself more strongly the farther it is to \\(\\mu\\), plus some noise. So, we want something like this:\n\\[\ndN_t = \\theta(\\mu - N_t)\\,dt+ \\sigma\\,dW_t\n\\]\nFor example, let’s say that a lake can accept around \\(\\mu=1000\\) trouts. If there are more than that, some will starve and die off, and if there are less, then they will reproduce. Finally, \\(\\theta\\) controls how strong is the correction. Here are some examples with \\(\\theta=1\\) and different values for \\(\\sigma\\):\n\n\nCode\nlibrary(ggplot2)\n\n# Right\ndt &lt;- 0.01\ntotal_time &lt;- 10\nN_0 &lt;- 10\nmu_ou &lt;- 1000.0\ntetha_ou &lt;- 1.0\n\nsteps = total_time / dt\ntimes &lt;- seq(from = 0, to = total_time, length.out=steps)\nstretched_times &lt;- times * tetha_ou\ndBt &lt;- rnorm(steps,mean = 0, sd = sqrt(dt))\n\ndf &lt;- data.frame(\n  time=stretched_times\n)\n\nsigma_ou &lt;- 0\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_0 &lt;- N\n\nsigma_ou &lt;- 100\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_100 &lt;- N\n\nsigma_ou &lt;- 250\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_250 &lt;- N\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlab('Time') +\n  ylab('N(t)') +\n  geom_line(mapping = aes(y=N_100, colour=\"σ=100\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_250, colour=\"σ=250\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_0, colour=\"σ=0\"),linewidth = 1) +\n  scale_colour_manual(\"Functions\",values=c(\"black\",\"darkgray\",\"darkviolet\"))\n\n\n\n\n\nThis is a very common process, so much it has a name: the Ornstein-Uhlenbeck process. Now, let’s calculate \\(DN\\). We have \\(a(X) = \\theta(\\mu - X)\\) and \\(b(x) = \\sigma\\), so it’s not a simple Ito process that only depends on time. We better start from those before tackling the Ornstein-Uhlenbeck process. If we remember that we can split the integrals as \\(\\int_0^t... dW_t=\\sum_{i=1}^n{...(W_{t_i}-W_{t_{i-1}})}\\), then we can transform a classical Ito process \\(X_t\\) into something we can easily apply chain and product rules:\n\\[\n\\begin{aligned}\nX_t &= \\sum_{i=1}^n \\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i}(W_{t_i}-W_{t_{i-1}}) \\\\\nD_rX_t &= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n D_r[\\sigma_{t_i}\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i} \\cdot 1_{[t_{i-1},t_{i}]}(r) + \\sum_{i=1}^n D_r(\\sigma_{t_i})\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\int_0^t D_r\\mu_s\\,ds + \\sigma_r 1_{[0,t]}(r) + \\int_0^t D_r\\sigma_s\\,dW_s \\\\\n\\end{aligned}\n\\]\nIt looks messy, but things are what we expect: \\(t\\) is the terminal value of both integrals, \\(s\\) is the variable we use to integrate from \\(0\\) to \\(t\\), and \\(r\\) is the variable we introduced with the Malliavin Derivative. See that it makes sense: the influence of \\(\\sigma\\) in the Ito process is the same along the whole Ito process path.\nNow, we can use a similar argument for the number of trouts in the lake, which followed an Ornstein-Uhlenbeck process. Given that \\(\\mu_s\\) and \\(\\sigma_s\\) are now \\(a(s,X_s)\\) and \\(b(s,X_s)\\), we apply chain and product rules as above to arrive to:\n\\[\nD_rX_t = \\int_r^t \\frac{\\partial a}{\\partial x}(s, X_s)\\,D_rX_s\\,ds + b(r,X_r)1_{[0,t]}(r) + \\int_r^t \\frac{\\partial b}{\\partial x}(s, X_s)\\,D_rX_s\\,dW_s \\\\\n\\]\nNow, we know from above that \\(\\frac{\\partial a}{\\partial x} = -\\theta\\) and \\(\\frac{\\partial b}{\\partial x} = 0\\), so we get:\n\\[\n\\begin{aligned}\nD_rN_t &= \\int_r^t (-\\theta)\\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= -\\theta\\int_r^t \\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= \\sigma\\,e^{-\\theta(t-r)}\n\\end{aligned}\n\\]\nIn the case above, we arrive at a neat expression that tell us something interesting: the effect of a perturbation on the number of trouts is exponentially smaller if \\(r&lt;&lt;t\\). This makes sense: the population of trouts \\(N\\) wants to be close to \\(\\mu\\) and the population from a distant past is irrelevant. It also tells us that there’s no randomness in the fluctuation because it doesn’t depend on any random variable, such as \\(W_t\\).\nFinally, we lucked out above. The expression for \\(D_rN_t\\) is simple, so we could write an analytic expression for it. If it were more convoluted, it’s probably better to estimate a solution. Alos (2021) does a great job showcasing the above.\n\n\n\nLet’s see a relatively simple application with profound implications, following Friz (2002) entirely. Let’s consider this function:\n\\[\nF(t) = e^{\\int_0^t h\\,dB - \\frac{1}{2}\\int_0^t{h^2}d\\lambda}\n\\]\nThis function is an exponential martingale, that is, \\(\\mathbb{E}_s[F(t)]=F(s)\\). We now take \\(F(1) = \\mathcal{E}(h)\\) and we now calculate \\(DF\\) :\n\\[\n\\begin{aligned}\nD_tF &= e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot D_t(e^{\\int_0^1 h\\,dB}) \\\\\n&= \\underbrace{e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot e^{\\int_0^1 h\\,dB}}_{F} \\cdot h(t) \\\\\n&= Fh(t)\n\\end{aligned}\n\\]\nNow, this is only valid at \\(t=1\\), but we use the expectation operator and martingale property to get the values at a previous time. We will call \\(\\mathcal{F}_s\\) the filtration up to time \\(s\\), and it’s the way we call the “history” or “information” known up to time \\(s\\), and then:\n\\[\n\\begin{aligned}\n\\mathbb{E}[D_t F | \\mathcal{F}_t] &= \\mathbb{E}[F(1)h(t)|\\mathcal{F_t}] \\\\\n&=h(t) \\mathbb{E}[F(1)|\\mathcal{F_t}] \\\\\n&=h(t) F(t)\n\\end{aligned}\n\\]\nNow, we pull everything together. This martingale \\(F(t)\\) is the solution of the (stochastic) differential equation \\(dF(t) = h(t)F(t)dB_t\\), when \\(F(0)=1=\\mathbb{E}[F]\\). Replacing with the above expression we get:\n\\[\n\\begin{aligned}\nF(t) &= \\mathbb{E}[F] + \\int_0^1  h(t)F(t) dB_t \\\\\n&= \\mathbb{E}[F] + \\int_0^1 \\mathbb{E}[D_t F | \\mathcal{F_t}] dB_t\n\\end{aligned}\n\\]\nThis is the Clark-Ocone formula, which is an explicit formula for the Martingale Representation Theorem. The Malliavin derivative is the key ingredient to have an analytic expression and it’s the main reason one would care about it. What this is telling us is that any random variable indexed by time \\(F_t\\) can be split into a sum of a “deterministic” portion, the expected value, and a martingale that fluctuates around it.\nWe can apply this to the Ornstein-Uhlenbeck process for our trouts. We know from before that \\(D_rN_t = \\sigma\\,e^{-\\theta(t-r)}\\). Notice that there’s no \\(W_t\\), so the expected value is just the Malliavin derivative. We could estimate the value of \\(\\mathbb{E}[N]\\) or try to solve the (stochastic) differential equation, but given that the process already has a known solution, I’ll go ahead and add it. Here’s in all its splendor:\n\\[\n\\begin{aligned}\nN(t) &= \\mathbb{E}[N] + \\int_0^t \\mathbb{E_r}[D_r N_t] dW_r \\\\\n&= \\underbrace{X_0e^{-\\theta t} + \\mu(1-e^{-\\theta t})}_{Deterministic} + \\underbrace{\\int_0^t \\sigma\\,e^{-\\theta(t-r)}\\,dW_r}_{Martingale} \\\\\n\\end{aligned}\n\\]\nWhy do we care about this? Well, for once, if we wanted to simulate different paths of our fish population \\(N\\), we only need to simulate the martingale portion, and the deterministic portion is only calculated once. Secondly, we can use the Clark-Ocone formula to directly calculate the variance for \\(N\\), without knowing the full analytic solution. Indeed, remember that \\(\\mathbb{Var}[N]=\\mathbb{E}[N-\\mathbb{E}[N]]^2\\), so then, using Ito’s Isometry:\n\\[\n\\begin{aligned}\n\\mathbb{Var}[N]&=\\mathbb{E}\\left[\\left(\\int_0^t \\mathbb{E_r}[D_r N_t] dW_r\\right)^2\\right] \\\\\n&=\\mathbb{E}\\left[\\int_0^t \\left(\\sigma\\,e^{-\\theta(t-r)}\\right)^2dr\\right] \\\\\n&=\\sigma^2\\mathbb{E}\\left[\\int_0^t e^{2\\theta(r-t)}dr\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\mathbb{E}\\left[1-e^{-2\\theta t}\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\left(1-e^{-2\\theta t}\\right)\n\\end{aligned}\n\\]\nNotice that this works for any variable: you only need the Malliavin Derivative to get the variance. We see above that:\n\nOur trout population \\(N\\) in the long term (\\(t \\rightarrow \\infty\\)) will be a process moving around \\(\\mu\\) with a constant variance \\(\\frac{\\sigma^2}{2\\theta}\\)\nVariance at the time of trout introduction (\\(t \\approx 0\\)) is very small because the growth of \\(N\\), trying to reach \\(\\mu\\) as soon as possible, dominates over the noise\nA large \\(\\theta\\) will not only make the long term variance arrive sooner, it will also prevent large deviations from \\(\\mu\\)\n\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. “An Introduction to Malliavin Calculus.” In. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "clarkocone.html#malliavin-derivative-of-the-ornstein-uhlenbeck-process",
    "href": "clarkocone.html#malliavin-derivative-of-the-ornstein-uhlenbeck-process",
    "title": "Applications and in-depth cases",
    "section": "",
    "text": "Let’s consider a random process \\(N_t\\) that fluctuates around a value \\(\\mu\\) and corrects itself more strongly the farther it is to \\(\\mu\\), plus some noise. So, we want something like this:\n\\[\ndN_t = \\theta(\\mu - N_t)\\,dt+ \\sigma\\,dW_t\n\\]\nFor example, let’s say that a lake can accept around \\(\\mu=1000\\) trouts. If there are more than that, some will starve and die off, and if there are less, then they will reproduce. Finally, \\(\\theta\\) controls how strong is the correction. Here are some examples with \\(\\theta=1\\) and different values for \\(\\sigma\\):\n\n\nCode\nlibrary(ggplot2)\n\n# Right\ndt &lt;- 0.01\ntotal_time &lt;- 10\nN_0 &lt;- 10\nmu_ou &lt;- 1000.0\ntetha_ou &lt;- 1.0\n\nsteps = total_time / dt\ntimes &lt;- seq(from = 0, to = total_time, length.out=steps)\nstretched_times &lt;- times * tetha_ou\ndBt &lt;- rnorm(steps,mean = 0, sd = sqrt(dt))\n\ndf &lt;- data.frame(\n  time=stretched_times\n)\n\nsigma_ou &lt;- 0\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_0 &lt;- N\n\nsigma_ou &lt;- 100\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_100 &lt;- N\n\nsigma_ou &lt;- 250\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_250 &lt;- N\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlab('Time') +\n  ylab('N(t)') +\n  geom_line(mapping = aes(y=N_100, colour=\"σ=100\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_250, colour=\"σ=250\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_0, colour=\"σ=0\"),linewidth = 1) +\n  scale_colour_manual(\"Functions\",values=c(\"black\",\"darkgray\",\"darkviolet\"))\n\n\n\n\n\nThis is a very common process, so much it has a name: the Ornstein-Uhlenbeck process. Now, let’s calculate \\(DN\\). We have \\(a(X) = \\theta(\\mu - X)\\) and \\(b(x) = \\sigma\\), so it’s not a simple Ito process that only depends on time. We better start from those before tackling the Ornstein-Uhlenbeck process. If we remember that we can split the integrals as \\(\\int_0^t... dW_t=\\sum_{i=1}^n{...(W_{t_i}-W_{t_{i-1}})}\\), then we can transform a classical Ito process \\(X_t\\) into something we can easily apply chain and product rules:\n\\[\n\\begin{aligned}\nX_t &= \\sum_{i=1}^n \\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i}(W_{t_i}-W_{t_{i-1}}) \\\\\nD_rX_t &= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n D_r[\\sigma_{t_i}\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i} \\cdot 1_{[t_{i-1},t_{i}]}(r) + \\sum_{i=1}^n D_r(\\sigma_{t_i})\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\int_0^t D_r\\mu_s\\,ds + \\sigma_r 1_{[0,t]}(r) + \\int_0^t D_r\\sigma_s\\,dW_s \\\\\n\\end{aligned}\n\\]\nIt looks messy, but things are what we expect: \\(t\\) is the terminal value of both integrals, \\(s\\) is the variable we use to integrate from \\(0\\) to \\(t\\), and \\(r\\) is the variable we introduced with the Malliavin Derivative. See that it makes sense: the influence of \\(\\sigma\\) in the Ito process is the same along the whole Ito process path.\nNow, we can use a similar argument for the number of trouts in the lake, which followed an Ornstein-Uhlenbeck process. Given that \\(\\mu_s\\) and \\(\\sigma_s\\) are now \\(a(s,X_s)\\) and \\(b(s,X_s)\\), we apply chain and product rules as above to arrive to:\n\\[\nD_rX_t = \\int_r^t \\frac{\\partial a}{\\partial x}(s, X_s)\\,D_rX_s\\,ds + b(r,X_r)1_{[0,t]}(r) + \\int_r^t \\frac{\\partial b}{\\partial x}(s, X_s)\\,D_rX_s\\,dW_s \\\\\n\\]\nNow, we know from above that \\(\\frac{\\partial a}{\\partial x} = -\\theta\\) and \\(\\frac{\\partial b}{\\partial x} = 0\\), so we get:\n\\[\n\\begin{aligned}\nD_rN_t &= \\int_r^t (-\\theta)\\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= -\\theta\\int_r^t \\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= \\sigma\\,e^{-\\theta(t-r)}\n\\end{aligned}\n\\]\nIn the case above, we arrive at a neat expression that tell us something interesting: the effect of a perturbation on the number of trouts is exponentially smaller if \\(r&lt;&lt;t\\). This makes sense: the population of trouts \\(N\\) wants to be close to \\(\\mu\\) and the population from a distant past is irrelevant. It also tells us that there’s no randomness in the fluctuation because it doesn’t depend on any random variable, such as \\(W_t\\).\nFinally, we lucked out above. The expression for \\(D_rN_t\\) is simple, so we could write an analytic expression for it. If it were more convoluted, it’s probably better to estimate a solution. Alos (2021) does a great job showcasing the above."
  },
  {
    "objectID": "clarkocone.html#clark-ocone-haussman-formula",
    "href": "clarkocone.html#clark-ocone-haussman-formula",
    "title": "Applications and in-depth cases",
    "section": "",
    "text": "Let’s see a relatively simple application with profound implications, following Friz (2002) entirely. Let’s consider this function:\n\\[\nF(t) = e^{\\int_0^t h\\,dB - \\frac{1}{2}\\int_0^t{h^2}d\\lambda}\n\\]\nThis function is an exponential martingale, that is, \\(\\mathbb{E}_s[F(t)]=F(s)\\). We now take \\(F(1) = \\mathcal{E}(h)\\) and we now calculate \\(DF\\) :\n\\[\n\\begin{aligned}\nD_tF &= e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot D_t(e^{\\int_0^1 h\\,dB}) \\\\\n&= \\underbrace{e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot e^{\\int_0^1 h\\,dB}}_{F} \\cdot h(t) \\\\\n&= Fh(t)\n\\end{aligned}\n\\]\nNow, this is only valid at \\(t=1\\), but we use the expectation operator and martingale property to get the values at a previous time. We will call \\(\\mathcal{F}_s\\) the filtration up to time \\(s\\), and it’s the way we call the “history” or “information” known up to time \\(s\\), and then:\n\\[\n\\begin{aligned}\n\\mathbb{E}[D_t F | \\mathcal{F}_t] &= \\mathbb{E}[F(1)h(t)|\\mathcal{F_t}] \\\\\n&=h(t) \\mathbb{E}[F(1)|\\mathcal{F_t}] \\\\\n&=h(t) F(t)\n\\end{aligned}\n\\]\nNow, we pull everything together. This martingale \\(F(t)\\) is the solution of the (stochastic) differential equation \\(dF(t) = h(t)F(t)dB_t\\), when \\(F(0)=1=\\mathbb{E}[F]\\). Replacing with the above expression we get:\n\\[\n\\begin{aligned}\nF(t) &= \\mathbb{E}[F] + \\int_0^1  h(t)F(t) dB_t \\\\\n&= \\mathbb{E}[F] + \\int_0^1 \\mathbb{E}[D_t F | \\mathcal{F_t}] dB_t\n\\end{aligned}\n\\]\nThis is the Clark-Ocone formula, which is an explicit formula for the Martingale Representation Theorem. The Malliavin derivative is the key ingredient to have an analytic expression and it’s the main reason one would care about it. What this is telling us is that any random variable indexed by time \\(F_t\\) can be split into a sum of a “deterministic” portion, the expected value, and a martingale that fluctuates around it.\nWe can apply this to the Ornstein-Uhlenbeck process for our trouts. We know from before that \\(D_rN_t = \\sigma\\,e^{-\\theta(t-r)}\\). Notice that there’s no \\(W_t\\), so the expected value is just the Malliavin derivative. We could estimate the value of \\(\\mathbb{E}[N]\\) or try to solve the (stochastic) differential equation, but given that the process already has a known solution, I’ll go ahead and add it. Here’s in all its splendor:\n\\[\n\\begin{aligned}\nN(t) &= \\mathbb{E}[N] + \\int_0^t \\mathbb{E_r}[D_r N_t] dW_r \\\\\n&= \\underbrace{X_0e^{-\\theta t} + \\mu(1-e^{-\\theta t})}_{Deterministic} + \\underbrace{\\int_0^t \\sigma\\,e^{-\\theta(t-r)}\\,dW_r}_{Martingale} \\\\\n\\end{aligned}\n\\]\nWhy do we care about this? Well, for once, if we wanted to simulate different paths of our fish population \\(N\\), we only need to simulate the martingale portion, and the deterministic portion is only calculated once. Secondly, we can use the Clark-Ocone formula to directly calculate the variance for \\(N\\), without knowing the full analytic solution. Indeed, remember that \\(\\mathbb{Var}[N]=\\mathbb{E}[N-\\mathbb{E}[N]]^2\\), so then, using Ito’s Isometry:\n\\[\n\\begin{aligned}\n\\mathbb{Var}[N]&=\\mathbb{E}\\left[\\left(\\int_0^t \\mathbb{E_r}[D_r N_t] dW_r\\right)^2\\right] \\\\\n&=\\mathbb{E}\\left[\\int_0^t \\left(\\sigma\\,e^{-\\theta(t-r)}\\right)^2dr\\right] \\\\\n&=\\sigma^2\\mathbb{E}\\left[\\int_0^t e^{2\\theta(r-t)}dr\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\mathbb{E}\\left[1-e^{-2\\theta t}\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\left(1-e^{-2\\theta t}\\right)\n\\end{aligned}\n\\]\nNotice that this works for any variable: you only need the Malliavin Derivative to get the variance. We see above that:\n\nOur trout population \\(N\\) in the long term (\\(t \\rightarrow \\infty\\)) will be a process moving around \\(\\mu\\) with a constant variance \\(\\frac{\\sigma^2}{2\\theta}\\)\nVariance at the time of trout introduction (\\(t \\approx 0\\)) is very small because the growth of \\(N\\), trying to reach \\(\\mu\\) as soon as possible, dominates over the noise\nA large \\(\\theta\\) will not only make the long term variance arrive sooner, it will also prevent large deviations from \\(\\mu\\)\n\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. “An Introduction to Malliavin Calculus.” In. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "integrationbyparts.html",
    "href": "integrationbyparts.html",
    "title": "Integration by parts",
    "section": "",
    "text": "We begin our journey by talking about a trick that could be seen as the reverse for the product rule for derivatives. We will use it to develop an entirely new way to solve problems by minimizing a function of functions. FInally, this will follow Wikipedia contributors (2023), which has the classical derivation, with some pieces added by me.\n\n\nWe will use the \\('\\) symbol to indicate a derivative with respect to \\(x\\). If you know the basics of derivation, you recall that:\n\\[\n\\left( f(x)g(x)\\right)'=f'(x)g(x)+f(x)g'(x)\n\\]\nNow, let’s integrate on both sides:\n\\[\n\\begin{aligned}\n\\int\\left( f(x)g(x)\\right)'dx&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx \\\\\nf(x)g(x)&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx\n\\end{aligned}\n\\]\nIf we rename \\(u=f(x)\\) and \\(dv = g'(x)dx\\), then we get the familiar expressions for indefinite and definite integrals:\n\\[\n\\begin{aligned}\n\\int u\\,dv &= uv -\\int v\\,du \\\\\n\\int_a^b u\\,dv &= \\left.{uv}\\right|_a^b -\\int_a^bv\\,du\n\\end{aligned}\n\\]\nFinally, imagine that the functions vanish on the extremes \\(a\\) and \\(b\\). That is, \\(u(b)v(b)-u(a)v(a)=0\\). In that case, you can simplify even further:\n\\[\n\\int u\\,dv = -\\int v\\,du\n\\]\n\n\n\nMalliavin Calculus is sometimes called an extension of calculus of variations to stochastic processes. What does that even means? Let’s deal with the first part.\n\n\nI’ll assume that you know the basics of calculus. That means you can solve problems like this: let’s say we have a function \\(f\\) and we want to know the value of \\(x\\) where \\(f\\) attains its minimum:\n\\[\n\\min{f(x)}=x^2-4x+5\n\\]\nTo solve it, we take the derivative, make it equal to zero, and obtain the arguments that make it so.\n\\[\n\\begin{aligned}\nf'(x)=2x-4 &= 0 \\\\\n2x &= 4 \\\\\nx &= 2\n\\end{aligned}\n\\]\nWhich means that \\(\\min{f(x)}=f(2)=2^2-4*2+5=1\\).\nThis approach works great when you try to minimize a function value over the reals, \\(f: \\mathbb{R} \\to \\mathbb{R}\\), or in general for multivariate functions, \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\).\nBut let’s say we want to find the function \\(y=f(x)\\) that minimizes an expression. We don’t know how that function looks, or want to impose any preconceived notions like being a polynomial or a sum of sine/cosine pairs. What do we do, then?\nFrom now on, it’s autopilot from any course (I’ll be using the Wikipedia article as the baseline). The first step is to define a “function of functions” as the starting point for minimization, and that function is essentially the integral like this:\n\\[\nJ[y]=\\int^{x_2}_{x_1} L(x,y,y')dx \\\\\n\\]\nTo keep things grounded on reality, we will use the classical example of finding the function that represents the smallest distance between two points, \\(a\\) and \\(b\\). Starting with a “coarse grain” case with deltas, we are minimizing the sum of all the little changes in the path between those two points using Pythagoras:\n\\[\n\\min\\sum^n_{i=1}\\sqrt{ (\\Delta x_i)^2+(\\Delta y_i)^2}\n\\]\nAs little changes become infinitesimal, and with some extreme abuse of notation, we switch to an integral and obtain the expression for \\(L\\):\n\\[\n\\begin{aligned}\n\\int^{b}_{a} \\sqrt{{dx}^2+{dy}^2}\n& = \\int^{b}_{a} \\sqrt{{(dx)}^2\\left ( 1+\\left({\\frac{dy}{dx}}\\right)^2\\right)} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\sqrt{(dx)^2} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\,dx \\\\\n& = \\int^{b}_{a}L(y')\\,dx\\\\\n\\end{aligned}\n\\]\nNow, we will introduce a generic function \\(\\eta(x)\\) called the variation. This function represents a perturbation and the only requirement that we will impose on it is that \\(\\eta(a)=\\eta(b)=0\\). We can assume that \\(f(x)=y\\) is the solution and \\(\\eta\\) is the deviation from the solution, which we can multiply by a small number \\(\\varepsilon\\). We can then define a function over \\(\\varepsilon\\), \\(\\Phi(\\varepsilon)= J[f + \\varepsilon *\\eta]\\), so that \\(\\Phi(0)=f\\), our solution.\nThe trick here is that now, instead of minimizing something that depends on unknown functions, which we can’t even start to comprehend, we minimize something that depends on a number, \\(\\varepsilon\\). Not only that, we constructed \\(\\varepsilon\\) and \\(\\eta\\) so that we know, in advance, that the function we are looking for, the solution, is at \\(\\Phi(\\varepsilon=0)=J[f]\\) and \\(\\Phi'(0)=0\\) because it’s the minimum. Absolute genius.\n\\[\n\\Phi'(0)=0=\\left.\\frac{d\\Phi}{d\\varepsilon}\\right|_{\\varepsilon=0}=\\int^{b}_{a}\\left. \\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon=0} dx\n\\]\nWe take the total derivative of \\(\\Phi\\) over \\(\\varepsilon\\) , just like before, but now \\(y=f+\\varepsilon\\eta\\) and \\(y'=f'+\\varepsilon\\eta'\\):\n\\[\n\\begin{aligned}\n\\frac{dL}{d\\varepsilon}\n& = \\frac{\\partial L}{\\partial x}\\underbrace{\\frac{dx}{d\\varepsilon}}_{=0} + \\frac{\\partial L}{\\partial y}\\underbrace{\\frac{dy}{d\\varepsilon}}_{=\\eta} + \\frac{\\partial L}{\\partial y'}\\underbrace{\\frac{dy'}{d\\varepsilon}}_{=\\eta'}\\\\\n& = \\frac{\\partial L}{\\partial y}\\eta + \\frac{\\partial L}{\\partial y'}\\eta'\\\\\n\\end{aligned}\n\\]\nThis looks meaningless, but now comes the magic:\n\\[\n\\begin{aligned}\n\\int_{a}^{b} \\left.\\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon = 0} dx\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta + \\frac{\\partial L}{\\partial f'} \\eta'\\right)\\, dx \\\\\n&  = \\int_{a}^{b} \\frac{\\partial L}{\\partial f} \\eta \\, dx + \\underbrace{\\left.\\frac{\\partial L}{\\partial f'} \\eta \\right|_{a}^{b}}_{=0} - \\int_{a}^{b} \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\, dx \\\\\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta - \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right)\\, dx\\\\\n0 &= \\int_{a}^{b} \\eta (x) \\left(\\frac{\\partial L}{\\partial f} - \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right) \\, dx \\\\\n\\end{aligned}\n\\]\nWe start from \\(\\Phi'(0)\\) and we do an integration by parts. This is crucial, without that operation this whole scheme falls apart. We also know that \\(\\eta(a)=\\eta(b)=0\\), so that term vanishes. Joining terms and taking a common factor we reach our final conclusion. The final piece of magic is realizing that this integral is zero, no matter what \\(\\eta(x)\\) we pick. By the Fundamental Lemma of Calculus of Variations, that leaves only one possibility, and it’s so important that it’s called the Euler-Lagrange equation:\n\\[\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}=0\n\\]\nWhatever the solution function \\(f\\) is, it must fulfill that condition.\n\n\n\nWhy is it helpful? Let’s return to the shortest path between two points, and I’m using \\(f=y\\) interchangeably. When we left off, we had arrived at:\n\\[\nL(f') = \\sqrt{1+(f')^2}\n\\]\nWe apply the Euler-Lagrange equation and we see where it leads us. What makes this example super clean is that there’s no explicit \\(f\\) in it, only \\(f'\\), so we end up with a very small formula:\n\\[\n\\begin{aligned}\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}&=0\\\\\n- \\frac{d}{dx} \\ \\frac{f'(x)} {\\sqrt{1 + [f'(x)]^2}} \\ &= 0\\\\\n\\end{aligned}\n\\]\nIf the derivative is zero, then we can integrate that and the result is an unknown constant \\(c&lt;1\\). We do some minor algebra, plus an integration at the end, and we are done!\n\\[\n\\begin{aligned}\n\\frac{f'(x)}{\\sqrt{1+[f'(x)]^2}} &= c \\\\\n\\frac{[f'(x)]^2}{1+[f'(x)]^2} &= c^2 \\\\\n{[f'(x)]}^2 &= c^2 + c^2{[f'(x)]}^2 \\\\\n{[f'(x)]}^2 &= \\frac{c^2}{1-c^2} \\\\\nf'(x) &= \\sqrt{\\frac{c^2}{1-c^2}} = m \\\\\nf(x) &= mx+b\n\\end{aligned}\n\\]\nThe function with the shortest path between two points is a straight line, and the only thing we needed to know is how the distance between two points is calculated to get a closed-form, analytic solution.\n\n\n\n\n\nWikipedia contributors. 2023. “Calculus of Variations — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Calculus_of_variations."
  },
  {
    "objectID": "integrationbyparts.html#sketch-for-deriving-the-integration-by-parts-formula",
    "href": "integrationbyparts.html#sketch-for-deriving-the-integration-by-parts-formula",
    "title": "Integration by parts",
    "section": "",
    "text": "We will use the \\('\\) symbol to indicate a derivative with respect to \\(x\\). If you know the basics of derivation, you recall that:\n\\[\n\\left( f(x)g(x)\\right)'=f'(x)g(x)+f(x)g'(x)\n\\]\nNow, let’s integrate on both sides:\n\\[\n\\begin{aligned}\n\\int\\left( f(x)g(x)\\right)'dx&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx \\\\\nf(x)g(x)&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx\n\\end{aligned}\n\\]\nIf we rename \\(u=f(x)\\) and \\(dv = g'(x)dx\\), then we get the familiar expressions for indefinite and definite integrals:\n\\[\n\\begin{aligned}\n\\int u\\,dv &= uv -\\int v\\,du \\\\\n\\int_a^b u\\,dv &= \\left.{uv}\\right|_a^b -\\int_a^bv\\,du\n\\end{aligned}\n\\]\nFinally, imagine that the functions vanish on the extremes \\(a\\) and \\(b\\). That is, \\(u(b)v(b)-u(a)v(a)=0\\). In that case, you can simplify even further:\n\\[\n\\int u\\,dv = -\\int v\\,du\n\\]"
  },
  {
    "objectID": "integrationbyparts.html#calculus-of-variations",
    "href": "integrationbyparts.html#calculus-of-variations",
    "title": "Integration by parts",
    "section": "",
    "text": "Malliavin Calculus is sometimes called an extension of calculus of variations to stochastic processes. What does that even means? Let’s deal with the first part.\n\n\nI’ll assume that you know the basics of calculus. That means you can solve problems like this: let’s say we have a function \\(f\\) and we want to know the value of \\(x\\) where \\(f\\) attains its minimum:\n\\[\n\\min{f(x)}=x^2-4x+5\n\\]\nTo solve it, we take the derivative, make it equal to zero, and obtain the arguments that make it so.\n\\[\n\\begin{aligned}\nf'(x)=2x-4 &= 0 \\\\\n2x &= 4 \\\\\nx &= 2\n\\end{aligned}\n\\]\nWhich means that \\(\\min{f(x)}=f(2)=2^2-4*2+5=1\\).\nThis approach works great when you try to minimize a function value over the reals, \\(f: \\mathbb{R} \\to \\mathbb{R}\\), or in general for multivariate functions, \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\).\nBut let’s say we want to find the function \\(y=f(x)\\) that minimizes an expression. We don’t know how that function looks, or want to impose any preconceived notions like being a polynomial or a sum of sine/cosine pairs. What do we do, then?\nFrom now on, it’s autopilot from any course (I’ll be using the Wikipedia article as the baseline). The first step is to define a “function of functions” as the starting point for minimization, and that function is essentially the integral like this:\n\\[\nJ[y]=\\int^{x_2}_{x_1} L(x,y,y')dx \\\\\n\\]\nTo keep things grounded on reality, we will use the classical example of finding the function that represents the smallest distance between two points, \\(a\\) and \\(b\\). Starting with a “coarse grain” case with deltas, we are minimizing the sum of all the little changes in the path between those two points using Pythagoras:\n\\[\n\\min\\sum^n_{i=1}\\sqrt{ (\\Delta x_i)^2+(\\Delta y_i)^2}\n\\]\nAs little changes become infinitesimal, and with some extreme abuse of notation, we switch to an integral and obtain the expression for \\(L\\):\n\\[\n\\begin{aligned}\n\\int^{b}_{a} \\sqrt{{dx}^2+{dy}^2}\n& = \\int^{b}_{a} \\sqrt{{(dx)}^2\\left ( 1+\\left({\\frac{dy}{dx}}\\right)^2\\right)} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\sqrt{(dx)^2} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\,dx \\\\\n& = \\int^{b}_{a}L(y')\\,dx\\\\\n\\end{aligned}\n\\]\nNow, we will introduce a generic function \\(\\eta(x)\\) called the variation. This function represents a perturbation and the only requirement that we will impose on it is that \\(\\eta(a)=\\eta(b)=0\\). We can assume that \\(f(x)=y\\) is the solution and \\(\\eta\\) is the deviation from the solution, which we can multiply by a small number \\(\\varepsilon\\). We can then define a function over \\(\\varepsilon\\), \\(\\Phi(\\varepsilon)= J[f + \\varepsilon *\\eta]\\), so that \\(\\Phi(0)=f\\), our solution.\nThe trick here is that now, instead of minimizing something that depends on unknown functions, which we can’t even start to comprehend, we minimize something that depends on a number, \\(\\varepsilon\\). Not only that, we constructed \\(\\varepsilon\\) and \\(\\eta\\) so that we know, in advance, that the function we are looking for, the solution, is at \\(\\Phi(\\varepsilon=0)=J[f]\\) and \\(\\Phi'(0)=0\\) because it’s the minimum. Absolute genius.\n\\[\n\\Phi'(0)=0=\\left.\\frac{d\\Phi}{d\\varepsilon}\\right|_{\\varepsilon=0}=\\int^{b}_{a}\\left. \\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon=0} dx\n\\]\nWe take the total derivative of \\(\\Phi\\) over \\(\\varepsilon\\) , just like before, but now \\(y=f+\\varepsilon\\eta\\) and \\(y'=f'+\\varepsilon\\eta'\\):\n\\[\n\\begin{aligned}\n\\frac{dL}{d\\varepsilon}\n& = \\frac{\\partial L}{\\partial x}\\underbrace{\\frac{dx}{d\\varepsilon}}_{=0} + \\frac{\\partial L}{\\partial y}\\underbrace{\\frac{dy}{d\\varepsilon}}_{=\\eta} + \\frac{\\partial L}{\\partial y'}\\underbrace{\\frac{dy'}{d\\varepsilon}}_{=\\eta'}\\\\\n& = \\frac{\\partial L}{\\partial y}\\eta + \\frac{\\partial L}{\\partial y'}\\eta'\\\\\n\\end{aligned}\n\\]\nThis looks meaningless, but now comes the magic:\n\\[\n\\begin{aligned}\n\\int_{a}^{b} \\left.\\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon = 0} dx\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta + \\frac{\\partial L}{\\partial f'} \\eta'\\right)\\, dx \\\\\n&  = \\int_{a}^{b} \\frac{\\partial L}{\\partial f} \\eta \\, dx + \\underbrace{\\left.\\frac{\\partial L}{\\partial f'} \\eta \\right|_{a}^{b}}_{=0} - \\int_{a}^{b} \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\, dx \\\\\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta - \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right)\\, dx\\\\\n0 &= \\int_{a}^{b} \\eta (x) \\left(\\frac{\\partial L}{\\partial f} - \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right) \\, dx \\\\\n\\end{aligned}\n\\]\nWe start from \\(\\Phi'(0)\\) and we do an integration by parts. This is crucial, without that operation this whole scheme falls apart. We also know that \\(\\eta(a)=\\eta(b)=0\\), so that term vanishes. Joining terms and taking a common factor we reach our final conclusion. The final piece of magic is realizing that this integral is zero, no matter what \\(\\eta(x)\\) we pick. By the Fundamental Lemma of Calculus of Variations, that leaves only one possibility, and it’s so important that it’s called the Euler-Lagrange equation:\n\\[\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}=0\n\\]\nWhatever the solution function \\(f\\) is, it must fulfill that condition.\n\n\n\nWhy is it helpful? Let’s return to the shortest path between two points, and I’m using \\(f=y\\) interchangeably. When we left off, we had arrived at:\n\\[\nL(f') = \\sqrt{1+(f')^2}\n\\]\nWe apply the Euler-Lagrange equation and we see where it leads us. What makes this example super clean is that there’s no explicit \\(f\\) in it, only \\(f'\\), so we end up with a very small formula:\n\\[\n\\begin{aligned}\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}&=0\\\\\n- \\frac{d}{dx} \\ \\frac{f'(x)} {\\sqrt{1 + [f'(x)]^2}} \\ &= 0\\\\\n\\end{aligned}\n\\]\nIf the derivative is zero, then we can integrate that and the result is an unknown constant \\(c&lt;1\\). We do some minor algebra, plus an integration at the end, and we are done!\n\\[\n\\begin{aligned}\n\\frac{f'(x)}{\\sqrt{1+[f'(x)]^2}} &= c \\\\\n\\frac{[f'(x)]^2}{1+[f'(x)]^2} &= c^2 \\\\\n{[f'(x)]}^2 &= c^2 + c^2{[f'(x)]}^2 \\\\\n{[f'(x)]}^2 &= \\frac{c^2}{1-c^2} \\\\\nf'(x) &= \\sqrt{\\frac{c^2}{1-c^2}} = m \\\\\nf(x) &= mx+b\n\\end{aligned}\n\\]\nThe function with the shortest path between two points is a straight line, and the only thing we needed to know is how the distance between two points is calculated to get a closed-form, analytic solution.\n\n\n\n\n\nWikipedia contributors. 2023. “Calculus of Variations — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/wiki/Calculus_of_variations."
  },
  {
    "objectID": "malliavinderivative.html",
    "href": "malliavinderivative.html",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "Now that we have established that Cameron-Martin directions allow us to change the integrals under Gaussian measures, we are ready to define the Malliavin derivative. We can do it from two angles:\n\nWe can talk about polynomial chaos, and then arrive to the derivative\nWe define the derivative, and not refer to polynomial chaos at all\n\nWe will follow the second approach for pedagogical reasons, collecting all the things we have learned. After that, we will follow Friz (2002) and Alos (2021) to bring all down to Earth.\n\n\nWe have accumulated a ton of knowledge. It’s time for us to approach the point of this entire webpage. When we asked the Question, we mentioned that the derivative of a random variable that follows a Brownian motion with respect to time can’t be calculated, that was the whole point: what kind of derivative can we calculate?\nWe will consider a Cameron-Martin direction of \\(\\hat{h}(\\tau)=\\int_0^\\tau h\\,dt\\). Moreover, \\(\\hat{h}\\in\\hat{H}\\) , the Cameron-Martin space. This definition allow us to have a derivative over time for the direction, so \\(\\frac{\\partial \\hat{h}(\\tau)}{\\partial \\tau}=h\\) , with \\(h\\in H = L^2[0,1]\\), the space of functions that are continuous between 0 and 1, and that allow a 2-norm1.\nBrownian motion paths up to \\(\\tau\\) will be denoted as \\(\\omega(\\tau)\\). The function \\(1_{[0,\\tau]}\\) is a function that’s \\(1\\) in the indicated interval and \\(0\\) everywhere else, behaving like a filter. Finally, we will define a function like \\(W(1_{[0,\\tau]})\\) as an Ito integral of the filter . We will also use \\(B_t\\) and \\(dB_t\\) to reference Brownian motions, alongside \\(W_t\\) and \\(dW_t\\).\nWe will also consider a polynomial function2 \\(f\\) that takes \\(n\\) Brownian motions as variables, each stopping at a different time. Two Brownian motions from \\(0\\) to \\(t\\) are essentially the same, even if their paths are different. So, each Brownian motion will go from \\(0\\) to \\(t_1\\) , \\(t_2\\), … \\(t_n\\) This function \\(f\\) is for the moment pretty useless and basic. We will find its use and extensions later.\nNow, we will do something just like in the section for calculus of variations. Let’s have \\(f(\\omega + \\varepsilon \\hat{h})\\). This means that we are moving each of the \\(n\\) Brownian motion path a bit along a Cameron-Martin direction, so all is good. Finally, we will take the derivative with respect to \\(\\varepsilon\\) , and we will evaluate the derivative at \\(\\varepsilon = 0\\). The Brownian motions, which can’t be derived, won’t be touched because they don’t depend on \\(\\varepsilon\\).\nAnd here’s the final result:\n\\[\n\\begin{aligned}\n\\left.\\frac{d}{d\\varepsilon}F(\\omega + \\varepsilon \\hat{h})\\right|_{\\varepsilon=0} &=\\left[\\sum_{i=1}^n\\partial_i f(\\omega(t_1)+ \\varepsilon \\hat{h},\\omega(t_2)+ \\varepsilon \\hat{h},\\,...\\,,\\omega(t_n)+ \\varepsilon \\hat{h})\\int_0^{t_i}h\\,d\\lambda \\right]_{\\varepsilon=0} \\\\\n&=\\sum_{i=1}^n\\partial_i f(\\omega(t_1),\\omega(t_2),\\,...\\,,\\omega(t_n))\\int_0^{t_i}h\\,d\\lambda \\\\\n&=\\langle DF,h \\rangle_H\n\\end{aligned}\n\\]\nWe define \\(DF\\) as:\n\\[\nDF = \\sum_i\\partial_if(W(1_{[0,\\tau_1]}),\\,...\\,,W(1_{[0,\\tau_n]}))1_{[0,\\tau_i]}\n\\]\nOr its alternative extension:\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))h_i\n\\]\nmaking \\(DF\\) an \\(H\\)-valued random variable.\n\n\n\nThis \\(D\\) is the Malliavin Derivative. It is a linear operator (like the ones we saw before) and it’s applied to \\(F\\). It means that if you have a function \\(F\\) with variables composed of these Brownian motions multiplied by these \\(h_i\\) functions, then you can apply this derivative definition.\nThis \\(F\\) looks very limited right now, but if you could represent, approximate or find an equivalence between the random variable you are interested in and a function like \\(F\\), then you could apply the derivative to the equivalence. The theory is concerned with finding those connections, we won’t bother to do that here.\nAt this point, the collection of \\(h_i\\) functions are a theoretical requirement and seem pulled out of thin air. For one, they aren’t more arbitrary than the displacement \\(h\\) from the classical derivative definition \\(\\lim_{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}\\). As we move forward, we will select the \\(h_i \\in H\\) that will be suitable for our purposes. More theoretical sources may establish that \\(h_i\\) are orthonormal (or be made orthonormal), especially under an inner product with a Gaussian weight. Instead, we will follow the simplest, default choice: we will use the single function \\(h=1_{[0,1]}\\), that is, a function that’s \\(1\\) on the interval and \\(0\\) elsewhere. This helps when the function is inside an integral because it “cuts” or “filters” the integration domain, like in this example:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x,t)\\cdot1_{[0,1]}(x)\\,dx = \\int_0^1f(x,t)\\,dx\n\\]\nA second question is whether the \\(\\left[ 0 , 1 \\right]\\) interval is a fundamental limit or if we can extend this to at least \\(\\left[0,T\\right]\\), which is what we see in common stochastic processes. All authors focusing on the theoretical aspects of the derivative stay in that interval, seemingly treating \\(1\\) as a conventional limit. On the other hand, Alos (2021) extends it. So, from now on, we use \\(h = 1_{[0,T]}\\) or \\(h = 1_{[0,1]}\\) based purely on convenience.\n\n\n\nNow, let’s start with a very simple example. Let’s calculate the Malliavin derivative of a Wiener process/Brownian motion:\n\\[\nF=W(h)=\\int_0^1h\\,dB\n\\]\nLet \\(h\\) be as we defined above, a function of \\(L^2\\) in the interval \\(\\left[0,1\\right]\\). In this case, the Malliavin derivative is:\n\\[\nDF=D(W(h))=h\n\\]\nHere’s a good rule-of-thumb: it’s as if we did \\(\\frac{\\partial F}{\\partial W}\\cdot h\\) instead of \\(\\frac{\\partial F}{\\partial t}\\) (which we know that we can’t do). We are seeing how much the function changes as an underlying Brownian motion changes (on a Cameron-Martin direction). Here’s a plot of how different choices of \\(h(t)\\) and a sample path for \\(W(h(t))\\) look like:\n\n\nCode\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndBt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\n\n# Left\nh_1 &lt;- Vectorize(function(x) 1)\nh_hat_1 &lt;- cumsum(h_1(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_1, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_1(t), colour = \"h = 1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCode\n# Middle\nh_2 &lt;- Vectorize(function(x) x)\nh_hat_2 &lt;- cumsum(h_2(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_2, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_2(t), colour = \"h = t\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCode\n# Right\nh_3 &lt;- Vectorize(function(x) x**2 - 1)\nh_hat_3 &lt;- cumsum(h_3(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_3, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_3(t), colour = \"h = t²-1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nThe simple case above also means that we can rewrite our original definition as\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))D(W(h_i))\n\\]\nwhich looks like a normal chain rule. I’m not going to prove it, but the product rule is also exactly like what we expect:\n\\[\nD(FG) = FD(G) + GD(F)\n\\]\nNow, we will do another simple example, a Brownian motion squared:\n\\[\nF(t)=(W_t)^2\n\\]\nIn this case, we use \\(h(s)=1_{[0,t]}(s)\\). See that there are actually two time-related variables in place: one is the original \\(t\\) that \\(F(t)\\) refers to, and the second one is the one introduced by the Malliavin derivative, which we will call \\(s\\) . With that in mind, we are ready to provide an answer:\n\\[\nD_sF=2\\,W_t \\, (DW_t)=2\\,W_t\\,h=2\\,W_t\\,1_{[0,t]}(s)\n\\]\nThere are two things to note here. First of all, the derivative takes non-zero values only when \\(0&lt;s&lt;t\\), and this makes sense: we don’t expect the function \\(F\\) to change beyond the time \\(t\\) where it’s evaluated. Secondly, this also means that when we plotted \\(W(h(t))\\) and \\(h(t)\\) together, it was a bit fake because we were assuming \\(s=t\\) for the sake of drawing it. Even so, I think that assumption allows us to see there’s a connection between the Malliavin derivative and the “instantaneous variance” or volatility of the process: the closer the derivative is to \\(0\\), the perturbations or movements are smaller. I’ll plot now a sample path for \\(F\\) and \\(DF\\), with \\(t \\in [0,1]\\) and \\(s=t\\) (which, again, isn’t the full picture, but I find it useful to connect the dots):\n\n\nCode\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndWt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\nWt &lt;- cumsum(dWt)\nf &lt;- Wt**2\nDf &lt;- 2*Wt\n\n# Plot\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y = f, colour=\"W(t)²\"),linetype = 2) + \n  geom_line(mapping = aes(y = Df, colour=\"DW(s=t)\"), linewidth = 0.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\n\n\n\nWe mentioned that linear operators come with a companion, adjoint operator. Malliavin derivatives aren’t the exception, and given that we defined \\(D\\) with an inner product and an \\(h\\) function to support it as in \\(\\langle DF, h \\rangle_H\\), we will look for an adjoint operator, which we call \\(\\delta\\), so that:\n\\[\n\\langle DF, h \\rangle_H = \\langle F, \\delta(h)\\rangle_{{R}^{\\,n}}\n\\]\nWe can find it by doing a bit of manipulation, taking some shortcuts here and relinquishing some mathematical rigor. From the definition, above, and assuming \\(h=h_1\\), we will take the expected value of the inner product, do integration by parts and some replacements, and we get:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[{\\langle DF, h \\rangle_H}\\right] &= \\mathbb{E}\\left[{\\sum_i \\partial_i f \\langle h_i, h \\rangle_H}\\right] \\\\\n&= \\int_{\\mathbb{R}^n} \\underbrace{\\partial_1 f(x)}_{dv}(2\\pi)^{-n/2}\\underbrace{e^{-\\|x\\|/2}}_{u} dx \\\\\n&= -\\int_{\\mathbb{R}^n} f(x) (-x_1) \\underbrace{(2\\pi)^{-n/2}e^{-\\|x\\|/2} dx}_{\\text{Gaussian measure}} \\\\\n&= \\int_{\\mathbb{R}^n} x_1 f(x) d\\mu_1 \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h_1)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\int_0^1 h dB}\\right]\n\\end{aligned}\n\\]\nWhat this means is that the expected value of the random variable \\(DF\\) measured using the function \\(h\\) between \\(0\\) and \\(1\\) as a ruler, is the same as the expected value of \\(F\\) multiplied by that integral of \\(h\\) on the right. We are implying that the \\(\\delta\\) operator is that integral. This is called the Skorohod integral, and it coincides with an Ito integral for non-anticipative processes3:\n\\[\n\\delta(h) = \\int_0^1 h dB_t\n\\]\nBy now, you probably have noticed how common it is to flip integrals and derivatives using integration by parts. It’s almost like second nature with Malliavin Calculus.\n\n\n\nSo, we have finally arrived to a definition of the Malliavin Derivative. It has taken us a while, but now we are in a comfortable position to use it for something!\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. “An Introduction to Malliavin Calculus.” In. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "malliavinderivative.html#malliavin-derivative-building-blocks",
    "href": "malliavinderivative.html#malliavin-derivative-building-blocks",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "We have accumulated a ton of knowledge. It’s time for us to approach the point of this entire webpage. When we asked the Question, we mentioned that the derivative of a random variable that follows a Brownian motion with respect to time can’t be calculated, that was the whole point: what kind of derivative can we calculate?\nWe will consider a Cameron-Martin direction of \\(\\hat{h}(\\tau)=\\int_0^\\tau h\\,dt\\). Moreover, \\(\\hat{h}\\in\\hat{H}\\) , the Cameron-Martin space. This definition allow us to have a derivative over time for the direction, so \\(\\frac{\\partial \\hat{h}(\\tau)}{\\partial \\tau}=h\\) , with \\(h\\in H = L^2[0,1]\\), the space of functions that are continuous between 0 and 1, and that allow a 2-norm1.\nBrownian motion paths up to \\(\\tau\\) will be denoted as \\(\\omega(\\tau)\\). The function \\(1_{[0,\\tau]}\\) is a function that’s \\(1\\) in the indicated interval and \\(0\\) everywhere else, behaving like a filter. Finally, we will define a function like \\(W(1_{[0,\\tau]})\\) as an Ito integral of the filter . We will also use \\(B_t\\) and \\(dB_t\\) to reference Brownian motions, alongside \\(W_t\\) and \\(dW_t\\).\nWe will also consider a polynomial function2 \\(f\\) that takes \\(n\\) Brownian motions as variables, each stopping at a different time. Two Brownian motions from \\(0\\) to \\(t\\) are essentially the same, even if their paths are different. So, each Brownian motion will go from \\(0\\) to \\(t_1\\) , \\(t_2\\), … \\(t_n\\) This function \\(f\\) is for the moment pretty useless and basic. We will find its use and extensions later.\nNow, we will do something just like in the section for calculus of variations. Let’s have \\(f(\\omega + \\varepsilon \\hat{h})\\). This means that we are moving each of the \\(n\\) Brownian motion path a bit along a Cameron-Martin direction, so all is good. Finally, we will take the derivative with respect to \\(\\varepsilon\\) , and we will evaluate the derivative at \\(\\varepsilon = 0\\). The Brownian motions, which can’t be derived, won’t be touched because they don’t depend on \\(\\varepsilon\\).\nAnd here’s the final result:\n\\[\n\\begin{aligned}\n\\left.\\frac{d}{d\\varepsilon}F(\\omega + \\varepsilon \\hat{h})\\right|_{\\varepsilon=0} &=\\left[\\sum_{i=1}^n\\partial_i f(\\omega(t_1)+ \\varepsilon \\hat{h},\\omega(t_2)+ \\varepsilon \\hat{h},\\,...\\,,\\omega(t_n)+ \\varepsilon \\hat{h})\\int_0^{t_i}h\\,d\\lambda \\right]_{\\varepsilon=0} \\\\\n&=\\sum_{i=1}^n\\partial_i f(\\omega(t_1),\\omega(t_2),\\,...\\,,\\omega(t_n))\\int_0^{t_i}h\\,d\\lambda \\\\\n&=\\langle DF,h \\rangle_H\n\\end{aligned}\n\\]\nWe define \\(DF\\) as:\n\\[\nDF = \\sum_i\\partial_if(W(1_{[0,\\tau_1]}),\\,...\\,,W(1_{[0,\\tau_n]}))1_{[0,\\tau_i]}\n\\]\nOr its alternative extension:\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))h_i\n\\]\nmaking \\(DF\\) an \\(H\\)-valued random variable."
  },
  {
    "objectID": "malliavinderivative.html#what-did-just-happen",
    "href": "malliavinderivative.html#what-did-just-happen",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "This \\(D\\) is the Malliavin Derivative. It is a linear operator (like the ones we saw before) and it’s applied to \\(F\\). It means that if you have a function \\(F\\) with variables composed of these Brownian motions multiplied by these \\(h_i\\) functions, then you can apply this derivative definition.\nThis \\(F\\) looks very limited right now, but if you could represent, approximate or find an equivalence between the random variable you are interested in and a function like \\(F\\), then you could apply the derivative to the equivalence. The theory is concerned with finding those connections, we won’t bother to do that here.\nAt this point, the collection of \\(h_i\\) functions are a theoretical requirement and seem pulled out of thin air. For one, they aren’t more arbitrary than the displacement \\(h\\) from the classical derivative definition \\(\\lim_{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}\\). As we move forward, we will select the \\(h_i \\in H\\) that will be suitable for our purposes. More theoretical sources may establish that \\(h_i\\) are orthonormal (or be made orthonormal), especially under an inner product with a Gaussian weight. Instead, we will follow the simplest, default choice: we will use the single function \\(h=1_{[0,1]}\\), that is, a function that’s \\(1\\) on the interval and \\(0\\) elsewhere. This helps when the function is inside an integral because it “cuts” or “filters” the integration domain, like in this example:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x,t)\\cdot1_{[0,1]}(x)\\,dx = \\int_0^1f(x,t)\\,dx\n\\]\nA second question is whether the \\(\\left[ 0 , 1 \\right]\\) interval is a fundamental limit or if we can extend this to at least \\(\\left[0,T\\right]\\), which is what we see in common stochastic processes. All authors focusing on the theoretical aspects of the derivative stay in that interval, seemingly treating \\(1\\) as a conventional limit. On the other hand, Alos (2021) extends it. So, from now on, we use \\(h = 1_{[0,T]}\\) or \\(h = 1_{[0,1]}\\) based purely on convenience."
  },
  {
    "objectID": "malliavinderivative.html#examples",
    "href": "malliavinderivative.html#examples",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "Now, let’s start with a very simple example. Let’s calculate the Malliavin derivative of a Wiener process/Brownian motion:\n\\[\nF=W(h)=\\int_0^1h\\,dB\n\\]\nLet \\(h\\) be as we defined above, a function of \\(L^2\\) in the interval \\(\\left[0,1\\right]\\). In this case, the Malliavin derivative is:\n\\[\nDF=D(W(h))=h\n\\]\nHere’s a good rule-of-thumb: it’s as if we did \\(\\frac{\\partial F}{\\partial W}\\cdot h\\) instead of \\(\\frac{\\partial F}{\\partial t}\\) (which we know that we can’t do). We are seeing how much the function changes as an underlying Brownian motion changes (on a Cameron-Martin direction). Here’s a plot of how different choices of \\(h(t)\\) and a sample path for \\(W(h(t))\\) look like:\n\n\nCode\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndBt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\n\n# Left\nh_1 &lt;- Vectorize(function(x) 1)\nh_hat_1 &lt;- cumsum(h_1(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_1, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_1(t), colour = \"h = 1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCode\n# Middle\nh_2 &lt;- Vectorize(function(x) x)\nh_hat_2 &lt;- cumsum(h_2(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_2, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_2(t), colour = \"h = t\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCode\n# Right\nh_3 &lt;- Vectorize(function(x) x**2 - 1)\nh_hat_3 &lt;- cumsum(h_3(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_3, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_3(t), colour = \"h = t²-1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))\n\n\n\n\n\nThe simple case above also means that we can rewrite our original definition as\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))D(W(h_i))\n\\]\nwhich looks like a normal chain rule. I’m not going to prove it, but the product rule is also exactly like what we expect:\n\\[\nD(FG) = FD(G) + GD(F)\n\\]\nNow, we will do another simple example, a Brownian motion squared:\n\\[\nF(t)=(W_t)^2\n\\]\nIn this case, we use \\(h(s)=1_{[0,t]}(s)\\). See that there are actually two time-related variables in place: one is the original \\(t\\) that \\(F(t)\\) refers to, and the second one is the one introduced by the Malliavin derivative, which we will call \\(s\\) . With that in mind, we are ready to provide an answer:\n\\[\nD_sF=2\\,W_t \\, (DW_t)=2\\,W_t\\,h=2\\,W_t\\,1_{[0,t]}(s)\n\\]\nThere are two things to note here. First of all, the derivative takes non-zero values only when \\(0&lt;s&lt;t\\), and this makes sense: we don’t expect the function \\(F\\) to change beyond the time \\(t\\) where it’s evaluated. Secondly, this also means that when we plotted \\(W(h(t))\\) and \\(h(t)\\) together, it was a bit fake because we were assuming \\(s=t\\) for the sake of drawing it. Even so, I think that assumption allows us to see there’s a connection between the Malliavin derivative and the “instantaneous variance” or volatility of the process: the closer the derivative is to \\(0\\), the perturbations or movements are smaller. I’ll plot now a sample path for \\(F\\) and \\(DF\\), with \\(t \\in [0,1]\\) and \\(s=t\\) (which, again, isn’t the full picture, but I find it useful to connect the dots):\n\n\nCode\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndWt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\nWt &lt;- cumsum(dWt)\nf &lt;- Wt**2\nDf &lt;- 2*Wt\n\n# Plot\nggplot(mapping = aes(x = t)) +\n  xlab('Time') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y = f, colour=\"W(t)²\"),linetype = 2) + \n  geom_line(mapping = aes(y = Df, colour=\"DW(s=t)\"), linewidth = 0.25) + \n  scale_colour_manual(\"Functions\",values=c(\"black\",\"red\"))"
  },
  {
    "objectID": "malliavinderivative.html#skorohod-integral-more-integration-by-parts",
    "href": "malliavinderivative.html#skorohod-integral-more-integration-by-parts",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "We mentioned that linear operators come with a companion, adjoint operator. Malliavin derivatives aren’t the exception, and given that we defined \\(D\\) with an inner product and an \\(h\\) function to support it as in \\(\\langle DF, h \\rangle_H\\), we will look for an adjoint operator, which we call \\(\\delta\\), so that:\n\\[\n\\langle DF, h \\rangle_H = \\langle F, \\delta(h)\\rangle_{{R}^{\\,n}}\n\\]\nWe can find it by doing a bit of manipulation, taking some shortcuts here and relinquishing some mathematical rigor. From the definition, above, and assuming \\(h=h_1\\), we will take the expected value of the inner product, do integration by parts and some replacements, and we get:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[{\\langle DF, h \\rangle_H}\\right] &= \\mathbb{E}\\left[{\\sum_i \\partial_i f \\langle h_i, h \\rangle_H}\\right] \\\\\n&= \\int_{\\mathbb{R}^n} \\underbrace{\\partial_1 f(x)}_{dv}(2\\pi)^{-n/2}\\underbrace{e^{-\\|x\\|/2}}_{u} dx \\\\\n&= -\\int_{\\mathbb{R}^n} f(x) (-x_1) \\underbrace{(2\\pi)^{-n/2}e^{-\\|x\\|/2} dx}_{\\text{Gaussian measure}} \\\\\n&= \\int_{\\mathbb{R}^n} x_1 f(x) d\\mu_1 \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h_1)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\int_0^1 h dB}\\right]\n\\end{aligned}\n\\]\nWhat this means is that the expected value of the random variable \\(DF\\) measured using the function \\(h\\) between \\(0\\) and \\(1\\) as a ruler, is the same as the expected value of \\(F\\) multiplied by that integral of \\(h\\) on the right. We are implying that the \\(\\delta\\) operator is that integral. This is called the Skorohod integral, and it coincides with an Ito integral for non-anticipative processes3:\n\\[\n\\delta(h) = \\int_0^1 h dB_t\n\\]\nBy now, you probably have noticed how common it is to flip integrals and derivatives using integration by parts. It’s almost like second nature with Malliavin Calculus."
  },
  {
    "objectID": "malliavinderivative.html#what-now",
    "href": "malliavinderivative.html#what-now",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "So, we have finally arrived to a definition of the Malliavin Derivative. It has taken us a while, but now we are in a comfortable position to use it for something!\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st Ed.). 1st ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. “An Introduction to Malliavin Calculus.” In. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "malliavinderivative.html#footnotes",
    "href": "malliavinderivative.html#footnotes",
    "title": "Malliavin Derivative",
    "section": "",
    "text": "On a more formal write-up, we can consider this translation:\n\\[\nT_{\\hat{h}}(\\omega)=\\omega + \\varepsilon\\int_0^\\tau h = \\omega + \\varepsilon\\hat{h}\n\\] And the change of measure/variable, that is, our Radon-Nikodym derivative, will be:\n\\[\n\\frac{d(T_{\\hat{h}})_{*} W}{dW}(\\omega) = \\exp \\left( \\int_0^1 h d\\beta(\\omega) - \\frac{1}{2} \\int_0^1 h^2 d\\lambda \\right)\n\\]\nFinally, without loss of generality, we can assume \\(\\|h\\|=1\\), and let all the \\(h_i\\) be orthonormal in \\(H\\). This is a safe assumption due to Gram-Schmidt orthonormalization.↩︎\nA function with polynomial growth is also acceptable. Conditions for this function belong to the theory and don’t bring pedagogical clarity.↩︎\nFormally, this is either predictable or adapted processes. A predicable process has a value at \\(t\\) known in advance (for example, a non-random function). An adapted process has a value at \\(t\\) known at \\(t\\) (for example, the price of a stock). Non-adapted processes, or anticipative processes, are only known after some time has passed, with their information depending on the future (for example, a hale occurring in 7 days).↩︎"
  },
  {
    "objectID": "multidimensional.html",
    "href": "multidimensional.html",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "Now that we know what Malliavin Calculus wants to achieve, let us jot down some ideas. If you look for the definition of Malliavin Calculus in Wikipedia, you’ll quickly find that there’s a Cameron-Martin direction in which the derivative takes place. That doesn’t make any sense, so we need to explain what a Cameron-Martin space is. But that requires us to go, before that, to vector spaces with infinite dimensions. And that will require talking about measuring, especially lengths and distances between vectors, and functions as vectors. You’ll see I take a lot of inspiration from Slater (2023) and Alessandra Lunardi (2015), great websites that you should visit. This section is quite long and touches many algebra-related topics, so brace yourself.\n\n\nWe start from the beginning, with spaces, especially spaces over \\(\\mathbb{R}\\), the field of reals1. A space is a set \\(V\\), with elements that we will call vectors, that comes equipped with two operations:\n\nA “vector addition” operation that returns another vector. That is, \\(V_1 \\text{ '+' } V_2 = V_3\\)\nA “scalar multiplication” operation that returns another vector. That is, \\(k \\text{ '}*\\text{' } V_1 = V_2\\)\n\nWe use the quotes because we don’t want to impose any definitions on what those operations are. At most, we will say that they should observe properties like commutation (\\(V_1+V_2=V_2+V_1\\)). In practice, though, we won’t be so exotic.\nNow, we can also equip spaces with other operations that will allow us to measure distances and lengths.\n\n\nA metric space is a vector space that’s paired with a metric or distance function \\(d(V,V) \\rightarrow \\mathbb{R}\\). That is, a function that takes two vectors and gives back a real, positive value. Not every function will do, though. It needs to:\n\nBe symmetric, that is \\(d(x,y)=d(y,x)\\)\nReturn a positive value for different vectors, or zero if both vectors are the same\nHave the “triangle inequality”. That is, the distance between two vectors is larger (or equal) if you pass through a third, intermediate vector.\n\nThe three most famous distances are the euclidean distance or \\(d_2\\), the taxicab distance or \\(d_1\\), and the maximum distance or \\(d_\\infty\\). These are their definitions for vectors composed of \\(n\\) real numbers:\n\\[\n\\begin{aligned}\nd_2(\\vec a,\\vec b) &= \\sqrt[2]{\\sum_{k=1}^n{\\left(a_k - b_k\\right)^2}} \\\\\\\\\nd_1(\\vec a,\\vec b) &= \\sum_{k=1}^n{\\left|a_k - b_k\\right|} \\\\\\\\\nd_\\infty(\\vec a,\\vec b) &= \\max_k{\\left|a_k - b_k\\right|}\n\\end{aligned}\n\\]\n\n\n\nIf you pair a vector space with a norm, it becomes a normed vector space. A norm is an operation that calculates the length of a single vector and it’s denoted as \\(\\|\\,.\\|:V\\rightarrow \\mathbb{R}\\). As a function, it takes a single vector and gives back a real, positive value. Again, not every function will do, it needs to:\n\nReturn zero for the zero-vector, or a positive value for non-zero vectors\nBe homogeneous. That is, a vector with components twice as big will have a length twice as large, as in \\(\\| k\\cdot x\\|=|k|\\cdot\\|x\\|\\)\nHave the triangle inequality. That is, the norm of a sum is smaller or equal than the sum of the norms\n\nA classical example of norms are the family of \\(p\\)-norms. For a vector of \\(n\\)-length:\n\\[\n\\|x\\|_p=\\sqrt[p]{\\sum_{i=1}^n\\left(|x_i|\\right)^p}\n\\]\nSimilar to above, the 1-norm is the taxicab norm \\(\\|x\\|_1=\\sum_{i=1}^n{|x_i|}\\), the 2-norm is the euclidean norm and the infinite-norm is the maximum norm. That similarity doesn’t end there: you can create a distance out of a norm if you define the distance function to be the norm of the vectors’ difference. For example, \\(d_1(a,b)=|a-b|_1\\) . This is known as a metric or distance induced by the norm.\nThe opposite isn’t true, though. In general, a distance function can’t be turned into a norm, unless:\n\nThe metric is invariant to translations, that is, \\(d(x,y)=d(x+a,y+a)\\)\nThe metric is homogeneous, that is, \\(d(kx, ky)=|k|\\cdot d(x,y)\\)\n\nIn that case, the metric is induced by the norm \\(\\|x\\|=d(x,0)\\).\n\n\n\nThere is yet another step in this ladder. You can equip a vector space with an operation called the inner product. It’s denoted \\(\\langle V,V\\rangle \\rightarrow\\mathbb{R}\\) and it is, like the metric, a function that takes two vectors and gives back a real number. It can be thought of as the length of a vector when you use another vector as a ruler. It has a few requirements, though:\n\nIt must be symmetric, that is, \\(\\langle x,y\\rangle=\\langle y,x\\rangle\\)\nIt must be linear in the first argument, that is, \\(\\langle ix+jy,z\\rangle=i\\langle x,z\\rangle+j\\langle y,z\\rangle\\) . It will also apply for the second argument because of symmetry.\nIf x is zero, \\(\\langle x,x\\rangle=0\\), otherwise it’s a strictly positive number.\n\nEvery inner product will induce a canonical norm \\(\\|x\\|=\\sqrt[2]{\\langle x, x \\rangle}\\), which in turn induces a metric. The most common example is the dot product. A \\(n\\)-size vector would be:\n\\[\n\\langle x,y\\rangle=x^Ty=\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\n\n\n\n\nIn the formulas above, we say that there are \\(n\\) components in our vectors. If we want to make sense of Cameron Martin spaces, we need to compare distances and lengths of vectors of potentially infinite dimensions. This is going be heavily inspired on Slater (2023).\nNow, I’m going to assume you know a bit about linear algebra. For example, let’s take a vector space with vectors of this form:\n\\[\n\\begin{pmatrix}\na &b &c \\\\\n\\end{pmatrix},\\,\\text{ } a,b,c \\in \\mathbb{R}\n\\]\nWe say that this vector space has dimension 3 because the smallest number of vectors we need to create a linear combination of every vector in that space is 3. Those vectors conform a basis, like so:\n\\[\n\\begin{aligned}\n\\begin{pmatrix}a &b &c\\end{pmatrix} =\\, &a \\begin{pmatrix}1 &0 &0\\end{pmatrix} + \\\\\n&b \\begin{pmatrix}0 &1 &0\\end{pmatrix} + \\\\\n&c \\begin{pmatrix}0 &0 &1\\end{pmatrix} \\\\\n\\end{aligned}\n\\]\nLet’s jump to a more interesting case: a vector space that represents polynomials, up to grade \\(x^n, n \\in \\mathbb{N}\\). That means,\n\\[\na_0 + a_1 x + ... + a_{n-1} x^{n-1} + a_n x^n \\rightarrow \\begin{pmatrix}a_0 &a_1 &... &a_{n-1} &a_n\\end{pmatrix}\n\\]\nWe can see that polynomials admit multiplication by a scalar, as well as addition between two polynomials. So, we can truly use these as vectors from a space instead of the full polynomial’s formula.\nNow, there’s nothing preventing us from saying that \\(n\\) is just the entire \\(\\mathbb{N}\\), and that the basis is infinite in nature. That is, we need infinitely many vectors to represent all possible polynomials:\n\\[\n\\begin{aligned}\na_0 + a_1 x+ a_2x^2 +\\, ... \\rightarrow \\begin{pmatrix}a_0 &a_1 &a_2 &...\\end{pmatrix} =\\, &a_0 \\begin{pmatrix}1 &0 &0 &...\\end{pmatrix} + \\\\\n&a_1 \\begin{pmatrix}0 &1 &0 &...\\end{pmatrix} + \\\\\n&a_2 \\begin{pmatrix}0 &0 &1 &...\\end{pmatrix} +\\, ...\\\\\n\\end{aligned}\n\\]\nThe idea, while strange, isn’t too exotic. In fact, a lot of what we already knew for vectors with finite dimensions translate to infinite dimensions. For example, we can apply a linear transformation by multiplying these vectors with an equally-infinite matrix. You may already know that the derivative is a linear operation, so we can represent it with a matrix acting on our vector-as-polynomial:\n\\[\n\\frac{\\partial }{\\partial{x}}\\left(a_0+a_1x+a_2x^2+...\\right)\n\\rightarrow\n\\begin{pmatrix}\n0 &1 &0 &0 &...\\\\\n0 &0 &2 &0 &...\\\\\n0 &0 &0 &3 &...\\\\\n0 &0 &0 &0 &...\\end{pmatrix}*\\begin{pmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\...\\end{pmatrix}=\\begin{pmatrix}a_1 \\\\ 2a_2 \\\\ 3a_3 \\\\...\\end{pmatrix}\n\\rightarrow\na_1+2a_2x+3a_3x^2+...\n\\]\n\n\nA situation that’s a bit more interesting is when evaluating the norm or “length” of an element of these spaces. Let’s follow Alessandra Lunardi (2015) and consider the vector space of all infinite sequences of real numbers, \\((a_i)\\), which map to \\(\\mathbb{R}^{\\infty}\\). When dealing with finite dimensions, norms will always give you a finite result. This is no longer the case with infinite dimensions. For example, let’s take the harmonic sequence:\n\\[\n(b_k)_{k\\in\\mathbb{N}}, b_k=\\frac{1}{k} \\rightarrow \\begin{pmatrix}1 &\\frac{1}{2} &\\frac{1}{3} &...\\end{pmatrix}\n\\]\nWith the 1-norm,\n\\[\n\\|b\\|_1=\\lim_{n\\to \\infty}{\\sum_{k=1}^n |b_k|}=\\lim_{n\\to \\infty}{\\sum_{k=1}^n \\frac{1}{k}} \\rightarrow \\infty\n\\]\nwe can’t calculate a length value for the sequence, the harmonic series diverges. On the other hand, the 2-norm or euclidean norm, is capable to calculate a value because the series converges to a real number:\n\\[\n\\|b\\|_2=\\lim_{n\\to \\infty}{\\sqrt{\\sum_{k=1}^n {b_k}^2}}={\\sqrt{\\lim_{n\\to \\infty}\\sum_{k=1}^n \\frac{1}{k^2}}}=\\sqrt\\frac{\\pi^2}{6}\n\\]\nIn fact, mathematicians name \\(\\ell^p\\) the space of sequences where the \\(p\\)-norm converges to a value. Alternatively, if you don’t want to deal with norms, you are better off defining a distance function for the space like this:\n\\[\nd(x,y)=\\sum_{k=0}\\frac{1}{2^k}\\frac{|x_k-y_k|}{1+|x_k-y_k|}\n\\]\nThis will calculate a distance between any two sequences and it will always converge, but this metric isn’t translation invariant, and therefore doesn’t have an equivalent norm.\n\n\n\nUp until now, we have seen countably infinite dimensions, so let’s explore an uncountable one now: a space of functions. Yeah, functions are now elements of a vector space.\nTo make any sense of this, we will start with a vector space with an inner product, and we will get the norm and metric for free. Let’s remember that for \\(n\\)-size vectors, we did \\(x^Ty\\). So, in infinite dimensions, it would be something like:\n\\[\n\\begin{pmatrix}1 &3 &-2 &...\\end{pmatrix}\n*\n\\begin{pmatrix}0 \\\\ -1 \\\\ 3 \\\\...\\end{pmatrix}=1\\cdot0+3\\cdot(-1)+(-2)\\cdot3+...=\\lim_{n\\rightarrow\\infty}\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\nAs we transition from \\(\\mathbb{N}\\) to \\(\\mathbb{R}\\), these sums will become integrals. In our vector space of functions defined over some generic domain \\(X\\):\n\\[\n\\langle f,g \\rangle=\\int_Xf(x)g(x)dx\n\\]\nThis definition fulfills our conditions for an inner product, and therefore induces a norm and a distance function:\n\\[\n\\begin{aligned}\n\\|f\\|&=\\left(\\int_X\\left[f(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\nd(f,g)&=\\left(\\int_X\\left[f(x)-g(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\n\\end{aligned}\n\\]\nAs a final note, you can check that there aren’t a lot of functions that will give you a value for these as well. Just like \\(\\ell^p\\) restricted the space to sequences that returned a value under the \\(p\\)-norm, we can also restrict the space of functions to those that return a value under the special 2-norm that we induced above. The space is, creatively named, \\(L^p\\). Alternatively, \\(L^p\\) is named the space of functions that are Lebesgue-integrable.\nThis space is really very limited when \\(X=\\mathbb{R}\\). There aren’t many functions where \\(\\int_{-\\infty}^{+\\infty}\\left[f(x)\\right]^2dx&lt;\\infty\\). Only some functions like \\(e^{-x^2}\\) belong there. Polynomials, \\(e^x\\) or logarithms aren’t included. That’s why people typically define the inner product over a smaller interval, \\(X=[a,b]\\). A norm such as \\(\\int_{a}^{b}\\left[f(x)\\right]^2dx\\) admits many more functions and it’s much more useful.\nThere’s an additional option that can maintain \\(X=\\mathbb{R}\\) and still give you a value: we discard the Lebesgue measure and switch to Gaussian measure. In terms of the Riemann integral, it means that we stop treating all values of \\(X\\) the same and we add a “weighting factor” that will reduce the function values as they go to infinity.\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)g(x)dx = \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\lambda \\rightarrow \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\gamma_{\\mu,\\sigma}=\\int_{-\\infty}^{+\\infty}f(x)g(x)e^{-\\frac{(x-\\mu)^2}{\\sigma}}dx\n\\]\nThis is the alternative we will choose. As we will see soon, it won’t come free of charge.\n\n\n\n\nBefore we continue to the Cameron Martin space, this is probably the best moment to present linear operators. We briefly mentioned them in our polynomials-as-vectors example. We mentioned that we could create a matrix (of infinite size) to represent the derivative. In truth, these matrices can also be thought as functions that transform a vector to another vector. If this transformation is linear, then the matrix/function is called, unsurprisingly, a linear operator or linear map.\nWe will use this fancy way of calling matrices/functions to define a derivative in the sense of Fréchet. Fréchet wanted to extend the notion of derivative to work with functions that take \\(m\\) variables as input and outputs an \\(n\\)-sized vector, with our classical derivative being the case for \\(m=1,n=1\\). Here’s the definition: if you have two normed vector spaced \\(V\\) and \\(W\\), and a subset \\(U \\subseteq V\\). Then \\(f: V \\rightarrow W\\) is Fréchet-differentiable at \\(x \\in V\\) if there’s a linear operator \\(A: V \\rightarrow W\\) such that\n\\[\n\\lim_{\\|h\\|\\rightarrow 0} \\frac{\\|f(x+h)-f(x)-Ah\\|_W}{\\|h\\|_V}=0\n\\]\nand \\(A=Df(x)\\) is the Fréchet derivative. This may look daunting, but notice that with some minor algebra and alterations, we can obtain a more familiar and straightforward formula:\n\\[\nf(x+h) = f(x) + Ah\n\\]\nSo, in the end, \\(A\\) is how much the function changes with a small \\(h\\) displacement.\nThis special definition of derivative even allows you to calculate the derivative of the norm \\(\\|\\,.\\|:H \\rightarrow \\mathbb{R}\\) around \\(x \\neq 0\\):\n\\[\nD_xv = \\left\\langle v, \\frac{x}{\\|x\\|} \\right\\rangle\n\\]\nThat is, the derivative of the norm around \\(x\\), applied on a vector, is how much the length of the vector grows on the direction of \\(x\\), using a vector of length 1 as a ruler.\n\n\n\nA final topic around operators is the adjoint operator. Let’s take a linear operator \\(A:U\\rightarrow V\\), vectors \\(u \\in U, v \\in V\\), and an inner product for \\(U\\) and \\(V\\). Then the adjoint of \\(A\\), called \\(A^*: V \\rightarrow U\\) , is such that:\n\\[\n\\langle Au, v \\rangle_V = \\langle u, A^* v \\rangle_U\n\\]\nIt’s important to note that \\(A^*\\) isn’t an inverse, although \\(A^{**}=A\\), it’s more like a “companion” operator that can be used instead of \\(A\\) if we are in the other vector space.\n\n\n\nWe mentioned above that a basis already has the property of generating every element in the space by linear combination of its (linearly independent) elements. It can also have additional properties.\nA basis is “orthogonal” if \\(\\langle b_i, b_j \\rangle = 0 \\text{ if } i \\neq j\\) . That is, different elements in the basis don’t “overlap” with each other. This means we can express any vector \\(v\\) as a sum that depends only on the basis vectors and \\(v\\). In particular, if \\(B\\) is an orthogonal basis of \\(V\\), then any element \\(v\\) of \\(V\\) can be written as:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\frac{\\langle b_i, x \\rangle}{\\|b_i\\|^2}}_{a_i}b_i\n\\]\nWith a non-orthogonal basis, you can still write it as a sum, but you need to solve a system of equations to obtain the \\(a_i\\) for the given vector. Compare that to an orthogonal basis, where you can get them directly from an operation that uses the vector and the basis elements themselves.\nThis can be even better if the basis is “orthonormal”. A basis is orthonormal if it’s orthogonal and \\(\\langle b_i, b_i \\rangle = \\|b_i\\|^2=1\\) . In that case it’s even more straightforward, you really only need a single inner product operation to obtain the scalar that belongs to the basis element:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\langle b_i, x \\rangle}_{a_i}b_i\n\\]\nYou may ask why don’t we just use orthonormal basis all the time and save us the hassle. Indeed, we can transform a basis into an orthonormal basis by using the Gram-Schmidt process. I won’t explain the process, it’s only important that we know it can be done.\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. “Infinite Dimensional Analysis.” 2015. http://dmi.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nSlater, Max. 2023. “Functions Are Vectors.” 2023. https://thenumb.at/Functions-are-Vectors."
  },
  {
    "objectID": "multidimensional.html#hierarchy-of-spaces",
    "href": "multidimensional.html#hierarchy-of-spaces",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "We start from the beginning, with spaces, especially spaces over \\(\\mathbb{R}\\), the field of reals1. A space is a set \\(V\\), with elements that we will call vectors, that comes equipped with two operations:\n\nA “vector addition” operation that returns another vector. That is, \\(V_1 \\text{ '+' } V_2 = V_3\\)\nA “scalar multiplication” operation that returns another vector. That is, \\(k \\text{ '}*\\text{' } V_1 = V_2\\)\n\nWe use the quotes because we don’t want to impose any definitions on what those operations are. At most, we will say that they should observe properties like commutation (\\(V_1+V_2=V_2+V_1\\)). In practice, though, we won’t be so exotic.\nNow, we can also equip spaces with other operations that will allow us to measure distances and lengths.\n\n\nA metric space is a vector space that’s paired with a metric or distance function \\(d(V,V) \\rightarrow \\mathbb{R}\\). That is, a function that takes two vectors and gives back a real, positive value. Not every function will do, though. It needs to:\n\nBe symmetric, that is \\(d(x,y)=d(y,x)\\)\nReturn a positive value for different vectors, or zero if both vectors are the same\nHave the “triangle inequality”. That is, the distance between two vectors is larger (or equal) if you pass through a third, intermediate vector.\n\nThe three most famous distances are the euclidean distance or \\(d_2\\), the taxicab distance or \\(d_1\\), and the maximum distance or \\(d_\\infty\\). These are their definitions for vectors composed of \\(n\\) real numbers:\n\\[\n\\begin{aligned}\nd_2(\\vec a,\\vec b) &= \\sqrt[2]{\\sum_{k=1}^n{\\left(a_k - b_k\\right)^2}} \\\\\\\\\nd_1(\\vec a,\\vec b) &= \\sum_{k=1}^n{\\left|a_k - b_k\\right|} \\\\\\\\\nd_\\infty(\\vec a,\\vec b) &= \\max_k{\\left|a_k - b_k\\right|}\n\\end{aligned}\n\\]\n\n\n\nIf you pair a vector space with a norm, it becomes a normed vector space. A norm is an operation that calculates the length of a single vector and it’s denoted as \\(\\|\\,.\\|:V\\rightarrow \\mathbb{R}\\). As a function, it takes a single vector and gives back a real, positive value. Again, not every function will do, it needs to:\n\nReturn zero for the zero-vector, or a positive value for non-zero vectors\nBe homogeneous. That is, a vector with components twice as big will have a length twice as large, as in \\(\\| k\\cdot x\\|=|k|\\cdot\\|x\\|\\)\nHave the triangle inequality. That is, the norm of a sum is smaller or equal than the sum of the norms\n\nA classical example of norms are the family of \\(p\\)-norms. For a vector of \\(n\\)-length:\n\\[\n\\|x\\|_p=\\sqrt[p]{\\sum_{i=1}^n\\left(|x_i|\\right)^p}\n\\]\nSimilar to above, the 1-norm is the taxicab norm \\(\\|x\\|_1=\\sum_{i=1}^n{|x_i|}\\), the 2-norm is the euclidean norm and the infinite-norm is the maximum norm. That similarity doesn’t end there: you can create a distance out of a norm if you define the distance function to be the norm of the vectors’ difference. For example, \\(d_1(a,b)=|a-b|_1\\) . This is known as a metric or distance induced by the norm.\nThe opposite isn’t true, though. In general, a distance function can’t be turned into a norm, unless:\n\nThe metric is invariant to translations, that is, \\(d(x,y)=d(x+a,y+a)\\)\nThe metric is homogeneous, that is, \\(d(kx, ky)=|k|\\cdot d(x,y)\\)\n\nIn that case, the metric is induced by the norm \\(\\|x\\|=d(x,0)\\).\n\n\n\nThere is yet another step in this ladder. You can equip a vector space with an operation called the inner product. It’s denoted \\(\\langle V,V\\rangle \\rightarrow\\mathbb{R}\\) and it is, like the metric, a function that takes two vectors and gives back a real number. It can be thought of as the length of a vector when you use another vector as a ruler. It has a few requirements, though:\n\nIt must be symmetric, that is, \\(\\langle x,y\\rangle=\\langle y,x\\rangle\\)\nIt must be linear in the first argument, that is, \\(\\langle ix+jy,z\\rangle=i\\langle x,z\\rangle+j\\langle y,z\\rangle\\) . It will also apply for the second argument because of symmetry.\nIf x is zero, \\(\\langle x,x\\rangle=0\\), otherwise it’s a strictly positive number.\n\nEvery inner product will induce a canonical norm \\(\\|x\\|=\\sqrt[2]{\\langle x, x \\rangle}\\), which in turn induces a metric. The most common example is the dot product. A \\(n\\)-size vector would be:\n\\[\n\\langle x,y\\rangle=x^Ty=\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]"
  },
  {
    "objectID": "multidimensional.html#sec-infinite-dimensional-vector-spaces",
    "href": "multidimensional.html#sec-infinite-dimensional-vector-spaces",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "In the formulas above, we say that there are \\(n\\) components in our vectors. If we want to make sense of Cameron Martin spaces, we need to compare distances and lengths of vectors of potentially infinite dimensions. This is going be heavily inspired on Slater (2023).\nNow, I’m going to assume you know a bit about linear algebra. For example, let’s take a vector space with vectors of this form:\n\\[\n\\begin{pmatrix}\na &b &c \\\\\n\\end{pmatrix},\\,\\text{ } a,b,c \\in \\mathbb{R}\n\\]\nWe say that this vector space has dimension 3 because the smallest number of vectors we need to create a linear combination of every vector in that space is 3. Those vectors conform a basis, like so:\n\\[\n\\begin{aligned}\n\\begin{pmatrix}a &b &c\\end{pmatrix} =\\, &a \\begin{pmatrix}1 &0 &0\\end{pmatrix} + \\\\\n&b \\begin{pmatrix}0 &1 &0\\end{pmatrix} + \\\\\n&c \\begin{pmatrix}0 &0 &1\\end{pmatrix} \\\\\n\\end{aligned}\n\\]\nLet’s jump to a more interesting case: a vector space that represents polynomials, up to grade \\(x^n, n \\in \\mathbb{N}\\). That means,\n\\[\na_0 + a_1 x + ... + a_{n-1} x^{n-1} + a_n x^n \\rightarrow \\begin{pmatrix}a_0 &a_1 &... &a_{n-1} &a_n\\end{pmatrix}\n\\]\nWe can see that polynomials admit multiplication by a scalar, as well as addition between two polynomials. So, we can truly use these as vectors from a space instead of the full polynomial’s formula.\nNow, there’s nothing preventing us from saying that \\(n\\) is just the entire \\(\\mathbb{N}\\), and that the basis is infinite in nature. That is, we need infinitely many vectors to represent all possible polynomials:\n\\[\n\\begin{aligned}\na_0 + a_1 x+ a_2x^2 +\\, ... \\rightarrow \\begin{pmatrix}a_0 &a_1 &a_2 &...\\end{pmatrix} =\\, &a_0 \\begin{pmatrix}1 &0 &0 &...\\end{pmatrix} + \\\\\n&a_1 \\begin{pmatrix}0 &1 &0 &...\\end{pmatrix} + \\\\\n&a_2 \\begin{pmatrix}0 &0 &1 &...\\end{pmatrix} +\\, ...\\\\\n\\end{aligned}\n\\]\nThe idea, while strange, isn’t too exotic. In fact, a lot of what we already knew for vectors with finite dimensions translate to infinite dimensions. For example, we can apply a linear transformation by multiplying these vectors with an equally-infinite matrix. You may already know that the derivative is a linear operation, so we can represent it with a matrix acting on our vector-as-polynomial:\n\\[\n\\frac{\\partial }{\\partial{x}}\\left(a_0+a_1x+a_2x^2+...\\right)\n\\rightarrow\n\\begin{pmatrix}\n0 &1 &0 &0 &...\\\\\n0 &0 &2 &0 &...\\\\\n0 &0 &0 &3 &...\\\\\n0 &0 &0 &0 &...\\end{pmatrix}*\\begin{pmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\...\\end{pmatrix}=\\begin{pmatrix}a_1 \\\\ 2a_2 \\\\ 3a_3 \\\\...\\end{pmatrix}\n\\rightarrow\na_1+2a_2x+3a_3x^2+...\n\\]\n\n\nA situation that’s a bit more interesting is when evaluating the norm or “length” of an element of these spaces. Let’s follow Alessandra Lunardi (2015) and consider the vector space of all infinite sequences of real numbers, \\((a_i)\\), which map to \\(\\mathbb{R}^{\\infty}\\). When dealing with finite dimensions, norms will always give you a finite result. This is no longer the case with infinite dimensions. For example, let’s take the harmonic sequence:\n\\[\n(b_k)_{k\\in\\mathbb{N}}, b_k=\\frac{1}{k} \\rightarrow \\begin{pmatrix}1 &\\frac{1}{2} &\\frac{1}{3} &...\\end{pmatrix}\n\\]\nWith the 1-norm,\n\\[\n\\|b\\|_1=\\lim_{n\\to \\infty}{\\sum_{k=1}^n |b_k|}=\\lim_{n\\to \\infty}{\\sum_{k=1}^n \\frac{1}{k}} \\rightarrow \\infty\n\\]\nwe can’t calculate a length value for the sequence, the harmonic series diverges. On the other hand, the 2-norm or euclidean norm, is capable to calculate a value because the series converges to a real number:\n\\[\n\\|b\\|_2=\\lim_{n\\to \\infty}{\\sqrt{\\sum_{k=1}^n {b_k}^2}}={\\sqrt{\\lim_{n\\to \\infty}\\sum_{k=1}^n \\frac{1}{k^2}}}=\\sqrt\\frac{\\pi^2}{6}\n\\]\nIn fact, mathematicians name \\(\\ell^p\\) the space of sequences where the \\(p\\)-norm converges to a value. Alternatively, if you don’t want to deal with norms, you are better off defining a distance function for the space like this:\n\\[\nd(x,y)=\\sum_{k=0}\\frac{1}{2^k}\\frac{|x_k-y_k|}{1+|x_k-y_k|}\n\\]\nThis will calculate a distance between any two sequences and it will always converge, but this metric isn’t translation invariant, and therefore doesn’t have an equivalent norm.\n\n\n\nUp until now, we have seen countably infinite dimensions, so let’s explore an uncountable one now: a space of functions. Yeah, functions are now elements of a vector space.\nTo make any sense of this, we will start with a vector space with an inner product, and we will get the norm and metric for free. Let’s remember that for \\(n\\)-size vectors, we did \\(x^Ty\\). So, in infinite dimensions, it would be something like:\n\\[\n\\begin{pmatrix}1 &3 &-2 &...\\end{pmatrix}\n*\n\\begin{pmatrix}0 \\\\ -1 \\\\ 3 \\\\...\\end{pmatrix}=1\\cdot0+3\\cdot(-1)+(-2)\\cdot3+...=\\lim_{n\\rightarrow\\infty}\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\nAs we transition from \\(\\mathbb{N}\\) to \\(\\mathbb{R}\\), these sums will become integrals. In our vector space of functions defined over some generic domain \\(X\\):\n\\[\n\\langle f,g \\rangle=\\int_Xf(x)g(x)dx\n\\]\nThis definition fulfills our conditions for an inner product, and therefore induces a norm and a distance function:\n\\[\n\\begin{aligned}\n\\|f\\|&=\\left(\\int_X\\left[f(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\nd(f,g)&=\\left(\\int_X\\left[f(x)-g(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\n\\end{aligned}\n\\]\nAs a final note, you can check that there aren’t a lot of functions that will give you a value for these as well. Just like \\(\\ell^p\\) restricted the space to sequences that returned a value under the \\(p\\)-norm, we can also restrict the space of functions to those that return a value under the special 2-norm that we induced above. The space is, creatively named, \\(L^p\\). Alternatively, \\(L^p\\) is named the space of functions that are Lebesgue-integrable.\nThis space is really very limited when \\(X=\\mathbb{R}\\). There aren’t many functions where \\(\\int_{-\\infty}^{+\\infty}\\left[f(x)\\right]^2dx&lt;\\infty\\). Only some functions like \\(e^{-x^2}\\) belong there. Polynomials, \\(e^x\\) or logarithms aren’t included. That’s why people typically define the inner product over a smaller interval, \\(X=[a,b]\\). A norm such as \\(\\int_{a}^{b}\\left[f(x)\\right]^2dx\\) admits many more functions and it’s much more useful.\nThere’s an additional option that can maintain \\(X=\\mathbb{R}\\) and still give you a value: we discard the Lebesgue measure and switch to Gaussian measure. In terms of the Riemann integral, it means that we stop treating all values of \\(X\\) the same and we add a “weighting factor” that will reduce the function values as they go to infinity.\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)g(x)dx = \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\lambda \\rightarrow \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\gamma_{\\mu,\\sigma}=\\int_{-\\infty}^{+\\infty}f(x)g(x)e^{-\\frac{(x-\\mu)^2}{\\sigma}}dx\n\\]\nThis is the alternative we will choose. As we will see soon, it won’t come free of charge."
  },
  {
    "objectID": "multidimensional.html#linear-operators-and-an-alternative-derivative-definition",
    "href": "multidimensional.html#linear-operators-and-an-alternative-derivative-definition",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "Before we continue to the Cameron Martin space, this is probably the best moment to present linear operators. We briefly mentioned them in our polynomials-as-vectors example. We mentioned that we could create a matrix (of infinite size) to represent the derivative. In truth, these matrices can also be thought as functions that transform a vector to another vector. If this transformation is linear, then the matrix/function is called, unsurprisingly, a linear operator or linear map.\nWe will use this fancy way of calling matrices/functions to define a derivative in the sense of Fréchet. Fréchet wanted to extend the notion of derivative to work with functions that take \\(m\\) variables as input and outputs an \\(n\\)-sized vector, with our classical derivative being the case for \\(m=1,n=1\\). Here’s the definition: if you have two normed vector spaced \\(V\\) and \\(W\\), and a subset \\(U \\subseteq V\\). Then \\(f: V \\rightarrow W\\) is Fréchet-differentiable at \\(x \\in V\\) if there’s a linear operator \\(A: V \\rightarrow W\\) such that\n\\[\n\\lim_{\\|h\\|\\rightarrow 0} \\frac{\\|f(x+h)-f(x)-Ah\\|_W}{\\|h\\|_V}=0\n\\]\nand \\(A=Df(x)\\) is the Fréchet derivative. This may look daunting, but notice that with some minor algebra and alterations, we can obtain a more familiar and straightforward formula:\n\\[\nf(x+h) = f(x) + Ah\n\\]\nSo, in the end, \\(A\\) is how much the function changes with a small \\(h\\) displacement.\nThis special definition of derivative even allows you to calculate the derivative of the norm \\(\\|\\,.\\|:H \\rightarrow \\mathbb{R}\\) around \\(x \\neq 0\\):\n\\[\nD_xv = \\left\\langle v, \\frac{x}{\\|x\\|} \\right\\rangle\n\\]\nThat is, the derivative of the norm around \\(x\\), applied on a vector, is how much the length of the vector grows on the direction of \\(x\\), using a vector of length 1 as a ruler."
  },
  {
    "objectID": "multidimensional.html#adjoint-operators",
    "href": "multidimensional.html#adjoint-operators",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "A final topic around operators is the adjoint operator. Let’s take a linear operator \\(A:U\\rightarrow V\\), vectors \\(u \\in U, v \\in V\\), and an inner product for \\(U\\) and \\(V\\). Then the adjoint of \\(A\\), called \\(A^*: V \\rightarrow U\\) , is such that:\n\\[\n\\langle Au, v \\rangle_V = \\langle u, A^* v \\rangle_U\n\\]\nIt’s important to note that \\(A^*\\) isn’t an inverse, although \\(A^{**}=A\\), it’s more like a “companion” operator that can be used instead of \\(A\\) if we are in the other vector space."
  },
  {
    "objectID": "multidimensional.html#orthonormalization",
    "href": "multidimensional.html#orthonormalization",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "We mentioned above that a basis already has the property of generating every element in the space by linear combination of its (linearly independent) elements. It can also have additional properties.\nA basis is “orthogonal” if \\(\\langle b_i, b_j \\rangle = 0 \\text{ if } i \\neq j\\) . That is, different elements in the basis don’t “overlap” with each other. This means we can express any vector \\(v\\) as a sum that depends only on the basis vectors and \\(v\\). In particular, if \\(B\\) is an orthogonal basis of \\(V\\), then any element \\(v\\) of \\(V\\) can be written as:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\frac{\\langle b_i, x \\rangle}{\\|b_i\\|^2}}_{a_i}b_i\n\\]\nWith a non-orthogonal basis, you can still write it as a sum, but you need to solve a system of equations to obtain the \\(a_i\\) for the given vector. Compare that to an orthogonal basis, where you can get them directly from an operation that uses the vector and the basis elements themselves.\nThis can be even better if the basis is “orthonormal”. A basis is orthonormal if it’s orthogonal and \\(\\langle b_i, b_i \\rangle = \\|b_i\\|^2=1\\) . In that case it’s even more straightforward, you really only need a single inner product operation to obtain the scalar that belongs to the basis element:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\langle b_i, x \\rangle}_{a_i}b_i\n\\]\nYou may ask why don’t we just use orthonormal basis all the time and save us the hassle. Indeed, we can transform a basis into an orthonormal basis by using the Gram-Schmidt process. I won’t explain the process, it’s only important that we know it can be done.\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. “Infinite Dimensional Analysis.” 2015. http://dmi.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nSlater, Max. 2023. “Functions Are Vectors.” 2023. https://thenumb.at/Functions-are-Vectors."
  },
  {
    "objectID": "multidimensional.html#footnotes",
    "href": "multidimensional.html#footnotes",
    "title": "Infinite-dimensional vector spaces",
    "section": "",
    "text": "A word of warning: some of these properties don’t apply for the field of complex numbers \\(\\mathbb{C}\\), but we won’t deal with them.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  }
]