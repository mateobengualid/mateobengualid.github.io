[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Comentarios finales",
    "section": "",
    "text": "¡Queda mucho más! Este trabajo hizo lo suficiente para presentar la derivada de Malliavin y la fórmula de Clark-Ocone, pero quedaron asuntos en el tintero. Hay tres cosas que he excluido, este ensayo ya es muy largo así como está.\nEn primer lugar, las derivadas de Malliavin simplifican el trabajo con varianzas estocásticas. Es decir, imaginemos que \\(\\sigma\\) es un proceso de Ito. Si no tiene una solución, hace falta correr un programa de computadora para estimar el proceso y su esperanza. Es más manejable utilizar las técnicas anteriores, en lugar de simular y estimar la evolución de \\(N\\).\nEn segundo lugar, podemos utilizar integración por partes para alternar entre la derivada de una función y la integral de Skorohod. En el caso de procesos no anticipatorios, la fórmula es fácil de calcular porque es simplemente una integral de Ito. Esto hace que sea, a su vez, más fácil calcular/estimar derivadas de funciones de procesos contra otros procesos. Por ejemplo, suponiendo que el precio de un activo sigue un proceso estocástico, se denomina Delta a la derivada del pago del seguro de algún activo contra el precio del activo. Cambiar a activos menos riesgosos para reducir esta derivada se llama cobertura Delta. Cuando esta derivada es cero, los cambios en el precio del activo ya no afectan la recompensa del seguro y el seguro se considera delta-neutral.\nUn último punto es que las integrales de Skorohod también funcionan para las integrales anticipatorias. No las hemos tocado aquí porque no son integrales de Ito propiamente dichas y ya era demasiado contenido, pero aquí también es donde el cálculo de Malliavin ayuda.\n\n\n\nQué viaje. Para ser honesto, cuando empecé este ensayo no pensaba que llegaría tan lejos. Me llevó meses sentirme lo suficientemente cómodo para escribir esto. Espero que hayamos podido aprender un poco sobre el cálculo de Malliavin. Si querés continuar y preferís un tratamiento más teórico, dejé enlaces a todas las fuentes interesantes para el trabajo previo, antes del cálculo de Malliavin, y supongo que Nualart, Oksendal o el propio Malliavin para el tópico en sí. Para cuestiones más prácticas, no puedo recomendar lo suficiente Alos (2021). Está muy por delante del resto de las fuentes consultadas.\nFinalmente, te agradezco a vos, que leíste todo esto. Me hago eco de Bret Victor cuando dijo que las ideas no deberían morir, y que hayas llegado a este punto demuestra que este tema puede sobrevivir un día más.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681."
  },
  {
    "objectID": "summary.html#hay-algo-más",
    "href": "summary.html#hay-algo-más",
    "title": "Comentarios finales",
    "section": "",
    "text": "¡Queda mucho más! Este trabajo hizo lo suficiente para presentar la derivada de Malliavin y la fórmula de Clark-Ocone, pero quedaron asuntos en el tintero. Hay tres cosas que he excluido, este ensayo ya es muy largo así como está.\nEn primer lugar, las derivadas de Malliavin simplifican el trabajo con varianzas estocásticas. Es decir, imaginemos que \\(\\sigma\\) es un proceso de Ito. Si no tiene una solución, hace falta correr un programa de computadora para estimar el proceso y su esperanza. Es más manejable utilizar las técnicas anteriores, en lugar de simular y estimar la evolución de \\(N\\).\nEn segundo lugar, podemos utilizar integración por partes para alternar entre la derivada de una función y la integral de Skorohod. En el caso de procesos no anticipatorios, la fórmula es fácil de calcular porque es simplemente una integral de Ito. Esto hace que sea, a su vez, más fácil calcular/estimar derivadas de funciones de procesos contra otros procesos. Por ejemplo, suponiendo que el precio de un activo sigue un proceso estocástico, se denomina Delta a la derivada del pago del seguro de algún activo contra el precio del activo. Cambiar a activos menos riesgosos para reducir esta derivada se llama cobertura Delta. Cuando esta derivada es cero, los cambios en el precio del activo ya no afectan la recompensa del seguro y el seguro se considera delta-neutral.\nUn último punto es que las integrales de Skorohod también funcionan para las integrales anticipatorias. No las hemos tocado aquí porque no son integrales de Ito propiamente dichas y ya era demasiado contenido, pero aquí también es donde el cálculo de Malliavin ayuda."
  },
  {
    "objectID": "summary.html#últimas-palabras",
    "href": "summary.html#últimas-palabras",
    "title": "Comentarios finales",
    "section": "",
    "text": "Qué viaje. Para ser honesto, cuando empecé este ensayo no pensaba que llegaría tan lejos. Me llevó meses sentirme lo suficientemente cómodo para escribir esto. Espero que hayamos podido aprender un poco sobre el cálculo de Malliavin. Si querés continuar y preferís un tratamiento más teórico, dejé enlaces a todas las fuentes interesantes para el trabajo previo, antes del cálculo de Malliavin, y supongo que Nualart, Oksendal o el propio Malliavin para el tópico en sí. Para cuestiones más prácticas, no puedo recomendar lo suficiente Alos (2021). Está muy por delante del resto de las fuentes consultadas.\nFinalmente, te agradezco a vos, que leíste todo esto. Me hago eco de Bret Victor cuando dijo que las ideas no deberían morir, y que hayas llegado a este punto demuestra que este tema puede sobrevivir un día más.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681."
  },
  {
    "objectID": "multidimensional.html",
    "href": "multidimensional.html",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Ahora que sabemos lo que pretende conseguir el Cálculo de Malliavin, hay que delinear algunas ideas. Si buscamos la definición de Cálculo de Malliavin en Wikipedia, van a encontrar rápido que hay una dirección de Cameron-Martin sobre la que se produce la derivada. Eso no tiene ningún sentido, así que hay que explicar qué es un espacio de Cameron-Martin. Pero eso requiere que vayamos, incluso antes, a espacios vectoriales de dimensión infinita. Y eso requerirá hablar de cómo se miden longitudes y distancias entre vectores, y de funciones como vectores. Me inspiré mucho en Slater (2023) y Alessandra Lunardi (2015), grandes sitios web que deberían visitar. Esta sección es bastante larga y toca muchos temas de álgebra, así que prepárense.\n\n\nEmpezamos por el principio, por los espacios, especialmente los espacios sobre \\(\\mathbb{R}\\), el campo de los reales1. Un espacio es un conjunto \\(V\\), con elementos que llamaremos vectores, que viene equipado con dos operaciones:\n\nUna operación de “suma de vectores”, que devuelve otro vector. Es decir, \\(V_1 \\text{ '+' } V_2 = V_3\\)\nUna operación de “multiplicación por un escalar” que devuelve otro vector. Es decir, \\(k \\text{ '}*\\text{' } V_1 = V_2\\)\n\nUsamos las comillas porque no queremos imponer ninguna definición previa sobre qué son esas operaciones. Como mucho, diremos que deben observar ciertas propiedades como la conmutación (\\(V_1+V_2=V_2+V_1\\)). En la práctica, sin embargo, no seremos tan exóticos.\nAhora bien, también podemos dotar a los espacios de otras operaciones que nos permitirán medir distancias y longitudes (ojo, no en el sentído de Teoría de la Medida).\n\n\nUn espacio métrico es un espacio vectorial al que le han agregado una métrica o función de distancia \\(d(V,V) \\rightarrow \\mathbb{R}\\). Es decir, una función que toma dos vectores y devuelve un valor real y positivo, la “distancia” entre ellos. Sin embargo, no todas las funciones sirven:\n\nDeben ser simétricas, es decir \\(d(x,y)=d(y,x)\\)\nDeben devolver un valor positivo para vectores diferentes, o cero si ambos vectores son iguales\nDeben cumplir la “desigualdad del triángulo”. Es decir, la distancia entre dos vectores es mayor (o igual) que la suma de las distancias entre esos vectores y un vector intermedio.\n\nLas tres distancias más famosas son la distancia euclidiana o \\(d_2\\), la distancia del taxi o \\(d_1\\) y la distancia máxima o \\(d_\\infty\\). Estas son sus definiciones para vectores compuestos de \\(n\\) números reales:\n\\[\n\\begin{aligned}\nd_2(\\vec a,\\vec b) &= \\sqrt[2]{\\sum_{k=1}^n{\\left(a_k - b_k\\right)^2}} \\\\\\\\\nd_1(\\vec a,\\vec b) &= \\sum_{k=1}^n{\\left|a_k - b_k\\right|} \\\\\\\\\nd_\\infty(\\vec a,\\vec b) &= \\max_k{\\left|a_k - b_k\\right|}\n\\end{aligned}\n\\]\n\n\n\nSi a un espacio vectorial se le asocia una norma, se convierte en un espacio vectorial normado. Una norma es una operación que calcula la longitud de un vector y se denota como \\(\\|\\,.\\|:V\\rightarrow \\mathbb{R}\\). Como función, toma un único vector y devuelve un valor real y positivo. Nuevamente, no todas las funciones pueden ser normas:\n\nDeben devolver cero para el vector cero, o un valor positivo para los vectores distintos de cero\nDeben ser homogéneas. Es decir, un vector con componentes dos veces más grandes tendrá una longitud dos veces más grande, como en \\(\\| k\\cdot x\\|=|k|\\cdot\\|x\\|\\)\nDeben cumplir la desigualdad del triángulo. Es decir, la norma de una suma es menor o igual que la suma de las normas\n\nUn ejemplo clásico de normas es la familia de las \\(p\\)-normas. Para un vector de longitud \\(n\\):\n\\[\n\\|x\\|_p=\\sqrt[p]{\\sum_{i=1}^n\\left(|x_i|\\right)^p}\n\\]\nDe manera similar a lo anterior, la norma-1 es la norma del taxi \\(\\|x\\|_1=\\sum_{i=1}^n{|x_i|}\\), la norma-2 es la norma euclidiana y la norma-infinito es la norma del máximo. Todo esto suena parecido a las funciones distancia, y la similitud no es casual: se puede crear una métrica a partir de una norma si se define la función de distancia como la norma de la diferencia entre dos vectores. Por ejemplo, \\(d_1(a,b)=|a-b|_1\\) . Se dice que la métrica es inducida por la norma.\nSin embargo, lo opuesto no siempre es cierto. En general, una función de distancia no se puede convertir en una norma, a menos que:\n\nLa métrica sea invariante a traslaciones, es decir, \\(d(x,y)=d(x+a,y+a)\\)\nLa métrica sea homogénea, es decir, \\(d(kx, ky)=|k|\\cdot d(x,y)\\)\n\nEn ese caso, la métrica es inducida por la norma \\(\\|x\\|=d(x,0)\\).\n\n\n\nHay otro paso más en esta escalera. Podés equipar un espacio vectorial con una operación llamada producto interno o producto interior. Se denota \\(\\langle V,V\\rangle \\rightarrow\\mathbb{R}\\) y es, como la métrica, una función que toma dos vectores y devuelve un número real. Puede interpretarse como la longitud de un vector cuando se utiliza otro vector como regla. Sin embargo, como antes, también tiene ciertos requisitos:\n\nDebe ser simétrico, es decir, \\(\\langle x,y\\rangle=\\langle y,x\\rangle\\)\nDebe ser lineal en el primer argumento, es decir, \\(\\langle ix+jy,z\\rangle=i\\langle x,z\\rangle+j\\langle y,z\\rangle\\) . Dado que el producto interno es simétrico, esto también aplica para el segundo argumento.\nSi x es cero, \\(\\langle x,x\\rangle=0\\), de lo contrario, es un número estrictamente positivo.\n\nTodo producto interno induce una norma canónica \\(\\|x\\|=\\sqrt[2]{\\langle x, x \\rangle}\\), que a su vez induce una métrica. El ejemplo más común es el producto escalar. Para un vector de tamaño \\(n\\), sería:\n\\[\n\\langle x,y\\rangle=x^Ty=\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\n\n\n\n\nEn las fórmulas anteriores, decimos que hay \\(n\\) componentes en nuestros vectores. Si queremos entender los espacios de Cameron Martin, necesitamos comparar distancias y longitudes de vectores de dimensiones potencialmente infinitas. Esto estará fuertemente inspirado en Slater (2023).\nVoy a asumir que sabés un poco sobre álgebra lineal. Por ejemplo, tomemos un espacio vectorial con vectores de esta forma:\n\\[\n\\begin{pmatrix}\na &b &c \\\\\n\\end{pmatrix},\\,\\text{ } a,b,c \\in \\mathbb{R}\n\\]\nDecimos que este espacio vectorial tiene dimensión 3 porque el número más pequeño de vectores que necesitamos para crear una combinación lineal de cada vector en ese espacio es 3. Esos vectores conforman una base, de la siguiente manera:\n\\[\n\\begin{aligned}\n\\begin{pmatrix}a &b &c\\end{pmatrix} =\\, &a \\begin{pmatrix}1 &0 &0\\end{pmatrix} + \\\\\n&b \\begin{pmatrix}0 &1 &0\\end{pmatrix} + \\\\\n&c \\begin{pmatrix}0 &0 &1\\end{pmatrix} \\\\\n\\end{aligned}\n\\]\nVeamos a un caso más interesante: un espacio vectorial que representa polinomios, hasta el grado \\(x^n, n \\in \\mathbb{N}\\). Esto significa que\n\\[\na_0 + a_1 x + ... + a_{n-1} x^{n-1} + a_n x^n \\rightarrow \\begin{pmatrix}a_0 &a_1 &... &a_{n-1} &a_n\\end{pmatrix}\n\\]\nPodemos ver que los polinomios se pueden sumar entre sí y que se pueden multiplicar por un número. Por lo tanto, podemos utilizarlos como vectores de un espacio vectorial en lugar de la fórmula del polinomio completo.\nDe hecho, no hay nada que nos impida decir que \\(n\\) es directamente tan grande como los números naturales \\(\\mathbb{N}\\), es decir que la base es de naturaleza infinita. Necesitamos, pues, una cantidad infinita de vectores para representar todos los polinomios posibles:\n\\[\n\\begin{aligned}\na_0 + a_1 x+ a_2x^2 +\\, ... \\rightarrow \\begin{pmatrix}a_0 &a_1 &a_2 &...\\end{pmatrix} =\\, &a_0 \\begin{pmatrix}1 &0 &0 &...\\end{pmatrix} + \\\\\n&a_1 \\begin{pmatrix}0 &1 &0 &...\\end{pmatrix} + \\\\\n&a_2 \\begin{pmatrix}0 &0 &1 &...\\end{pmatrix} +\\, ...\\\\\n\\end{aligned}\n\\]\nLa idea es rara pero no demasiado rara. Mucho de lo que ya sabíamos sobre vectores con dimensiones finitas se traduce a dimensiones infinitas. Por ejemplo, podemos aplicar una transformación lineal multiplicando estos vectores por una matriz igualmente infinita. Es posible que sepas que la derivada es una operación lineal, por lo que podemos representarla con una matriz que actúe sobre nuestro vector (que en realidad es un polinomio):\n\\[\n\\frac{\\partial }{\\partial{x}}\\left(a_0+a_1x+a_2x^2+...\\right)\n\\rightarrow\n\\begin{pmatrix}\n0 &1 &0 &0 &...\\\\\n0 &0 &2 &0 &...\\\\\n0 &0 &0 &3 &...\\\\\n0 &0 &0 &0 &...\\end{pmatrix}*\\begin{pmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\...\\end{pmatrix}=\\begin{pmatrix}a_1 \\\\ 2a_2 \\\\ 3a_3 \\\\...\\end{pmatrix}\n\\rightarrow\na_1+2a_2x+3a_3x^2+...\n\\]\n\n\nUna situación un poco más interesante es cuando evaluamos la norma o “longitud” de un elemento en estos espacios de dimensión infinita. Siguiendo un ejemplo de Alessandra Lunardi (2015), consideremos el espacio vectorial de las sucesiones infinitas de números reales, \\((a_i)\\), que se asignan a \\(\\mathbb{R}^{\\infty}\\). Cuando se trabaja con dimensiones finitas, las normas siempre darán un resultado finito. Este ya no es el caso con dimensiones infinitas. Por ejemplo, tomemos la secuencia armónica:\n\\[\n(b_k)_{k\\in\\mathbb{N}}, b_k=\\frac{1}{k} \\rightarrow \\begin{pmatrix}1 &\\frac{1}{2} &\\frac{1}{3} &...\\end{pmatrix}\n\\]\nCon la norma-1 nos queda:\n\\[\n\\|b\\|_1=\\lim_{n\\to \\infty}{\\sum_{k=1}^n |b_k|}=\\lim_{n\\to \\infty}{\\sum_{k=1}^n \\frac{1}{k}} \\rightarrow \\infty\n\\]\nNo podemos calcular una longitud para la sucesión porque la serie armónica diverge. Por el contrario, la norma euclidiana sí es capaz de calcular un valor porque la serie converge a un número real:\n\\[\n\\|b\\|_2=\\lim_{n\\to \\infty}{\\sqrt{\\sum_{k=1}^n {b_k}^2}}={\\sqrt{\\lim_{n\\to \\infty}\\sum_{k=1}^n \\frac{1}{k^2}}}=\\frac{\\pi}{\\sqrt6}\n\\]\nDebido a esto, los matemáticos denominan \\(\\ell^p\\) al espacio de aquellas sucesiones donde la norma-\\(p\\) converge a un valor. Alternativamente, podemos no lidiar con normas y definir solamente una función de distancia para el espacio, de esta manera:\n\\[\nd(x,y)=\\sum_{k=0}\\frac{1}{2^k}\\frac{|x_k-y_k|}{1+|x_k-y_k|}\n\\]\nEsto puede calcular una distancia entre dos sucesiones y converge siempre, pero esta métrica no es invariante a traslaciones y, por lo tanto, no tiene una norma equivalente.\n\n\n\nHasta ahora, hemos visto dimensiones infinitas numerables, con una base tan grande como los números naturales. Exploremos ahora una no numerable: un espacio de funciones. Sí, las funciones ahora son elementos de un espacio vectorial.\nPara que esto tenga algún sentido, vamos a empezar con un espacio vectorial con un producto interno, que es relativamente fácil de construir. Eso también nos dará la norma y la métrica de forma gratuita. Recordemos que para vectores de tamaño \\(n\\), hicimos \\(x^Ty\\). Entonces, en dimensiones infinitas, sería algo como:\n\\[\n\\begin{pmatrix}1 &3 &-2 &...\\end{pmatrix}\n*\n\\begin{pmatrix}0 \\\\ -1 \\\\ 3 \\\\...\\end{pmatrix}=1\\cdot0+3\\cdot(-1)+(-2)\\cdot3+...=\\lim_{n\\rightarrow\\infty}\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\nA medida que pasamos de \\(\\mathbb{N}\\) a \\(\\mathbb{R}\\), estas sumas se convertirán en integrales. En nuestro espacio vectorial de funciones definidas sobre un dominio genérico \\(X\\):\n\\[\n\\langle f,g \\rangle=\\int_Xf(x)g(x)dx\n\\]\nEsta definición cumple nuestras condiciones para un producto interno y, por lo tanto, induce una norma y una función de distancia:\n\\[\n\\begin{aligned}\n\\|f\\|&=\\left(\\int_X\\left[f(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\nd(f,g)&=\\left(\\int_X\\left[f(x)-g(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\n\\end{aligned}\n\\]\nPara redondear el concepto, se puede comprobar que también existen funciones para las que este producto interno, norma y métrica no puede calcular o converger a un valor. De la misma manera que \\(\\ell^p\\) restringe el espacio a sucesiones que devolvían un valor bajo la norma \\(p\\), también podemos restringir el espacio de funciones a aquellas que sí devuelven un valor bajo la norma-2 para funciones inducida anteriormente. El espacio se llama creativamente \\(L^p\\). Alternativamente, \\(L^p\\) se llama el espacio de funciones que son integrables en Lebesgue.\nEste espacio es realmente muy limitado cuando \\(X=\\mathbb{R}\\). No hay muchas funciones donde \\(\\int_{-\\infty}^{+\\infty}\\left[f(x)\\right]^2dx&lt;\\infty\\). Solo algunas funciones como \\(e^{-x^2}\\) pertenecen allí. Los polinomios, \\(e^x\\) o los logaritmos no están incluidos. Es por eso que la gente generalmente define el producto interno sobre un intervalo más pequeño, \\(X=[a,b]\\). Una norma como \\(\\int_{a}^{b}\\left[f(x)\\right]^2dx\\) admite muchas más funciones y es mucho más útil.\nHay una opción adicional que te permite integrar sobre todo el dominio, \\(X=\\mathbb{R}\\), y aún así converger a un valor: descartamos la medida de Lebesgue y cambiamos a la medida gaussiana. En términos de la integral de Riemann, significa que dejamos de tratar todos los valores de \\(X\\) por igual y agregamos un “factor de ponderación” que reducirá los valores de la función a medida que se acerquen al infinito. Nos queda así:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)g(x)dx = \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\lambda \\rightarrow \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\gamma_{\\mu,\\sigma}=\\int_{-\\infty}^{+\\infty}f(x)g(x)e^{-\\frac{(x-\\mu)^2}{\\sigma}}dx\n\\]\nEsta es la alternativa que elegiremos. Como veremos pronto, no será gratis.\n\n\n\n\nYa estamos listos para discutir lo que es el espacio de Cameron Martin. Antes de continuar, este es probablemente el mejor momento para presentar los operadores lineales. Los mencionamos brevemente en nuestro ejemplo de polinomios/vectores. Dijimos que podíamos crear una matriz (de tamaño infinito) para representar la derivada. En verdad, estas matrices también pueden considerarse funciones que transforman un vector en otro vector. Si esta transformación es lineal, entonces la matriz/función se denomina, como es de esperar, operador lineal o mapa lineal.\nUsaremos esta forma elegante de llamar a las matrices/funciones para definir una derivada en el sentido de Fréchet. El objetivo de Fréchet era extender la definición de derivada para que sirva para funciones que toman \\(m\\) variables como entrada y generan un vector de tamaño \\(n\\), siendo la derivada clásica el caso para \\(m=1,n=1\\). Aquí está la definición: dado dos espacios vectoriales normados \\(V\\) y \\(W\\), y un subconjunto \\(U \\subseteq V\\). Entonces \\(f: V \\rightarrow W\\) es diferenciable en el sentido de Fréchet para un \\(x \\in V\\) si hay un operador lineal \\(A: V \\rightarrow W\\) tal que\n\\[\n\\lim_{\\|h\\|\\rightarrow 0} \\frac{\\|f(x+h)-f(x)-Ah\\|_W}{\\|h\\|_V}=0\n\\]\ny \\(A=Df(x)\\) es la derivada de Fréchet. Esta fórmula se ve complicada pero, con un poco de álgebra y pasaje de términos, podemos obtener una fórmula más familiar y directa:\n\\[\nf(x+h) = f(x) + Ah\n\\]\nAl final, \\(A\\) es cuánto cambia la función con un pequeño desplazamiento \\(h\\).\nEsta definición especial de derivada te permite calcular la derivada de la norma \\(\\|\\,.\\|:H \\rightarrow \\mathbb{R}\\) alrededor de \\(x \\neq 0\\):\n\\[\nD_xv = \\left\\langle v, \\frac{x}{\\|x\\|} \\right\\rangle\n\\]\nEs decir, la derivada de la norma alrededor de \\(x\\), aplicada a un vector, es cuánto crece la longitud del vector en la dirección de \\(x\\), usando un vector de longitud 1 como regla.\n\n\n\nUn último punto sobre operadores es el operador adjunto. Tomemos un operador lineal \\(A:U\\rightarrow V\\), vectores \\(u \\in U, v \\in V\\) y un producto interno para \\(U\\) y \\(V\\). Entonces, el operador adjunto de \\(A\\), llamado \\(A^*: V \\rightarrow U\\) , es aquel que cumple:\n\\[\n\\langle Au, v \\rangle_V = \\langle u, A^* v \\rangle_U\n\\]\nEs importante remarcar que \\(A^*\\) no es una inversa, aunque \\(A^{**}=A\\), es más como un operador “acompañante” que se puede usar en lugar de \\(A\\) si estamos en el otro espacio vectorial.\n\n\n\nUna base tiene la propiedad de generar todos los elementos de un espacio vectorial por combinación lineal de sus elementos (linealmente independientes). También puede tener propiedades adicionales.\nUna base es “ortogonal” si \\(\\langle b_i, b_j \\rangle = 0 \\text{ if } i \\neq j\\) . Es decir, los diferentes elementos en la base no se “superponen” entre sí. Esto significa que podemos expresar cualquier vector \\(v\\) como una suma que depende únicamente de los vectores base y \\(v\\). En particular, si \\(B\\) es una base ortogonal de \\(V\\), entonces cualquier elemento \\(v\\) de \\(V\\) puede escribirse como:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\frac{\\langle b_i, x \\rangle}{\\|b_i\\|^2}}_{a_i}b_i\n\\]\nCon una base no ortogonal, se puede escribir una suma, pero para obtener los \\(a_i\\) hay que resolver un sistema de ecuaciones para cada vector. En cambio, usando una base ortogonal, se pueden obtener directamente de una operación que usa el vector y los elementos de la base.\nEsto puede ser incluso mejor si la base es “ortonormal”. Una base es ortonormal si es ortogonal y \\(\\langle b_i, b_i \\rangle = \\|b_i\\|^2=1\\) . En ese caso es aún más sencillo, solamente hace falta una única operación de producto interno para obtener el escalar que pertenece al elemento base:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\langle b_i, x \\rangle}_{a_i}b_i\n\\]\nUno puede preguntarse por qué no usamos bases ortonormales todo el tiempo y nos ahorraríamos todas las molestias. De hecho, podemos transformar una base en una base ortonormal usando el proceso de Gram-Schmidt. No explicaré el proceso, solo es importante que sepamos que se puede hacer.\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. «Infinite Dimensional Analysis». 2015. http://www.dm.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nSlater, Max. 2023. «Functions are Vectors». 2023. https://thenumb.at/Functions-are-Vectors."
  },
  {
    "objectID": "multidimensional.html#jerarquía-de-espacios",
    "href": "multidimensional.html#jerarquía-de-espacios",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Empezamos por el principio, por los espacios, especialmente los espacios sobre \\(\\mathbb{R}\\), el campo de los reales1. Un espacio es un conjunto \\(V\\), con elementos que llamaremos vectores, que viene equipado con dos operaciones:\n\nUna operación de “suma de vectores”, que devuelve otro vector. Es decir, \\(V_1 \\text{ '+' } V_2 = V_3\\)\nUna operación de “multiplicación por un escalar” que devuelve otro vector. Es decir, \\(k \\text{ '}*\\text{' } V_1 = V_2\\)\n\nUsamos las comillas porque no queremos imponer ninguna definición previa sobre qué son esas operaciones. Como mucho, diremos que deben observar ciertas propiedades como la conmutación (\\(V_1+V_2=V_2+V_1\\)). En la práctica, sin embargo, no seremos tan exóticos.\nAhora bien, también podemos dotar a los espacios de otras operaciones que nos permitirán medir distancias y longitudes (ojo, no en el sentído de Teoría de la Medida).\n\n\nUn espacio métrico es un espacio vectorial al que le han agregado una métrica o función de distancia \\(d(V,V) \\rightarrow \\mathbb{R}\\). Es decir, una función que toma dos vectores y devuelve un valor real y positivo, la “distancia” entre ellos. Sin embargo, no todas las funciones sirven:\n\nDeben ser simétricas, es decir \\(d(x,y)=d(y,x)\\)\nDeben devolver un valor positivo para vectores diferentes, o cero si ambos vectores son iguales\nDeben cumplir la “desigualdad del triángulo”. Es decir, la distancia entre dos vectores es mayor (o igual) que la suma de las distancias entre esos vectores y un vector intermedio.\n\nLas tres distancias más famosas son la distancia euclidiana o \\(d_2\\), la distancia del taxi o \\(d_1\\) y la distancia máxima o \\(d_\\infty\\). Estas son sus definiciones para vectores compuestos de \\(n\\) números reales:\n\\[\n\\begin{aligned}\nd_2(\\vec a,\\vec b) &= \\sqrt[2]{\\sum_{k=1}^n{\\left(a_k - b_k\\right)^2}} \\\\\\\\\nd_1(\\vec a,\\vec b) &= \\sum_{k=1}^n{\\left|a_k - b_k\\right|} \\\\\\\\\nd_\\infty(\\vec a,\\vec b) &= \\max_k{\\left|a_k - b_k\\right|}\n\\end{aligned}\n\\]\n\n\n\nSi a un espacio vectorial se le asocia una norma, se convierte en un espacio vectorial normado. Una norma es una operación que calcula la longitud de un vector y se denota como \\(\\|\\,.\\|:V\\rightarrow \\mathbb{R}\\). Como función, toma un único vector y devuelve un valor real y positivo. Nuevamente, no todas las funciones pueden ser normas:\n\nDeben devolver cero para el vector cero, o un valor positivo para los vectores distintos de cero\nDeben ser homogéneas. Es decir, un vector con componentes dos veces más grandes tendrá una longitud dos veces más grande, como en \\(\\| k\\cdot x\\|=|k|\\cdot\\|x\\|\\)\nDeben cumplir la desigualdad del triángulo. Es decir, la norma de una suma es menor o igual que la suma de las normas\n\nUn ejemplo clásico de normas es la familia de las \\(p\\)-normas. Para un vector de longitud \\(n\\):\n\\[\n\\|x\\|_p=\\sqrt[p]{\\sum_{i=1}^n\\left(|x_i|\\right)^p}\n\\]\nDe manera similar a lo anterior, la norma-1 es la norma del taxi \\(\\|x\\|_1=\\sum_{i=1}^n{|x_i|}\\), la norma-2 es la norma euclidiana y la norma-infinito es la norma del máximo. Todo esto suena parecido a las funciones distancia, y la similitud no es casual: se puede crear una métrica a partir de una norma si se define la función de distancia como la norma de la diferencia entre dos vectores. Por ejemplo, \\(d_1(a,b)=|a-b|_1\\) . Se dice que la métrica es inducida por la norma.\nSin embargo, lo opuesto no siempre es cierto. En general, una función de distancia no se puede convertir en una norma, a menos que:\n\nLa métrica sea invariante a traslaciones, es decir, \\(d(x,y)=d(x+a,y+a)\\)\nLa métrica sea homogénea, es decir, \\(d(kx, ky)=|k|\\cdot d(x,y)\\)\n\nEn ese caso, la métrica es inducida por la norma \\(\\|x\\|=d(x,0)\\).\n\n\n\nHay otro paso más en esta escalera. Podés equipar un espacio vectorial con una operación llamada producto interno o producto interior. Se denota \\(\\langle V,V\\rangle \\rightarrow\\mathbb{R}\\) y es, como la métrica, una función que toma dos vectores y devuelve un número real. Puede interpretarse como la longitud de un vector cuando se utiliza otro vector como regla. Sin embargo, como antes, también tiene ciertos requisitos:\n\nDebe ser simétrico, es decir, \\(\\langle x,y\\rangle=\\langle y,x\\rangle\\)\nDebe ser lineal en el primer argumento, es decir, \\(\\langle ix+jy,z\\rangle=i\\langle x,z\\rangle+j\\langle y,z\\rangle\\) . Dado que el producto interno es simétrico, esto también aplica para el segundo argumento.\nSi x es cero, \\(\\langle x,x\\rangle=0\\), de lo contrario, es un número estrictamente positivo.\n\nTodo producto interno induce una norma canónica \\(\\|x\\|=\\sqrt[2]{\\langle x, x \\rangle}\\), que a su vez induce una métrica. El ejemplo más común es el producto escalar. Para un vector de tamaño \\(n\\), sería:\n\\[\n\\langle x,y\\rangle=x^Ty=\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]"
  },
  {
    "objectID": "multidimensional.html#sec-infinite-dimensional-vector-spaces",
    "href": "multidimensional.html#sec-infinite-dimensional-vector-spaces",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "En las fórmulas anteriores, decimos que hay \\(n\\) componentes en nuestros vectores. Si queremos entender los espacios de Cameron Martin, necesitamos comparar distancias y longitudes de vectores de dimensiones potencialmente infinitas. Esto estará fuertemente inspirado en Slater (2023).\nVoy a asumir que sabés un poco sobre álgebra lineal. Por ejemplo, tomemos un espacio vectorial con vectores de esta forma:\n\\[\n\\begin{pmatrix}\na &b &c \\\\\n\\end{pmatrix},\\,\\text{ } a,b,c \\in \\mathbb{R}\n\\]\nDecimos que este espacio vectorial tiene dimensión 3 porque el número más pequeño de vectores que necesitamos para crear una combinación lineal de cada vector en ese espacio es 3. Esos vectores conforman una base, de la siguiente manera:\n\\[\n\\begin{aligned}\n\\begin{pmatrix}a &b &c\\end{pmatrix} =\\, &a \\begin{pmatrix}1 &0 &0\\end{pmatrix} + \\\\\n&b \\begin{pmatrix}0 &1 &0\\end{pmatrix} + \\\\\n&c \\begin{pmatrix}0 &0 &1\\end{pmatrix} \\\\\n\\end{aligned}\n\\]\nVeamos a un caso más interesante: un espacio vectorial que representa polinomios, hasta el grado \\(x^n, n \\in \\mathbb{N}\\). Esto significa que\n\\[\na_0 + a_1 x + ... + a_{n-1} x^{n-1} + a_n x^n \\rightarrow \\begin{pmatrix}a_0 &a_1 &... &a_{n-1} &a_n\\end{pmatrix}\n\\]\nPodemos ver que los polinomios se pueden sumar entre sí y que se pueden multiplicar por un número. Por lo tanto, podemos utilizarlos como vectores de un espacio vectorial en lugar de la fórmula del polinomio completo.\nDe hecho, no hay nada que nos impida decir que \\(n\\) es directamente tan grande como los números naturales \\(\\mathbb{N}\\), es decir que la base es de naturaleza infinita. Necesitamos, pues, una cantidad infinita de vectores para representar todos los polinomios posibles:\n\\[\n\\begin{aligned}\na_0 + a_1 x+ a_2x^2 +\\, ... \\rightarrow \\begin{pmatrix}a_0 &a_1 &a_2 &...\\end{pmatrix} =\\, &a_0 \\begin{pmatrix}1 &0 &0 &...\\end{pmatrix} + \\\\\n&a_1 \\begin{pmatrix}0 &1 &0 &...\\end{pmatrix} + \\\\\n&a_2 \\begin{pmatrix}0 &0 &1 &...\\end{pmatrix} +\\, ...\\\\\n\\end{aligned}\n\\]\nLa idea es rara pero no demasiado rara. Mucho de lo que ya sabíamos sobre vectores con dimensiones finitas se traduce a dimensiones infinitas. Por ejemplo, podemos aplicar una transformación lineal multiplicando estos vectores por una matriz igualmente infinita. Es posible que sepas que la derivada es una operación lineal, por lo que podemos representarla con una matriz que actúe sobre nuestro vector (que en realidad es un polinomio):\n\\[\n\\frac{\\partial }{\\partial{x}}\\left(a_0+a_1x+a_2x^2+...\\right)\n\\rightarrow\n\\begin{pmatrix}\n0 &1 &0 &0 &...\\\\\n0 &0 &2 &0 &...\\\\\n0 &0 &0 &3 &...\\\\\n0 &0 &0 &0 &...\\end{pmatrix}*\\begin{pmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\...\\end{pmatrix}=\\begin{pmatrix}a_1 \\\\ 2a_2 \\\\ 3a_3 \\\\...\\end{pmatrix}\n\\rightarrow\na_1+2a_2x+3a_3x^2+...\n\\]\n\n\nUna situación un poco más interesante es cuando evaluamos la norma o “longitud” de un elemento en estos espacios de dimensión infinita. Siguiendo un ejemplo de Alessandra Lunardi (2015), consideremos el espacio vectorial de las sucesiones infinitas de números reales, \\((a_i)\\), que se asignan a \\(\\mathbb{R}^{\\infty}\\). Cuando se trabaja con dimensiones finitas, las normas siempre darán un resultado finito. Este ya no es el caso con dimensiones infinitas. Por ejemplo, tomemos la secuencia armónica:\n\\[\n(b_k)_{k\\in\\mathbb{N}}, b_k=\\frac{1}{k} \\rightarrow \\begin{pmatrix}1 &\\frac{1}{2} &\\frac{1}{3} &...\\end{pmatrix}\n\\]\nCon la norma-1 nos queda:\n\\[\n\\|b\\|_1=\\lim_{n\\to \\infty}{\\sum_{k=1}^n |b_k|}=\\lim_{n\\to \\infty}{\\sum_{k=1}^n \\frac{1}{k}} \\rightarrow \\infty\n\\]\nNo podemos calcular una longitud para la sucesión porque la serie armónica diverge. Por el contrario, la norma euclidiana sí es capaz de calcular un valor porque la serie converge a un número real:\n\\[\n\\|b\\|_2=\\lim_{n\\to \\infty}{\\sqrt{\\sum_{k=1}^n {b_k}^2}}={\\sqrt{\\lim_{n\\to \\infty}\\sum_{k=1}^n \\frac{1}{k^2}}}=\\frac{\\pi}{\\sqrt6}\n\\]\nDebido a esto, los matemáticos denominan \\(\\ell^p\\) al espacio de aquellas sucesiones donde la norma-\\(p\\) converge a un valor. Alternativamente, podemos no lidiar con normas y definir solamente una función de distancia para el espacio, de esta manera:\n\\[\nd(x,y)=\\sum_{k=0}\\frac{1}{2^k}\\frac{|x_k-y_k|}{1+|x_k-y_k|}\n\\]\nEsto puede calcular una distancia entre dos sucesiones y converge siempre, pero esta métrica no es invariante a traslaciones y, por lo tanto, no tiene una norma equivalente.\n\n\n\nHasta ahora, hemos visto dimensiones infinitas numerables, con una base tan grande como los números naturales. Exploremos ahora una no numerable: un espacio de funciones. Sí, las funciones ahora son elementos de un espacio vectorial.\nPara que esto tenga algún sentido, vamos a empezar con un espacio vectorial con un producto interno, que es relativamente fácil de construir. Eso también nos dará la norma y la métrica de forma gratuita. Recordemos que para vectores de tamaño \\(n\\), hicimos \\(x^Ty\\). Entonces, en dimensiones infinitas, sería algo como:\n\\[\n\\begin{pmatrix}1 &3 &-2 &...\\end{pmatrix}\n*\n\\begin{pmatrix}0 \\\\ -1 \\\\ 3 \\\\...\\end{pmatrix}=1\\cdot0+3\\cdot(-1)+(-2)\\cdot3+...=\\lim_{n\\rightarrow\\infty}\\sum_{i=1}^n{(x_i \\cdot y_i)}\n\\]\nA medida que pasamos de \\(\\mathbb{N}\\) a \\(\\mathbb{R}\\), estas sumas se convertirán en integrales. En nuestro espacio vectorial de funciones definidas sobre un dominio genérico \\(X\\):\n\\[\n\\langle f,g \\rangle=\\int_Xf(x)g(x)dx\n\\]\nEsta definición cumple nuestras condiciones para un producto interno y, por lo tanto, induce una norma y una función de distancia:\n\\[\n\\begin{aligned}\n\\|f\\|&=\\left(\\int_X\\left[f(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\nd(f,g)&=\\left(\\int_X\\left[f(x)-g(x)\\right]^2dx\\right)^{\\frac{1}{2}} \\\\\n\\end{aligned}\n\\]\nPara redondear el concepto, se puede comprobar que también existen funciones para las que este producto interno, norma y métrica no puede calcular o converger a un valor. De la misma manera que \\(\\ell^p\\) restringe el espacio a sucesiones que devolvían un valor bajo la norma \\(p\\), también podemos restringir el espacio de funciones a aquellas que sí devuelven un valor bajo la norma-2 para funciones inducida anteriormente. El espacio se llama creativamente \\(L^p\\). Alternativamente, \\(L^p\\) se llama el espacio de funciones que son integrables en Lebesgue.\nEste espacio es realmente muy limitado cuando \\(X=\\mathbb{R}\\). No hay muchas funciones donde \\(\\int_{-\\infty}^{+\\infty}\\left[f(x)\\right]^2dx&lt;\\infty\\). Solo algunas funciones como \\(e^{-x^2}\\) pertenecen allí. Los polinomios, \\(e^x\\) o los logaritmos no están incluidos. Es por eso que la gente generalmente define el producto interno sobre un intervalo más pequeño, \\(X=[a,b]\\). Una norma como \\(\\int_{a}^{b}\\left[f(x)\\right]^2dx\\) admite muchas más funciones y es mucho más útil.\nHay una opción adicional que te permite integrar sobre todo el dominio, \\(X=\\mathbb{R}\\), y aún así converger a un valor: descartamos la medida de Lebesgue y cambiamos a la medida gaussiana. En términos de la integral de Riemann, significa que dejamos de tratar todos los valores de \\(X\\) por igual y agregamos un “factor de ponderación” que reducirá los valores de la función a medida que se acerquen al infinito. Nos queda así:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)g(x)dx = \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\lambda \\rightarrow \\int_{\\mathbb{R}}\\left[f\\cdot g\\right] d\\gamma_{\\mu,\\sigma}=\\int_{-\\infty}^{+\\infty}f(x)g(x)e^{-\\frac{(x-\\mu)^2}{\\sigma}}dx\n\\]\nEsta es la alternativa que elegiremos. Como veremos pronto, no será gratis."
  },
  {
    "objectID": "multidimensional.html#operadores-lineales-y-una-definición-alternativa-de-derivada",
    "href": "multidimensional.html#operadores-lineales-y-una-definición-alternativa-de-derivada",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Ya estamos listos para discutir lo que es el espacio de Cameron Martin. Antes de continuar, este es probablemente el mejor momento para presentar los operadores lineales. Los mencionamos brevemente en nuestro ejemplo de polinomios/vectores. Dijimos que podíamos crear una matriz (de tamaño infinito) para representar la derivada. En verdad, estas matrices también pueden considerarse funciones que transforman un vector en otro vector. Si esta transformación es lineal, entonces la matriz/función se denomina, como es de esperar, operador lineal o mapa lineal.\nUsaremos esta forma elegante de llamar a las matrices/funciones para definir una derivada en el sentido de Fréchet. El objetivo de Fréchet era extender la definición de derivada para que sirva para funciones que toman \\(m\\) variables como entrada y generan un vector de tamaño \\(n\\), siendo la derivada clásica el caso para \\(m=1,n=1\\). Aquí está la definición: dado dos espacios vectoriales normados \\(V\\) y \\(W\\), y un subconjunto \\(U \\subseteq V\\). Entonces \\(f: V \\rightarrow W\\) es diferenciable en el sentido de Fréchet para un \\(x \\in V\\) si hay un operador lineal \\(A: V \\rightarrow W\\) tal que\n\\[\n\\lim_{\\|h\\|\\rightarrow 0} \\frac{\\|f(x+h)-f(x)-Ah\\|_W}{\\|h\\|_V}=0\n\\]\ny \\(A=Df(x)\\) es la derivada de Fréchet. Esta fórmula se ve complicada pero, con un poco de álgebra y pasaje de términos, podemos obtener una fórmula más familiar y directa:\n\\[\nf(x+h) = f(x) + Ah\n\\]\nAl final, \\(A\\) es cuánto cambia la función con un pequeño desplazamiento \\(h\\).\nEsta definición especial de derivada te permite calcular la derivada de la norma \\(\\|\\,.\\|:H \\rightarrow \\mathbb{R}\\) alrededor de \\(x \\neq 0\\):\n\\[\nD_xv = \\left\\langle v, \\frac{x}{\\|x\\|} \\right\\rangle\n\\]\nEs decir, la derivada de la norma alrededor de \\(x\\), aplicada a un vector, es cuánto crece la longitud del vector en la dirección de \\(x\\), usando un vector de longitud 1 como regla."
  },
  {
    "objectID": "multidimensional.html#operadores-adjuntos",
    "href": "multidimensional.html#operadores-adjuntos",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Un último punto sobre operadores es el operador adjunto. Tomemos un operador lineal \\(A:U\\rightarrow V\\), vectores \\(u \\in U, v \\in V\\) y un producto interno para \\(U\\) y \\(V\\). Entonces, el operador adjunto de \\(A\\), llamado \\(A^*: V \\rightarrow U\\) , es aquel que cumple:\n\\[\n\\langle Au, v \\rangle_V = \\langle u, A^* v \\rangle_U\n\\]\nEs importante remarcar que \\(A^*\\) no es una inversa, aunque \\(A^{**}=A\\), es más como un operador “acompañante” que se puede usar en lugar de \\(A\\) si estamos en el otro espacio vectorial."
  },
  {
    "objectID": "multidimensional.html#ortonormalización",
    "href": "multidimensional.html#ortonormalización",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Una base tiene la propiedad de generar todos los elementos de un espacio vectorial por combinación lineal de sus elementos (linealmente independientes). También puede tener propiedades adicionales.\nUna base es “ortogonal” si \\(\\langle b_i, b_j \\rangle = 0 \\text{ if } i \\neq j\\) . Es decir, los diferentes elementos en la base no se “superponen” entre sí. Esto significa que podemos expresar cualquier vector \\(v\\) como una suma que depende únicamente de los vectores base y \\(v\\). En particular, si \\(B\\) es una base ortogonal de \\(V\\), entonces cualquier elemento \\(v\\) de \\(V\\) puede escribirse como:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\frac{\\langle b_i, x \\rangle}{\\|b_i\\|^2}}_{a_i}b_i\n\\]\nCon una base no ortogonal, se puede escribir una suma, pero para obtener los \\(a_i\\) hay que resolver un sistema de ecuaciones para cada vector. En cambio, usando una base ortogonal, se pueden obtener directamente de una operación que usa el vector y los elementos de la base.\nEsto puede ser incluso mejor si la base es “ortonormal”. Una base es ortonormal si es ortogonal y \\(\\langle b_i, b_i \\rangle = \\|b_i\\|^2=1\\) . En ese caso es aún más sencillo, solamente hace falta una única operación de producto interno para obtener el escalar que pertenece al elemento base:\n\\[\nv = \\sum_{b_i \\in B}a_i b_i = \\sum_{b_i \\in B} \\underbrace{\\langle b_i, x \\rangle}_{a_i}b_i\n\\]\nUno puede preguntarse por qué no usamos bases ortonormales todo el tiempo y nos ahorraríamos todas las molestias. De hecho, podemos transformar una base en una base ortonormal usando el proceso de Gram-Schmidt. No explicaré el proceso, solo es importante que sepamos que se puede hacer.\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. «Infinite Dimensional Analysis». 2015. http://www.dm.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nSlater, Max. 2023. «Functions are Vectors». 2023. https://thenumb.at/Functions-are-Vectors."
  },
  {
    "objectID": "multidimensional.html#footnotes",
    "href": "multidimensional.html#footnotes",
    "title": "Espacios vectoriales de dimensión infinita",
    "section": "",
    "text": "Una advertencia: algunas de estas propiedades no se aplican al campo de los números complejos \\(\\mathbb{C}\\), pero no las trataremos acá.↩︎"
  },
  {
    "objectID": "malliavinderivative.html",
    "href": "malliavinderivative.html",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Ahora que establecimos que las direcciones de Cameron-Martin nos permiten cambiar las integrales bajo medidas gaussianas, estamos listos para definir la derivada de Malliavin. Podemos hacerlo desde dos enfoques:\n\nPodemos hablar de caos polinómico y luego llegar a la derivada\nDefinimos la derivada y no hacemos referencia alguna al caos polinómico\n\nSeguiremos el segundo enfoque por razones pedagógicas, recopilando todo lo que hemos aprendido. Después de eso, seguiremos a Friz (2002) y Alos (2021) para ponerlo en terminos más concretos.\n\n\nHemos acumulado una gran cantidad de conocimiento. Es hora de que abordemos el objetivo de este ensayo. Cuando planteamos la Pregunta, mencionamos que la derivada de una variable aleatoria que sigue un movimiento browniano con respecto al tiempo no se puede calcular, ese era todo el punto: ¿Qué tipo de derivada podemos calcular?\nConsideremos una dirección de Cameron-Martin de \\(\\hat{h}(\\tau)=\\int_0^\\tau h\\,dt\\). Además, \\(\\hat{h}\\in\\hat{H}\\) , el espacio de Cameron-Martin. Esta definición nos permite tener una derivada en el tiempo para la dirección, por lo que \\(\\frac{\\partial \\hat{h}(\\tau)}{\\partial \\tau}=h\\) , con \\(h\\in H = L^2[0,1]\\), el espacio de funciones que son continuas entre 0 y 1, y que permiten una norma-21.\nLas trayectorias de movimiento browniano hasta \\(\\tau\\) se denotarán como \\(\\omega(\\tau)\\). La función \\(1_{[0,\\tau]}\\) es una función que es \\(1\\) en el intervalo indicado y \\(0\\) en el resto del intervalo, comportándose como un filtro. Finalmente, definiremos una función como \\(W(1_{[0,\\tau]})\\) como una integral de Ito del filtro. También utilizaremos \\(B_t\\) y \\(dB_t\\) para hacer referencia a los movimientos brownianos, junto con \\(W_t\\) y \\(dW_t\\).\nNuestro último ingrediente es una función polinómica2 \\(f\\) que toma \\(n\\) movimientos brownianos como variables, cada uno deteniéndose en un momento diferente. Dos movimientos brownianos desde \\(0\\) hasta \\(t\\) son esencialmente iguales, incluso si sus trayectorias son diferentes. Así, cada movimiento browniano irá de \\(0\\) a \\(t_1\\) , \\(t_2\\), … \\(t_n\\). Esta función \\(f\\) es por el momento bastante básica. Encontraremos su uso y extensiones más adelante.\nAhora, haremos algo como en la sección de cálculo de variaciones. Planteamos \\(f(\\omega + \\varepsilon \\hat{h})\\). Esto significa que estamos moviendo cada una de las \\(n\\) trayectorias del movimiento browniano un poco a lo largo de una dirección de Cameron-Martin, por lo que es una traslación aceptable. Finalmente, tomamos la derivada con respecto a \\(\\varepsilon\\) , y evaluamos la derivada en \\(\\varepsilon = 0\\). Los movimientos brownianos, que no se pueden derivar, no se tocan porque no dependen de \\(\\varepsilon\\).\nY aquí está el resultado final:\n\\[\n\\begin{aligned}\n\\left.\\frac{d}{d\\varepsilon}F(\\omega + \\varepsilon \\hat{h})\\right|_{\\varepsilon=0} &=\\left[\\sum_{i=1}^n\\partial_i f(\\omega(t_1)+ \\varepsilon \\hat{h},\\omega(t_2)+ \\varepsilon \\hat{h},\\,...\\,,\\omega(t_n)+ \\varepsilon \\hat{h})\\int_0^{t_i}h\\,d\\lambda \\right]_{\\varepsilon=0} \\\\\n&=\\sum_{i=1}^n\\partial_i f(\\omega(t_1),\\omega(t_2),\\,...\\,,\\omega(t_n))\\int_0^{t_i}h\\,d\\lambda \\\\\n&=\\langle DF,h \\rangle_H\n\\end{aligned}\n\\]\nDefinimos \\(DF\\) como:\n\\[\nDF = \\sum_i\\partial_if(W(1_{[0,\\tau_1]}),\\,...\\,,W(1_{[0,\\tau_n]}))1_{[0,\\tau_i]}\n\\]\nO su extensión alternativa:\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))h_i\n\\]\nhaciendo que \\(DF\\) sea una variable aleatoria con valores de \\(H\\).\n\n\n\nEsta \\(D\\) es la derivada de Malliavin. Es un operador lineal (como los que vimos antes) y se aplica a la función \\(F\\). Significa que si tenés una función \\(F\\) con variables compuestas por estos movimientos brownianos multiplicados por estas funciones \\(h_i\\), entonces se puede aplicar esta definición de derivada.\nEsta \\(F\\) parece muy limitada ahora mismo, pero si se pudiera representar, aproximar o encontrar una equivalencia entre la variable aleatoria de interés y una función como \\(F\\), entonces se podría aplicar la derivada a la equivalencia. La teoría se ocupa de encontrar esas conexiones, no nos molestaremos en hacerlo aquí.\nLlegados a este punto, la colección de funciones \\(h_i\\) son un requisito teórico y parecen salidas de la nada. Por un lado, no son más arbitrarias que el desplazamiento \\(h\\) de la definición clásica de derivada \\(\\lim_{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}\\). En los textos que vienen, seleccionaremos las \\(h_i \\in H\\) que sean adecuadas para nuestros propósitos. Fuentes más teóricas pueden establecer que las \\(h_i\\) son ortonormales (o pueden volverse ortonormales), especialmente bajo un producto interno con un ponderador gaussiano. En vez de eso, tomamos la opción más directa y más simple: usaremos una única función \\(h=1_{[0,1]}\\), es decir, una función que es \\(1\\) en el intervalo de integración y \\(0\\) en el resto. Esto ayuda cuando la función está dentro de una integral porque “corta” o “filtra” el dominio de integración, como en este ejemplo:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x,t)\\cdot1_{[0,1]}(x)\\,dx = \\int_0^1f(x,t)\\,dx\n\\]\nUn segundo interrogante es si el intervalo \\(\\left[ 0 , 1 \\right]\\) es un límite fundamental o si podemos extenderlo al menos hasta \\(\\left[0,T\\right]\\), que es lo que vemos en procesos estocásticos comunes y corrientes. Todos los autores que se centran en los aspectos teóricos de la derivada se mantienen en ese intervalo, tratando aparentemente a \\(1\\) como un límite convencional. Por otro lado, Alos (2021) lo extiende a \\(T\\). Por lo tanto, a partir de ahora usamos, basándonos puramente en la conveniencia, tanto \\(h = 1_{[0,T]}\\) como \\(h = 1_{[0,1]}\\) .\n\n\n\nAhora, comencemos con un ejemplo muy simple. Calculemos la derivada de Malliavin de un proceso de Wiener/movimiento browniano:\n\\[\nF=W(h)=\\int_0^1h\\,dB\n\\]\nSea \\(h\\) una función de \\(L^2\\) en el intervalo \\(\\left[0,1\\right]\\), como hemos definido anteriormente. En este caso, la derivada de Malliavin es:\n\\[\nDF=D(W(h))=h\n\\]\nUna buena regla mnemotécnica: esto es como si hiciéramos \\(\\frac{\\partial F}{\\partial W}\\cdot h\\) en lugar de \\(\\frac{\\partial F}{\\partial t}\\) (algo que sabemos que no podemos hacer). Es decir, esto es cuánto cambia la función a medida que cambia el movimiento browniano subyacente (en la dirección de Cameron-Martin). Aquí hay un gráfico de cómo se ven las diferentes opciones de \\(h(t)\\) y un ejemplo/realización de \\(W(h(t))\\):\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndBt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\n\n# Left\nh_1 &lt;- Vectorize(function(x) 1)\nh_hat_1 &lt;- cumsum(h_1(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_1, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_1(t), colour = \"h = 1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCódigo\n# Middle\nh_2 &lt;- Vectorize(function(x) x)\nh_hat_2 &lt;- cumsum(h_2(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_2, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_2(t), colour = \"h = t\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCódigo\n# Right\nh_3 &lt;- Vectorize(function(x) x**2 - 1)\nh_hat_3 &lt;- cumsum(h_3(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_3, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_3(t), colour = \"h = t²-1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nEl caso simple también significa que podemos reescribir nuestra definición original como\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))D(W(h_i))\n\\]\nque se ve como una regla de la cadena normal. No voy a demostrarlo, pero la regla del producto también es exactamente como lo que esperamos:\n\\[\nD(FG) = FD(G) + GD(F)\n\\]\nAhora, usaremos otro ejemplo simple, un movimiento browniano al cuadrado:\n\\[\nF(t)=(W_t)^2\n\\]\nEn este caso, usamos \\(h(s)=1_{[0,t]}(s)\\). Observemos que en realidad hay dos variables relacionadas con el tiempo: una es la \\(t\\) original a la que se refiere \\(F(t)\\), y la segunda es la introducida por la derivada de Malliavin, a la que llamaremos \\(s\\) . Con esto en mente, estamos listos para brindar una respuesta:\n\\[\nD_sF=2\\,W_t \\, (DW_t)=2\\,W_t\\,h=2\\,W_t\\,1_{[0,t]}(s)\n\\]\nHay dos cosas para destacar acá. En primer lugar, la derivada toma valores distintos de cero solo cuando \\(0&lt;s&lt;t\\), y esto tiene sentido: no esperamos que la función \\(F\\) cambie más allá del tiempo \\(t\\) en el que se evalúa. En segundo lugar, esto también significa que cuando graficamos \\(W(h(t))\\) y \\(h(t)\\) juntos, fue un poco impreciso porque estábamos asumiendo \\(s=t\\) para poder dibujarlos juntos. Aun así, creo que ese supuesto nos permite ver que hay cierta conexión entre la derivada de Malliavin y la “varianza instantánea” o volatilidad del proceso: cuanto más cerca está la derivada de \\(0\\), las perturbaciones o movimientos son menores en el proceso estocástico. Graficaré ahora una trayectoria de ejemplo para \\(F\\) y \\(DF\\), con \\(t \\in [0,1]\\) y \\(s=t\\) (que, nuevamente, no es la imagen completa, pero me parece útil para conectar los puntos):\n\n\nCódigo\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndWt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\nWt &lt;- cumsum(dWt)\nf &lt;- Wt**2\nDf &lt;- 2*Wt\n\n# Plot\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y = f, colour=\"W(t)²\"),linetype = 2) + \n  geom_line(mapping = aes(y = Df, colour=\"DW(s=t)\"), linewidth = 0.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\n\n\n\nDijimos que los operadores lineales vienen con un operador adjunto. Las derivadas de Malliavin no son la excepción y, dado que definimos \\(D\\) con un producto interno y una función \\(h\\) en \\(\\langle DF, h \\rangle_H\\), buscaremos un operador adjunto, al que llamamos \\(\\delta\\), de modo que:\n\\[\n\\langle DF, h \\rangle_H = \\langle F, \\delta(h)\\rangle_{{R}^{\\,n}}\n\\]\nPodemos encontrarlo haciendo un poco de manipulación, tomando algunos atajos y renunciando a cierto rigor matemático. A partir de la definición anterior y suponiendo que \\(h=h_1\\), tomamos el valor esperado del producto interno, realizamos integración por partes y algunos reemplazos y obtendremos:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[{\\langle DF, h \\rangle_H}\\right] &= \\mathbb{E}\\left[{\\sum_i \\partial_i f \\langle h_i, h \\rangle_H}\\right] \\\\\n&= \\int_{\\mathbb{R}^n} \\underbrace{\\partial_1 f(x)}_{dv}(2\\pi)^{-n/2}\\underbrace{e^{-\\|x\\|/2}}_{u} dx \\\\\n&= -\\int_{\\mathbb{R}^n} f(x) (-x_1) \\underbrace{(2\\pi)^{-n/2}e^{-\\|x\\|/2} dx}_{\\text{Medida gaussiana}} \\\\\n&= \\int_{\\mathbb{R}^n} x_1 f(x) d\\mu_1 \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h_1)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\int_0^1 h dB}\\right]\n\\end{aligned}\n\\]\nEsto significa que la esperanza matemática de la variable aleatoria \\(DF\\) medida usando la función \\(h\\) entre \\(0\\) y \\(1\\) como regla, tiene el mismo valor que la esperanza de \\(F\\) multiplicado por esa integral de \\(h\\) a la derecha. Estamos dando a entender que el operador \\(\\delta\\) es esa integral. A esta integral se la llama la integral de Skorohod, y coincide con una integral de Ito para procesos no anticipativos3:\n\\[\n\\delta(h) = \\int_0^1 h dB_t\n\\]\nA estas alturas, probablemente hayas notado lo común que es invertir integrales y derivadas mediante integración por partes.\n\n\n\nPor fin llegamos a una definición de la derivada de Malliavin. Nos ha llevado un tiempo, pero ahora estamos en una posición cómoda para usarla para algo útil.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. «An Introduction to Malliavin Calculus». En. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "malliavinderivative.html#fundamentos-de-la-derivada-de-malliavin",
    "href": "malliavinderivative.html#fundamentos-de-la-derivada-de-malliavin",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Hemos acumulado una gran cantidad de conocimiento. Es hora de que abordemos el objetivo de este ensayo. Cuando planteamos la Pregunta, mencionamos que la derivada de una variable aleatoria que sigue un movimiento browniano con respecto al tiempo no se puede calcular, ese era todo el punto: ¿Qué tipo de derivada podemos calcular?\nConsideremos una dirección de Cameron-Martin de \\(\\hat{h}(\\tau)=\\int_0^\\tau h\\,dt\\). Además, \\(\\hat{h}\\in\\hat{H}\\) , el espacio de Cameron-Martin. Esta definición nos permite tener una derivada en el tiempo para la dirección, por lo que \\(\\frac{\\partial \\hat{h}(\\tau)}{\\partial \\tau}=h\\) , con \\(h\\in H = L^2[0,1]\\), el espacio de funciones que son continuas entre 0 y 1, y que permiten una norma-21.\nLas trayectorias de movimiento browniano hasta \\(\\tau\\) se denotarán como \\(\\omega(\\tau)\\). La función \\(1_{[0,\\tau]}\\) es una función que es \\(1\\) en el intervalo indicado y \\(0\\) en el resto del intervalo, comportándose como un filtro. Finalmente, definiremos una función como \\(W(1_{[0,\\tau]})\\) como una integral de Ito del filtro. También utilizaremos \\(B_t\\) y \\(dB_t\\) para hacer referencia a los movimientos brownianos, junto con \\(W_t\\) y \\(dW_t\\).\nNuestro último ingrediente es una función polinómica2 \\(f\\) que toma \\(n\\) movimientos brownianos como variables, cada uno deteniéndose en un momento diferente. Dos movimientos brownianos desde \\(0\\) hasta \\(t\\) son esencialmente iguales, incluso si sus trayectorias son diferentes. Así, cada movimiento browniano irá de \\(0\\) a \\(t_1\\) , \\(t_2\\), … \\(t_n\\). Esta función \\(f\\) es por el momento bastante básica. Encontraremos su uso y extensiones más adelante.\nAhora, haremos algo como en la sección de cálculo de variaciones. Planteamos \\(f(\\omega + \\varepsilon \\hat{h})\\). Esto significa que estamos moviendo cada una de las \\(n\\) trayectorias del movimiento browniano un poco a lo largo de una dirección de Cameron-Martin, por lo que es una traslación aceptable. Finalmente, tomamos la derivada con respecto a \\(\\varepsilon\\) , y evaluamos la derivada en \\(\\varepsilon = 0\\). Los movimientos brownianos, que no se pueden derivar, no se tocan porque no dependen de \\(\\varepsilon\\).\nY aquí está el resultado final:\n\\[\n\\begin{aligned}\n\\left.\\frac{d}{d\\varepsilon}F(\\omega + \\varepsilon \\hat{h})\\right|_{\\varepsilon=0} &=\\left[\\sum_{i=1}^n\\partial_i f(\\omega(t_1)+ \\varepsilon \\hat{h},\\omega(t_2)+ \\varepsilon \\hat{h},\\,...\\,,\\omega(t_n)+ \\varepsilon \\hat{h})\\int_0^{t_i}h\\,d\\lambda \\right]_{\\varepsilon=0} \\\\\n&=\\sum_{i=1}^n\\partial_i f(\\omega(t_1),\\omega(t_2),\\,...\\,,\\omega(t_n))\\int_0^{t_i}h\\,d\\lambda \\\\\n&=\\langle DF,h \\rangle_H\n\\end{aligned}\n\\]\nDefinimos \\(DF\\) como:\n\\[\nDF = \\sum_i\\partial_if(W(1_{[0,\\tau_1]}),\\,...\\,,W(1_{[0,\\tau_n]}))1_{[0,\\tau_i]}\n\\]\nO su extensión alternativa:\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))h_i\n\\]\nhaciendo que \\(DF\\) sea una variable aleatoria con valores de \\(H\\)."
  },
  {
    "objectID": "malliavinderivative.html#qué-acaba-de-pasar",
    "href": "malliavinderivative.html#qué-acaba-de-pasar",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Esta \\(D\\) es la derivada de Malliavin. Es un operador lineal (como los que vimos antes) y se aplica a la función \\(F\\). Significa que si tenés una función \\(F\\) con variables compuestas por estos movimientos brownianos multiplicados por estas funciones \\(h_i\\), entonces se puede aplicar esta definición de derivada.\nEsta \\(F\\) parece muy limitada ahora mismo, pero si se pudiera representar, aproximar o encontrar una equivalencia entre la variable aleatoria de interés y una función como \\(F\\), entonces se podría aplicar la derivada a la equivalencia. La teoría se ocupa de encontrar esas conexiones, no nos molestaremos en hacerlo aquí.\nLlegados a este punto, la colección de funciones \\(h_i\\) son un requisito teórico y parecen salidas de la nada. Por un lado, no son más arbitrarias que el desplazamiento \\(h\\) de la definición clásica de derivada \\(\\lim_{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}\\). En los textos que vienen, seleccionaremos las \\(h_i \\in H\\) que sean adecuadas para nuestros propósitos. Fuentes más teóricas pueden establecer que las \\(h_i\\) son ortonormales (o pueden volverse ortonormales), especialmente bajo un producto interno con un ponderador gaussiano. En vez de eso, tomamos la opción más directa y más simple: usaremos una única función \\(h=1_{[0,1]}\\), es decir, una función que es \\(1\\) en el intervalo de integración y \\(0\\) en el resto. Esto ayuda cuando la función está dentro de una integral porque “corta” o “filtra” el dominio de integración, como en este ejemplo:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x,t)\\cdot1_{[0,1]}(x)\\,dx = \\int_0^1f(x,t)\\,dx\n\\]\nUn segundo interrogante es si el intervalo \\(\\left[ 0 , 1 \\right]\\) es un límite fundamental o si podemos extenderlo al menos hasta \\(\\left[0,T\\right]\\), que es lo que vemos en procesos estocásticos comunes y corrientes. Todos los autores que se centran en los aspectos teóricos de la derivada se mantienen en ese intervalo, tratando aparentemente a \\(1\\) como un límite convencional. Por otro lado, Alos (2021) lo extiende a \\(T\\). Por lo tanto, a partir de ahora usamos, basándonos puramente en la conveniencia, tanto \\(h = 1_{[0,T]}\\) como \\(h = 1_{[0,1]}\\) ."
  },
  {
    "objectID": "malliavinderivative.html#ejemplos",
    "href": "malliavinderivative.html#ejemplos",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Ahora, comencemos con un ejemplo muy simple. Calculemos la derivada de Malliavin de un proceso de Wiener/movimiento browniano:\n\\[\nF=W(h)=\\int_0^1h\\,dB\n\\]\nSea \\(h\\) una función de \\(L^2\\) en el intervalo \\(\\left[0,1\\right]\\), como hemos definido anteriormente. En este caso, la derivada de Malliavin es:\n\\[\nDF=D(W(h))=h\n\\]\nUna buena regla mnemotécnica: esto es como si hiciéramos \\(\\frac{\\partial F}{\\partial W}\\cdot h\\) en lugar de \\(\\frac{\\partial F}{\\partial t}\\) (algo que sabemos que no podemos hacer). Es decir, esto es cuánto cambia la función a medida que cambia el movimiento browniano subyacente (en la dirección de Cameron-Martin). Aquí hay un gráfico de cómo se ven las diferentes opciones de \\(h(t)\\) y un ejemplo/realización de \\(W(h(t))\\):\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndBt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\n\n# Left\nh_1 &lt;- Vectorize(function(x) 1)\nh_hat_1 &lt;- cumsum(h_1(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_1, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_1(t), colour = \"h = 1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCódigo\n# Middle\nh_2 &lt;- Vectorize(function(x) x)\nh_hat_2 &lt;- cumsum(h_2(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_2, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_2(t), colour = \"h = t\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nCódigo\n# Right\nh_3 &lt;- Vectorize(function(x) x**2 - 1)\nh_hat_3 &lt;- cumsum(h_3(t) * dBt)\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y=h_hat_3, colour=\"W(h)\"),linetype = 2) + \n  geom_line(mapping = aes(y = h_3(t), colour = \"h = t²-1\"), linewidth = 1.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))\n\n\n\n\n\nEl caso simple también significa que podemos reescribir nuestra definición original como\n\\[\nDF = \\sum_i\\partial_if(W(h_1),\\,...\\,,W(h_n))D(W(h_i))\n\\]\nque se ve como una regla de la cadena normal. No voy a demostrarlo, pero la regla del producto también es exactamente como lo que esperamos:\n\\[\nD(FG) = FD(G) + GD(F)\n\\]\nAhora, usaremos otro ejemplo simple, un movimiento browniano al cuadrado:\n\\[\nF(t)=(W_t)^2\n\\]\nEn este caso, usamos \\(h(s)=1_{[0,t]}(s)\\). Observemos que en realidad hay dos variables relacionadas con el tiempo: una es la \\(t\\) original a la que se refiere \\(F(t)\\), y la segunda es la introducida por la derivada de Malliavin, a la que llamaremos \\(s\\) . Con esto en mente, estamos listos para brindar una respuesta:\n\\[\nD_sF=2\\,W_t \\, (DW_t)=2\\,W_t\\,h=2\\,W_t\\,1_{[0,t]}(s)\n\\]\nHay dos cosas para destacar acá. En primer lugar, la derivada toma valores distintos de cero solo cuando \\(0&lt;s&lt;t\\), y esto tiene sentido: no esperamos que la función \\(F\\) cambie más allá del tiempo \\(t\\) en el que se evalúa. En segundo lugar, esto también significa que cuando graficamos \\(W(h(t))\\) y \\(h(t)\\) juntos, fue un poco impreciso porque estábamos asumiendo \\(s=t\\) para poder dibujarlos juntos. Aun así, creo que ese supuesto nos permite ver que hay cierta conexión entre la derivada de Malliavin y la “varianza instantánea” o volatilidad del proceso: cuanto más cerca está la derivada de \\(0\\), las perturbaciones o movimientos son menores en el proceso estocástico. Graficaré ahora una trayectoria de ejemplo para \\(F\\) y \\(DF\\), con \\(t \\in [0,1]\\) y \\(s=t\\) (que, nuevamente, no es la imagen completa, pero me parece útil para conectar los puntos):\n\n\nCódigo\n# Setup\nsteps = 100000\nh &lt;- 1/steps\nt &lt;- seq(from = 0, to = 1, length.out=steps)\ndWt &lt;- c(0, rnorm(n=(steps-1),mean = 0,sd = sqrt(h)))\nWt &lt;- cumsum(dWt)\nf &lt;- Wt**2\nDf &lt;- 2*Wt\n\n# Plot\nggplot(mapping = aes(x = t)) +\n  xlab('Tiempo') +\n  ylab('f(t)') +\n  geom_line(mapping = aes(y = f, colour=\"W(t)²\"),linetype = 2) + \n  geom_line(mapping = aes(y = Df, colour=\"DW(s=t)\"), linewidth = 0.25) + \n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"red\"))"
  },
  {
    "objectID": "malliavinderivative.html#integral-de-skorohod-y-más-integración-por-partes",
    "href": "malliavinderivative.html#integral-de-skorohod-y-más-integración-por-partes",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Dijimos que los operadores lineales vienen con un operador adjunto. Las derivadas de Malliavin no son la excepción y, dado que definimos \\(D\\) con un producto interno y una función \\(h\\) en \\(\\langle DF, h \\rangle_H\\), buscaremos un operador adjunto, al que llamamos \\(\\delta\\), de modo que:\n\\[\n\\langle DF, h \\rangle_H = \\langle F, \\delta(h)\\rangle_{{R}^{\\,n}}\n\\]\nPodemos encontrarlo haciendo un poco de manipulación, tomando algunos atajos y renunciando a cierto rigor matemático. A partir de la definición anterior y suponiendo que \\(h=h_1\\), tomamos el valor esperado del producto interno, realizamos integración por partes y algunos reemplazos y obtendremos:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[{\\langle DF, h \\rangle_H}\\right] &= \\mathbb{E}\\left[{\\sum_i \\partial_i f \\langle h_i, h \\rangle_H}\\right] \\\\\n&= \\int_{\\mathbb{R}^n} \\underbrace{\\partial_1 f(x)}_{dv}(2\\pi)^{-n/2}\\underbrace{e^{-\\|x\\|/2}}_{u} dx \\\\\n&= -\\int_{\\mathbb{R}^n} f(x) (-x_1) \\underbrace{(2\\pi)^{-n/2}e^{-\\|x\\|/2} dx}_{\\text{Medida gaussiana}} \\\\\n&= \\int_{\\mathbb{R}^n} x_1 f(x) d\\mu_1 \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h_1)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\,W(h)}\\right] \\\\\n&= \\mathbb{E} \\left[{ F\\int_0^1 h dB}\\right]\n\\end{aligned}\n\\]\nEsto significa que la esperanza matemática de la variable aleatoria \\(DF\\) medida usando la función \\(h\\) entre \\(0\\) y \\(1\\) como regla, tiene el mismo valor que la esperanza de \\(F\\) multiplicado por esa integral de \\(h\\) a la derecha. Estamos dando a entender que el operador \\(\\delta\\) es esa integral. A esta integral se la llama la integral de Skorohod, y coincide con una integral de Ito para procesos no anticipativos3:\n\\[\n\\delta(h) = \\int_0^1 h dB_t\n\\]\nA estas alturas, probablemente hayas notado lo común que es invertir integrales y derivadas mediante integración por partes."
  },
  {
    "objectID": "malliavinderivative.html#y-ahora-qué",
    "href": "malliavinderivative.html#y-ahora-qué",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "Por fin llegamos a una definición de la derivada de Malliavin. Nos ha llevado un tiempo, pero ahora estamos en una posición cómoda para usarla para algo útil.\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. «An Introduction to Malliavin Calculus». En. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "malliavinderivative.html#footnotes",
    "href": "malliavinderivative.html#footnotes",
    "title": "Derivada de Malliavin",
    "section": "",
    "text": "En términos más formales, podemos considerar esta traslación:\n\\[\nT_{\\hat{h}}(\\omega)=\\omega + \\varepsilon\\int_0^\\tau h = \\omega + \\varepsilon\\hat{h}\n\\]\nY el cambio de medida/variable, es decir, nuestra derivada de Radon-Nikodym, será:\n\\[\n\\frac{d(T_{\\hat{h}})_{*} W}{dW}(\\omega) = \\exp \\left( \\int_0^1 h d\\beta(\\omega) - \\frac{1}{2} \\int_0^1 h^2 d\\lambda \\right)\n\\]\nFinalmente, sin pérdida de generalidad, podemos suponer que \\(\\|h\\|=1\\) y que todos los \\(h_i\\) sean ortonormales en \\(H\\). Esta es seguro de suponer debido a la ortonormalización de Gram-Schmidt.↩︎\nUna función con crecimiento polinómico también es aceptable. Las condiciones para esta función pertenecen a la teoría y no aportan claridad pedagógica.↩︎\nFormalmente, se trata de procesos predecibles o adaptados. Un proceso predecible tiene un valor en \\(t\\) conocido en momentos anteriores a \\(t\\) (por ejemplo, una función no aleatoria). Un proceso adaptado tiene un valor en \\(t\\) conocido en \\(t\\) o posterior (por ejemplo, el precio de una acción). Los procesos no adaptados, o procesos anticipativos, solo se conocen después de que haya pasado algún tiempo, y su información depende del futuro (por ejemplo, que una granizada se produzca en los próximos 7 días).↩︎"
  },
  {
    "objectID": "integrationbyparts.html",
    "href": "integrationbyparts.html",
    "title": "Integración por Partes",
    "section": "",
    "text": "Empezamos este viaje hablando de un truco que podría interpretarse como el inverso de la regla del producto para las derivadas. Lo usaremos para describir una forma novedosa de resolver el problema de minimizar funciones. Finalmente, usando Wikipedia contributors (2023) como base, haremos un desarrollo clásico.\n\n\nUsaremos el símbolo \\('\\) para indicar la derivada con respecto a \\(x\\). Si sabés lo básico de cálculo diferencial, vas a recordar que:\n\\[\n\\left( f(x)g(x)\\right)'=f'(x)g(x)+f(x)g'(x)\n\\]\nAhora, integrando a ambos lados:\n\\[\n\\begin{aligned}\n\\int\\left( f(x)g(x)\\right)'dx&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx \\\\\nf(x)g(x)&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx\n\\end{aligned}\n\\]\nSi renombramos \\(u=f(x)\\) y \\(dv = g'(x)dx\\), entonces obtenemos las expresiones familiares para integrales definidas e indefinidas:\n\\[\n\\begin{aligned}\n\\int u\\,dv &= uv -\\int v\\,du \\\\\n\\int_a^b u\\,dv &= \\left.{uv}\\right|_a^b -\\int_a^bv\\,du\n\\end{aligned}\n\\]\nFinalmente, imaginá que las funciones tienden a cero en los extremos \\(a\\) y \\(b\\). Es decir, \\(u(b)v(b)-u(a)v(a)=0\\). En ese caso, se puede simplificar la expresión aún más:\n\\[\n\\int u\\,dv = -\\int v\\,du\n\\]\n\n\n\nEl Cálculo Malliavin a veces se lo llama la extensión del cálculo de variaciones a procesos estocásticos. ¿Qué significa eso? Vamos a empezar por la primera parte.\n\n\nVoy a asumir que sabés lo más básico de cálculo diferencial e integral. Eso significa que podés resolver problemas como este: supongamos que tenemos una función \\(f\\) y que queremos obtener el valor de \\(x\\) donde \\(f\\) alcanza su mínimo:\n\\[\n\\min{f(x)}=x^2-4x+5\n\\]\nPara resolver esto, derivamos e igualamos a cero. Con esto, obtenemos el valor del argumento que minimiza la función.\n\\[\n\\begin{aligned}\nf'(x)=2x-4 &= 0 \\\\\n2x &= 4 \\\\\nx &= 2\n\\end{aligned}\n\\]\nEsto significa que \\(\\min{f(x)}=f(2)=2^2-4*2+5=1\\).\nEste método funciona bien cuando se trata de minimizar el valor de una función sobre los números reales, \\(f: \\mathbb{R} \\to \\mathbb{R}\\), o en general para funciones de más de una variable, \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\).\nPero digamos que lo que queremos encontrar es la función \\(y=f(x)\\) que minimiza una expresión. No sabemos cómo es esa función, o no queremos imponer ideas preconcebidas como que sea un polinomio o una suma de pares de senos y cosenos. ¿Qué hacemos entonces?\nA partir de ahora, entramos en piloto automático para cualquier curso en la materia (yo usaré como base el artículo de Wikipedia sobre el tema). El primer paso es definir una “función de funciones” como el punto de partida para la minimización, y esa función es esencialmente una integral como esta:\n\\[\nJ[y]=\\int^{x_2}_{x_1} L(x,y,y')dx \\\\\n\\]\nPara que todo sea menos abstracto, usaremos el ejemplo clásico de encontrar la función que representa la distancia más corta entre dos puntos, \\(a\\) y \\(b\\). Empezando por el caso “de grano grueso” con deltas o intervalos, lo que queremos es minimizar la suma de todos los pequeños cambios en el camino entre esos dos puntos, usando el teorema de Pitágoras:\n\\[\n\\min\\sum^n_{i=1}\\sqrt{ (\\Delta x_i)^2+(\\Delta y_i)^2}\n\\]\nA medida que los cambios se vuelven infinitesimales, y haciendo un abuso de notación, podemos cambiar de sumas a una integral y obtener una expresión para \\(L\\):\n\\[\n\\begin{aligned}\n\\int^{b}_{a} \\sqrt{{dx}^2+{dy}^2}\n& = \\int^{b}_{a} \\sqrt{{(dx)}^2\\left ( 1+\\left({\\frac{dy}{dx}}\\right)^2\\right)} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\sqrt{(dx)^2} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\,dx \\\\\n& = \\int^{b}_{a}L(y')\\,dx\\\\\n\\end{aligned}\n\\]\nAhora, introducimos una función genérica \\(\\eta(x)\\) que llamaremos la variación. Esta función representa una perturbación y el único requisito que le impondremos es que \\(\\eta(a)=\\eta(b)=0\\). Vamos a asumir que \\(f(x)=y\\) es la solución y \\(\\eta\\) es la desviación que la función tiene con respecto a la solución. Además, podemos multiplicar la variación por un número pequeño \\(\\varepsilon\\). Finalmente, podemos definir una función sobre \\(\\varepsilon\\), \\(\\Phi(\\varepsilon)= J[f + \\varepsilon *\\eta]\\), de modo tal que \\(\\Phi(0)=f\\) termina siendo nuestra solución.\nEl truco es que, ahora, en vez de minimizar algo que depende de una función que no conocemos (y que ni siquiera podemos empezar a comprender), podemos minimizar algo que depende de un número, \\(\\varepsilon\\). No solo eso, hemos construido \\(\\varepsilon\\) y \\(\\eta\\) para que sepamos de antemano que la función que estamos buscando, la solución, se encuentra en \\(\\Phi(\\varepsilon=0)=J[f]\\), y también que \\(\\Phi'(0)=0\\) porque esa función está en su mínimo. Una genialidad.\n\\[\n\\Phi'(0)=0=\\left.\\frac{d\\Phi}{d\\varepsilon}\\right|_{\\varepsilon=0}=\\int^{b}_{a}\\left. \\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon=0} dx\n\\]\nTomamos la derivada total de \\(\\Phi\\) con respecto a \\(\\varepsilon\\), como hicimos antes, pero ahora consideramos los cambios de variables \\(y=f+\\varepsilon\\eta\\) y \\(y'=f'+\\varepsilon\\eta'\\):\n\\[\n\\begin{aligned}\n\\frac{dL}{d\\varepsilon}\n& = \\frac{\\partial L}{\\partial x}\\underbrace{\\frac{dx}{d\\varepsilon}}_{=0} + \\frac{\\partial L}{\\partial y}\\underbrace{\\frac{dy}{d\\varepsilon}}_{=\\eta} + \\frac{\\partial L}{\\partial y'}\\underbrace{\\frac{dy'}{d\\varepsilon}}_{=\\eta'}\\\\\n& = \\frac{\\partial L}{\\partial y}\\eta + \\frac{\\partial L}{\\partial y'}\\eta'\\\\\n\\end{aligned}\n\\]\nEsto parece no tener sentido, pero ahora viene la magia:\n\\[\n\\begin{aligned}\n\\int_{a}^{b} \\left.\\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon = 0} dx\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta + \\frac{\\partial L}{\\partial f'} \\eta'\\right)\\, dx \\\\\n&  = \\int_{a}^{b} \\frac{\\partial L}{\\partial f} \\eta \\, dx + \\underbrace{\\left.\\frac{\\partial L}{\\partial f'} \\eta \\right|_{a}^{b}}_{=0} - \\int_{a}^{b} \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\, dx \\\\\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta - \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right)\\, dx\\\\\n0 &= \\int_{a}^{b} \\eta (x) \\left(\\frac{\\partial L}{\\partial f} - \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right) \\, dx \\\\\n\\end{aligned}\n\\]\nEmpezamos obteniendo \\(\\Phi'(0)\\) e hicimos una integración por partes. Esto es crucial, sin ella nada de esto funciona. También sabemos que \\(\\eta(a)=\\eta(b)=0\\), entonces ese término se cancela. Uniendo términos y tomando un factor común, llegamos a nuestra conclusión. La última pieza de magia es darse cuenta que esa integral es cero, para cualquier función \\(\\eta(x)\\). Por el Lema Fundamental del Cálculo de Variaciones, solo queda una posibilidad, y es tan importante que se llama la ecuación de Euler-Lagrange:\n\\[\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}=0\n\\]\nSea cual sea la función solución \\(f\\), debe cumplir esa condición.\n\n\n\n¿Para qué nos sirve esto? Volvamos al caso del camino más corto entre dos puntos. Usaré en forma indistinta \\(f=y\\). Lo último que habíamos concluído era que:\n\\[\nL(f') = \\sqrt{1+(f')^2}\n\\]\nAplicamos la ecuación de Euler-Lagrange y veremos a dónde nos conduce. Lo que hace que el ejemplo sea muy sencillo es que no hay un \\(f\\) explícito en la función, solo un \\(f'\\), y la fórmula queda muy simple:\n\\[\n\\begin{aligned}\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}&=0\\\\\n- \\frac{d}{dx} \\ \\frac{f'(x)} {\\sqrt{1 + [f'(x)]^2}} \\ &= 0\\\\\n\\end{aligned}\n\\]\nSi la derivada es cero, podemos integrar esa expresión y el resultado es una constante (desconocida) \\(c&lt;1\\). Hacemos un poco de álgebra, integramos al final, y listo:\n\\[\n\\begin{aligned}\n\\frac{f'(x)}{\\sqrt{1+[f'(x)]^2}} &= c \\\\\n\\frac{[f'(x)]^2}{1+[f'(x)]^2} &= c^2 \\\\\n{[f'(x)]}^2 &= c^2 + c^2{[f'(x)]}^2 \\\\\n{[f'(x)]}^2 &= \\frac{c^2}{1-c^2} \\\\\nf'(x) &= \\sqrt{\\frac{c^2}{1-c^2}} = m \\\\\nf(x) &= mx+b\n\\end{aligned}\n\\]\nLa función con el camino más corto entre dos puntos es una linea recta, y lo único necesario para obtener la solución analítica es saber cómo se calcula la distancia entre dos puntos.\n\n\n\n\n\nWikipedia contributors. 2023. «Calculus of variations — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Calculus_of_variations."
  },
  {
    "objectID": "integrationbyparts.html#esbozo-para-obtener-la-fórmula-de-integración-por-partes",
    "href": "integrationbyparts.html#esbozo-para-obtener-la-fórmula-de-integración-por-partes",
    "title": "Integración por Partes",
    "section": "",
    "text": "Usaremos el símbolo \\('\\) para indicar la derivada con respecto a \\(x\\). Si sabés lo básico de cálculo diferencial, vas a recordar que:\n\\[\n\\left( f(x)g(x)\\right)'=f'(x)g(x)+f(x)g'(x)\n\\]\nAhora, integrando a ambos lados:\n\\[\n\\begin{aligned}\n\\int\\left( f(x)g(x)\\right)'dx&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx \\\\\nf(x)g(x)&=\\int f'(x)g(x)dx+\\int f(x)g'(x)dx\n\\end{aligned}\n\\]\nSi renombramos \\(u=f(x)\\) y \\(dv = g'(x)dx\\), entonces obtenemos las expresiones familiares para integrales definidas e indefinidas:\n\\[\n\\begin{aligned}\n\\int u\\,dv &= uv -\\int v\\,du \\\\\n\\int_a^b u\\,dv &= \\left.{uv}\\right|_a^b -\\int_a^bv\\,du\n\\end{aligned}\n\\]\nFinalmente, imaginá que las funciones tienden a cero en los extremos \\(a\\) y \\(b\\). Es decir, \\(u(b)v(b)-u(a)v(a)=0\\). En ese caso, se puede simplificar la expresión aún más:\n\\[\n\\int u\\,dv = -\\int v\\,du\n\\]"
  },
  {
    "objectID": "integrationbyparts.html#cálculo-de-variaciones",
    "href": "integrationbyparts.html#cálculo-de-variaciones",
    "title": "Integración por Partes",
    "section": "",
    "text": "El Cálculo Malliavin a veces se lo llama la extensión del cálculo de variaciones a procesos estocásticos. ¿Qué significa eso? Vamos a empezar por la primera parte.\n\n\nVoy a asumir que sabés lo más básico de cálculo diferencial e integral. Eso significa que podés resolver problemas como este: supongamos que tenemos una función \\(f\\) y que queremos obtener el valor de \\(x\\) donde \\(f\\) alcanza su mínimo:\n\\[\n\\min{f(x)}=x^2-4x+5\n\\]\nPara resolver esto, derivamos e igualamos a cero. Con esto, obtenemos el valor del argumento que minimiza la función.\n\\[\n\\begin{aligned}\nf'(x)=2x-4 &= 0 \\\\\n2x &= 4 \\\\\nx &= 2\n\\end{aligned}\n\\]\nEsto significa que \\(\\min{f(x)}=f(2)=2^2-4*2+5=1\\).\nEste método funciona bien cuando se trata de minimizar el valor de una función sobre los números reales, \\(f: \\mathbb{R} \\to \\mathbb{R}\\), o en general para funciones de más de una variable, \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\).\nPero digamos que lo que queremos encontrar es la función \\(y=f(x)\\) que minimiza una expresión. No sabemos cómo es esa función, o no queremos imponer ideas preconcebidas como que sea un polinomio o una suma de pares de senos y cosenos. ¿Qué hacemos entonces?\nA partir de ahora, entramos en piloto automático para cualquier curso en la materia (yo usaré como base el artículo de Wikipedia sobre el tema). El primer paso es definir una “función de funciones” como el punto de partida para la minimización, y esa función es esencialmente una integral como esta:\n\\[\nJ[y]=\\int^{x_2}_{x_1} L(x,y,y')dx \\\\\n\\]\nPara que todo sea menos abstracto, usaremos el ejemplo clásico de encontrar la función que representa la distancia más corta entre dos puntos, \\(a\\) y \\(b\\). Empezando por el caso “de grano grueso” con deltas o intervalos, lo que queremos es minimizar la suma de todos los pequeños cambios en el camino entre esos dos puntos, usando el teorema de Pitágoras:\n\\[\n\\min\\sum^n_{i=1}\\sqrt{ (\\Delta x_i)^2+(\\Delta y_i)^2}\n\\]\nA medida que los cambios se vuelven infinitesimales, y haciendo un abuso de notación, podemos cambiar de sumas a una integral y obtener una expresión para \\(L\\):\n\\[\n\\begin{aligned}\n\\int^{b}_{a} \\sqrt{{dx}^2+{dy}^2}\n& = \\int^{b}_{a} \\sqrt{{(dx)}^2\\left ( 1+\\left({\\frac{dy}{dx}}\\right)^2\\right)} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\sqrt{(dx)^2} \\\\\n& = \\int^{b}_{a} \\sqrt{1+(y')^2}\\,dx \\\\\n& = \\int^{b}_{a}L(y')\\,dx\\\\\n\\end{aligned}\n\\]\nAhora, introducimos una función genérica \\(\\eta(x)\\) que llamaremos la variación. Esta función representa una perturbación y el único requisito que le impondremos es que \\(\\eta(a)=\\eta(b)=0\\). Vamos a asumir que \\(f(x)=y\\) es la solución y \\(\\eta\\) es la desviación que la función tiene con respecto a la solución. Además, podemos multiplicar la variación por un número pequeño \\(\\varepsilon\\). Finalmente, podemos definir una función sobre \\(\\varepsilon\\), \\(\\Phi(\\varepsilon)= J[f + \\varepsilon *\\eta]\\), de modo tal que \\(\\Phi(0)=f\\) termina siendo nuestra solución.\nEl truco es que, ahora, en vez de minimizar algo que depende de una función que no conocemos (y que ni siquiera podemos empezar a comprender), podemos minimizar algo que depende de un número, \\(\\varepsilon\\). No solo eso, hemos construido \\(\\varepsilon\\) y \\(\\eta\\) para que sepamos de antemano que la función que estamos buscando, la solución, se encuentra en \\(\\Phi(\\varepsilon=0)=J[f]\\), y también que \\(\\Phi'(0)=0\\) porque esa función está en su mínimo. Una genialidad.\n\\[\n\\Phi'(0)=0=\\left.\\frac{d\\Phi}{d\\varepsilon}\\right|_{\\varepsilon=0}=\\int^{b}_{a}\\left. \\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon=0} dx\n\\]\nTomamos la derivada total de \\(\\Phi\\) con respecto a \\(\\varepsilon\\), como hicimos antes, pero ahora consideramos los cambios de variables \\(y=f+\\varepsilon\\eta\\) y \\(y'=f'+\\varepsilon\\eta'\\):\n\\[\n\\begin{aligned}\n\\frac{dL}{d\\varepsilon}\n& = \\frac{\\partial L}{\\partial x}\\underbrace{\\frac{dx}{d\\varepsilon}}_{=0} + \\frac{\\partial L}{\\partial y}\\underbrace{\\frac{dy}{d\\varepsilon}}_{=\\eta} + \\frac{\\partial L}{\\partial y'}\\underbrace{\\frac{dy'}{d\\varepsilon}}_{=\\eta'}\\\\\n& = \\frac{\\partial L}{\\partial y}\\eta + \\frac{\\partial L}{\\partial y'}\\eta'\\\\\n\\end{aligned}\n\\]\nEsto parece no tener sentido, pero ahora viene la magia:\n\\[\n\\begin{aligned}\n\\int_{a}^{b} \\left.\\frac{dL}{d\\varepsilon}\\right|_{\\varepsilon = 0} dx\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta + \\frac{\\partial L}{\\partial f'} \\eta'\\right)\\, dx \\\\\n&  = \\int_{a}^{b} \\frac{\\partial L}{\\partial f} \\eta \\, dx + \\underbrace{\\left.\\frac{\\partial L}{\\partial f'} \\eta \\right|_{a}^{b}}_{=0} - \\int_{a}^{b} \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\, dx \\\\\n&  = \\int_{a}^{b} \\left(\\frac{\\partial L}{\\partial f} \\eta - \\eta \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right)\\, dx\\\\\n0 &= \\int_{a}^{b} \\eta (x) \\left(\\frac{\\partial L}{\\partial f} - \\frac{d}{dx}\\frac{\\partial L}{\\partial f'} \\right) \\, dx \\\\\n\\end{aligned}\n\\]\nEmpezamos obteniendo \\(\\Phi'(0)\\) e hicimos una integración por partes. Esto es crucial, sin ella nada de esto funciona. También sabemos que \\(\\eta(a)=\\eta(b)=0\\), entonces ese término se cancela. Uniendo términos y tomando un factor común, llegamos a nuestra conclusión. La última pieza de magia es darse cuenta que esa integral es cero, para cualquier función \\(\\eta(x)\\). Por el Lema Fundamental del Cálculo de Variaciones, solo queda una posibilidad, y es tan importante que se llama la ecuación de Euler-Lagrange:\n\\[\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}=0\n\\]\nSea cual sea la función solución \\(f\\), debe cumplir esa condición.\n\n\n\n¿Para qué nos sirve esto? Volvamos al caso del camino más corto entre dos puntos. Usaré en forma indistinta \\(f=y\\). Lo último que habíamos concluído era que:\n\\[\nL(f') = \\sqrt{1+(f')^2}\n\\]\nAplicamos la ecuación de Euler-Lagrange y veremos a dónde nos conduce. Lo que hace que el ejemplo sea muy sencillo es que no hay un \\(f\\) explícito en la función, solo un \\(f'\\), y la fórmula queda muy simple:\n\\[\n\\begin{aligned}\n\\frac{\\partial L}{\\partial f} -\\frac{d}{dx} \\frac{\\partial L}{\\partial f'}&=0\\\\\n- \\frac{d}{dx} \\ \\frac{f'(x)} {\\sqrt{1 + [f'(x)]^2}} \\ &= 0\\\\\n\\end{aligned}\n\\]\nSi la derivada es cero, podemos integrar esa expresión y el resultado es una constante (desconocida) \\(c&lt;1\\). Hacemos un poco de álgebra, integramos al final, y listo:\n\\[\n\\begin{aligned}\n\\frac{f'(x)}{\\sqrt{1+[f'(x)]^2}} &= c \\\\\n\\frac{[f'(x)]^2}{1+[f'(x)]^2} &= c^2 \\\\\n{[f'(x)]}^2 &= c^2 + c^2{[f'(x)]}^2 \\\\\n{[f'(x)]}^2 &= \\frac{c^2}{1-c^2} \\\\\nf'(x) &= \\sqrt{\\frac{c^2}{1-c^2}} = m \\\\\nf(x) &= mx+b\n\\end{aligned}\n\\]\nLa función con el camino más corto entre dos puntos es una linea recta, y lo único necesario para obtener la solución analítica es saber cómo se calcula la distancia entre dos puntos.\n\n\n\n\n\nWikipedia contributors. 2023. «Calculus of variations — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Calculus_of_variations."
  },
  {
    "objectID": "clarkocone.html",
    "href": "clarkocone.html",
    "title": "Aplicaciones y casos en profundidad",
    "section": "",
    "text": "Hasta ahora, el cálculo de Malliavin ha sido principalmente un juego o procedimiento que aplicamos a procesos estocásticos. Profundicemos más y obtendremos a algunos resultados interesantes.\n\n\nSupongamos un proceso aleatorio \\(N_t\\) que fluctúa alrededor de un valor \\(\\mu\\) y se corrige a sí mismo con mayor intensidad mientras mayor sea la distancia a \\(\\mu\\), más algo de ruido. En términos de ecuaciones, queremos algo como esto:\n\\[\ndN_t = \\theta(\\mu - N_t)\\,dt+ \\sigma\\,dW_t\n\\]\nPor ejemplo, digamos que un lago puede albergar alrededor de \\(\\mu=1000\\) truchas. Si hay más que eso, algunas morirán de hambre y, si hay menos, se reproducirán. Finalmente, \\(\\theta\\) controla cuán fuerte es la corrección. A continuación, se muestran algunas trayectorias poblacionales con \\(\\theta=1\\) y diferentes valores para \\(\\sigma\\):\n\n\nCódigo\nlibrary(ggplot2)\n\n# Right\ndt &lt;- 0.01\ntotal_time &lt;- 10\nN_0 &lt;- 10\nmu_ou &lt;- 1000.0\ntetha_ou &lt;- 1.0\n\nsteps = total_time / dt\ntimes &lt;- seq(from = 0, to = total_time, length.out=steps)\nstretched_times &lt;- times * tetha_ou\ndBt &lt;- rnorm(steps,mean = 0, sd = sqrt(dt))\n\ndf &lt;- data.frame(\n  time=stretched_times\n)\n\nsigma_ou &lt;- 0\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_0 &lt;- N\n\nsigma_ou &lt;- 100\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_100 &lt;- N\n\nsigma_ou &lt;- 250\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_250 &lt;- N\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlab('Tiempo') +\n  ylab('N(t)') +\n  geom_line(mapping = aes(y=N_100, colour=\"σ=100\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_250, colour=\"σ=250\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_0, colour=\"σ=0\"),linewidth = 1) +\n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"darkgray\",\"darkviolet\"))\n\n\n\n\n\nEste es un proceso muy común, tanto que ya tiene un nombre propio: el proceso de Ornstein-Uhlenbeck. Ahora, calculemos su derivada \\(DN\\). Tenemos \\(a(X) = \\theta(\\mu - X)\\) y \\(b(x) = \\sigma\\), por lo que no es un proceso de Ito sencillo que solo depende del tiempo. Es mejor comenzar con ellos antes de abordar el proceso de Ornstein-Uhlenbeck.\nRecordemos que podemos dividir las integrales como \\(\\int_0^t... dW_t=\\sum_{i=1}^n{ ...(W_{t_i}-W_{t_{i-1}})}\\). Entonces, podemos transformar un proceso de Ito clásico \\(X_t\\) en algo a lo que podemos aplicar fácilmente las reglas de la cadena y del producto para la derivada de Malliavin:\n\\[\n\\begin{aligned}\nX_t &= \\sum_{i=1}^n \\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i}(W_{t_i}-W_{t_{i-1}}) \\\\\nD_rX_t &= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n D_r[\\sigma_{t_i}\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i} \\cdot 1_{[t_{i-1},t_{i}]}(r) + \\sum_{i=1}^n D_r(\\sigma_{t_i})\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\int_0^t D_r\\mu_s\\,ds + \\sigma_r 1_{[0,t]}(r) + \\int_0^t D_r\\sigma_s\\,dW_s \\\\\n\\end{aligned}\n\\]\nSe ve un poco caótico, pero todo es como podríamos esperar: \\(t\\) es el valor terminal de ambas integrales, \\(s\\) es la variable que usamos para integrar de \\(0\\) a \\(t\\), y \\(r\\) es la variable que introdujimos con la derivada de Malliavin. La expresión tiene sentido: la influencia de \\(\\sigma\\) en el proceso de Ito es la misma a lo largo de todo el recorrido del proceso de Ito.\nAhora, usamos un argumento similar para la cantidad de truchas en el lago, que evoluciona según un proceso de Ornstein-Uhlenbeck. Dado que \\(\\mu_s\\) y \\(\\sigma_s\\) son ahora \\(a(s,X_s)\\) y \\(b(s,X_s)\\), aplicamos las reglas de la cadena y del producto como se indicó anteriormente para llegar a:\n\\[\nD_rX_t = \\int_r^t \\frac{\\partial a}{\\partial x}(s, X_s)\\,D_rX_s\\,ds + b(r,X_r)1_{[0,t]}(r) + \\int_r^t \\frac{\\partial b}{\\partial x}(s, X_s)\\,D_rX_s\\,dW_s \\\\\n\\]\nAhora, sabemos por lo anterior que \\(\\frac{\\partial a}{\\partial x} = -\\theta\\) y \\(\\frac{\\partial b}{\\partial x} = 0\\), entonces reemplazamos y, suponiendo que sabemos resolver ecuaciones integrales, resolvemos:\n\\[\n\\begin{aligned}\nD_rN_t &= \\int_r^t (-\\theta)\\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= -\\theta\\int_r^t \\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= \\sigma\\,e^{-\\theta(t-r)}\n\\end{aligned}\n\\]\nEn este caso, llegamos a una expresión linda que nos dice algo interesante: el efecto de una perturbación en el número de truchas es exponencialmente menor si \\(r&lt;&lt;t\\). Esto tiene sentido: la población de truchas \\(N\\) quiere estar cerca de \\(\\mu\\) y la población de un pasado lejano es irrelevante. También nos dice que no hay aleatoriedad en la fluctuación porque no depende de una variable aleatoria como \\(W_t\\).\nFinalmente, tuvimos suerte arriba. \\(D_rN_t\\) es simple y pudimos escribir una solución en forma analítica. Si fuera más complicada, probablemente sea mejor estimar una solución. Alos (2021) hace un gran trabajo mostrando lo anterior.\n\n\n\nVeamos una aplicación relativamente simple con implicaciones muy profundas, siguiendo completamente el planteo descripto en Friz (2002). Consideremos esta función:\n\\[\nF(t) = e^{\\int_0^t h\\,dB - \\frac{1}{2}\\int_0^t{h^2}d\\lambda}\n\\]\nEsta función es una martingala exponencial, es decir, \\(\\mathbb{E}_s[F(t)]=F(s)\\). A continuación, tomamos \\(F(1) = \\mathcal{E}(h)\\) y calculamos \\(DF\\) :\n\\[\n\\begin{aligned}\nD_tF &= e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot D_t(e^{\\int_0^1 h\\,dB}) \\\\\n&= \\underbrace{e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot e^{\\int_0^1 h\\,dB}}_{F} \\cdot h(t) \\\\\n&= Fh(t)\n\\end{aligned}\n\\]\nAhora bien, esto sólo es válido en \\(t=1\\), pero podemos usar el operador de esperanza y la propiedad de las martingalas para obtener los valores en un tiempo anterior. Llamaremos \\(\\mathcal{F}_s\\) a la filtración hasta el tiempo \\(s\\) (la forma a la que llamamos a la “historia” o “información” conocida hasta el tiempo \\(s\\)), y luego:\n\\[\n\\begin{aligned}\n\\mathbb{E}[D_t F | \\mathcal{F}_t] &= \\mathbb{E}[F(1)h(t)|\\mathcal{F_t}] \\\\\n&=h(t) \\mathbb{E}[F(1)|\\mathcal{F_t}] \\\\\n&=h(t) F(t)\n\\end{aligned}\n\\]\nPor último, esta martingala \\(F(t)\\) es la solución de la ecuación diferencial (estocástica) \\(dF(t) = h(t)F(t)dB_t\\), cuando \\(F(0)=1=\\mathbb{E}[F]\\). Reemplazando con la expresión anterior obtenemos:\n\\[\n\\begin{aligned}\nF(t) &= \\mathbb{E}[F] + \\int_0^1  h(t)F(t) dB_t \\\\\n&= \\mathbb{E}[F] + \\int_0^1 \\mathbb{E}[D_t F | \\mathcal{F_t}] dB_t\n\\end{aligned}\n\\]\nEsta es la fórmula de Clark-Ocone en todo su esplendor. Nos permite calcular en forma explícita lo que el Teorema de Representación en Martingala indicaba que debía existir. La derivada de Malliavin es el ingrediente clave para tener una expresión analítica y es la razón principal por la que a uno le interesaría. La expresión nos afirma que cualquier variable aleatoria indexada por el tiempo \\(F_t\\) se puede dividir en una suma de una parte “determinista” (su esperanza matemática), y una martingala que fluctúa alrededor de ella.\nPodemos aplicar esto al proceso de Ornstein-Uhlenbeck para nuestra población de truchas. Sabemos de antes que \\(D_rN_t = \\sigma\\,e^{-\\theta(t-r)}\\). Vemos que no hay \\(W_t\\), por lo que la esperanza es la derivada de Malliavin, directamente. Podríamos estimar el valor de \\(\\mathbb{E}[N]\\) o intentar resolver la ecuación diferencial (estocástica), pero dado que el proceso ya tiene una solución conocida, voy a ahorrarnos el esfuerzo y usarla directamente. Aquí está la aplicación de Clark-Ocone para un proceso de Ornstein-Uhlenbeck:\n\\[\n\\begin{aligned}\nN(t) &= \\mathbb{E}[N] + \\int_0^t \\mathbb{E_r}[D_r N_t] dW_r \\\\\n&= \\underbrace{X_0e^{-\\theta t} + \\mu(1-e^{-\\theta t})}_{Determinístico} + \\underbrace{\\int_0^t \\sigma\\,e^{-\\theta(t-r)}\\,dW_r}_{Martingala} \\\\\n\\end{aligned}\n\\]\n¿Por qué nos importa esto? Bueno, si quisiéramos simular diferentes trayectorias de nuestra población de truchas \\(N\\), solo necesitamos simular la martingala, y la parte determinista solo se calcula una vez. En segundo lugar, podemos usar la fórmula de Clark-Ocone para calcular directamente la varianza para \\(N\\), sin conocer la solución analítica completa que usamos arriba. Recordemos que \\(\\mathbb{Var}[N]=\\mathbb{E}[N-\\mathbb{E}[N]]^2\\), entonces, usando la isometría de Ito:\n\\[\n\\begin{aligned}\n\\mathbb{Var}[N]&=\\mathbb{E}\\left[\\left(\\int_0^t \\mathbb{E_r}[D_r N_t] dW_r\\right)^2\\right] \\\\\n&=\\mathbb{E}\\left[\\int_0^t \\left(\\sigma\\,e^{-\\theta(t-r)}\\right)^2dr\\right] \\\\\n&=\\sigma^2\\mathbb{E}\\left[\\int_0^t e^{2\\theta(r-t)}dr\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\mathbb{E}\\left[1-e^{-2\\theta t}\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\left(1-e^{-2\\theta t}\\right)\n\\end{aligned}\n\\]\nTengamos en cuenta que esto funciona para cualquier variable: solo se necesita la derivada de Malliavin para obtener la varianza. Vemos arriba que:\n\nNuestra población de truchas \\(N\\) en el largo plazo (\\(t \\rightarrow \\infty\\)) será un proceso que se mueve alrededor de \\(\\mu\\) con una varianza constante \\(\\frac{\\sigma^2}{2\\theta}\\)\nLa varianza en el momento de la introducción de las truchas al lago (\\(t \\approx 0\\)) es muy pequeña porque el crecimiento de \\(N\\), que intenta alcanzar \\(\\mu\\) lo antes posible, predomina por encima del ruido normal del proceso\nUn \\(\\theta\\) grande no solo hará que la varianza de largo plazo llegue antes, sino que también evitará grandes desviaciones de \\(\\mu\\) en el largo plazo\n\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. «An Introduction to Malliavin Calculus». En. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "clarkocone.html#derivada-de-malliavin-del-proceso-de-ornstein-uhlenbeck",
    "href": "clarkocone.html#derivada-de-malliavin-del-proceso-de-ornstein-uhlenbeck",
    "title": "Aplicaciones y casos en profundidad",
    "section": "",
    "text": "Supongamos un proceso aleatorio \\(N_t\\) que fluctúa alrededor de un valor \\(\\mu\\) y se corrige a sí mismo con mayor intensidad mientras mayor sea la distancia a \\(\\mu\\), más algo de ruido. En términos de ecuaciones, queremos algo como esto:\n\\[\ndN_t = \\theta(\\mu - N_t)\\,dt+ \\sigma\\,dW_t\n\\]\nPor ejemplo, digamos que un lago puede albergar alrededor de \\(\\mu=1000\\) truchas. Si hay más que eso, algunas morirán de hambre y, si hay menos, se reproducirán. Finalmente, \\(\\theta\\) controla cuán fuerte es la corrección. A continuación, se muestran algunas trayectorias poblacionales con \\(\\theta=1\\) y diferentes valores para \\(\\sigma\\):\n\n\nCódigo\nlibrary(ggplot2)\n\n# Right\ndt &lt;- 0.01\ntotal_time &lt;- 10\nN_0 &lt;- 10\nmu_ou &lt;- 1000.0\ntetha_ou &lt;- 1.0\n\nsteps = total_time / dt\ntimes &lt;- seq(from = 0, to = total_time, length.out=steps)\nstretched_times &lt;- times * tetha_ou\ndBt &lt;- rnorm(steps,mean = 0, sd = sqrt(dt))\n\ndf &lt;- data.frame(\n  time=stretched_times\n)\n\nsigma_ou &lt;- 0\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_0 &lt;- N\n\nsigma_ou &lt;- 100\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_100 &lt;- N\n\nsigma_ou &lt;- 250\nN &lt;- rep_len(x = N_0, length.out = length(times))\nfor (i in (2:length(times))) {\n  N[i] &lt;- N[i-1] + tetha_ou * (mu_ou - N[i-1]) * dt + sigma_ou * dBt[i]\n}\ndf$N_250 &lt;- N\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlab('Tiempo') +\n  ylab('N(t)') +\n  geom_line(mapping = aes(y=N_100, colour=\"σ=100\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_250, colour=\"σ=250\"),linewidth = 1) + \n  geom_line(mapping = aes(y=N_0, colour=\"σ=0\"),linewidth = 1) +\n  scale_colour_manual(\"Funciones\",values=c(\"black\",\"darkgray\",\"darkviolet\"))\n\n\n\n\n\nEste es un proceso muy común, tanto que ya tiene un nombre propio: el proceso de Ornstein-Uhlenbeck. Ahora, calculemos su derivada \\(DN\\). Tenemos \\(a(X) = \\theta(\\mu - X)\\) y \\(b(x) = \\sigma\\), por lo que no es un proceso de Ito sencillo que solo depende del tiempo. Es mejor comenzar con ellos antes de abordar el proceso de Ornstein-Uhlenbeck.\nRecordemos que podemos dividir las integrales como \\(\\int_0^t... dW_t=\\sum_{i=1}^n{ ...(W_{t_i}-W_{t_{i-1}})}\\). Entonces, podemos transformar un proceso de Ito clásico \\(X_t\\) en algo a lo que podemos aplicar fácilmente las reglas de la cadena y del producto para la derivada de Malliavin:\n\\[\n\\begin{aligned}\nX_t &= \\sum_{i=1}^n \\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i}(W_{t_i}-W_{t_{i-1}}) \\\\\nD_rX_t &= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n D_r[\\sigma_{t_i}\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\sum_{i=1}^n D_r\\mu_{t_i}(t_i-t_{i-1}) + \\sum_{i=1}^n \\sigma_{t_i} \\cdot 1_{[t_{i-1},t_{i}]}(r) + \\sum_{i=1}^n D_r(\\sigma_{t_i})\\cdot(W_{t_i}-W_{t_{i-1}})] \\\\\n&= \\int_0^t D_r\\mu_s\\,ds + \\sigma_r 1_{[0,t]}(r) + \\int_0^t D_r\\sigma_s\\,dW_s \\\\\n\\end{aligned}\n\\]\nSe ve un poco caótico, pero todo es como podríamos esperar: \\(t\\) es el valor terminal de ambas integrales, \\(s\\) es la variable que usamos para integrar de \\(0\\) a \\(t\\), y \\(r\\) es la variable que introdujimos con la derivada de Malliavin. La expresión tiene sentido: la influencia de \\(\\sigma\\) en el proceso de Ito es la misma a lo largo de todo el recorrido del proceso de Ito.\nAhora, usamos un argumento similar para la cantidad de truchas en el lago, que evoluciona según un proceso de Ornstein-Uhlenbeck. Dado que \\(\\mu_s\\) y \\(\\sigma_s\\) son ahora \\(a(s,X_s)\\) y \\(b(s,X_s)\\), aplicamos las reglas de la cadena y del producto como se indicó anteriormente para llegar a:\n\\[\nD_rX_t = \\int_r^t \\frac{\\partial a}{\\partial x}(s, X_s)\\,D_rX_s\\,ds + b(r,X_r)1_{[0,t]}(r) + \\int_r^t \\frac{\\partial b}{\\partial x}(s, X_s)\\,D_rX_s\\,dW_s \\\\\n\\]\nAhora, sabemos por lo anterior que \\(\\frac{\\partial a}{\\partial x} = -\\theta\\) y \\(\\frac{\\partial b}{\\partial x} = 0\\), entonces reemplazamos y, suponiendo que sabemos resolver ecuaciones integrales, resolvemos:\n\\[\n\\begin{aligned}\nD_rN_t &= \\int_r^t (-\\theta)\\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= -\\theta\\int_r^t \\,D_rN_s\\,ds + \\sigma1_{[0,t]}(r) \\\\\n&= \\sigma\\,e^{-\\theta(t-r)}\n\\end{aligned}\n\\]\nEn este caso, llegamos a una expresión linda que nos dice algo interesante: el efecto de una perturbación en el número de truchas es exponencialmente menor si \\(r&lt;&lt;t\\). Esto tiene sentido: la población de truchas \\(N\\) quiere estar cerca de \\(\\mu\\) y la población de un pasado lejano es irrelevante. También nos dice que no hay aleatoriedad en la fluctuación porque no depende de una variable aleatoria como \\(W_t\\).\nFinalmente, tuvimos suerte arriba. \\(D_rN_t\\) es simple y pudimos escribir una solución en forma analítica. Si fuera más complicada, probablemente sea mejor estimar una solución. Alos (2021) hace un gran trabajo mostrando lo anterior."
  },
  {
    "objectID": "clarkocone.html#fórmula-de-clark-ocone-haussman",
    "href": "clarkocone.html#fórmula-de-clark-ocone-haussman",
    "title": "Aplicaciones y casos en profundidad",
    "section": "",
    "text": "Veamos una aplicación relativamente simple con implicaciones muy profundas, siguiendo completamente el planteo descripto en Friz (2002). Consideremos esta función:\n\\[\nF(t) = e^{\\int_0^t h\\,dB - \\frac{1}{2}\\int_0^t{h^2}d\\lambda}\n\\]\nEsta función es una martingala exponencial, es decir, \\(\\mathbb{E}_s[F(t)]=F(s)\\). A continuación, tomamos \\(F(1) = \\mathcal{E}(h)\\) y calculamos \\(DF\\) :\n\\[\n\\begin{aligned}\nD_tF &= e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot D_t(e^{\\int_0^1 h\\,dB}) \\\\\n&= \\underbrace{e^{-\\frac{1}{2}\\int_0^1{h^2}d\\lambda}\\cdot e^{\\int_0^1 h\\,dB}}_{F} \\cdot h(t) \\\\\n&= Fh(t)\n\\end{aligned}\n\\]\nAhora bien, esto sólo es válido en \\(t=1\\), pero podemos usar el operador de esperanza y la propiedad de las martingalas para obtener los valores en un tiempo anterior. Llamaremos \\(\\mathcal{F}_s\\) a la filtración hasta el tiempo \\(s\\) (la forma a la que llamamos a la “historia” o “información” conocida hasta el tiempo \\(s\\)), y luego:\n\\[\n\\begin{aligned}\n\\mathbb{E}[D_t F | \\mathcal{F}_t] &= \\mathbb{E}[F(1)h(t)|\\mathcal{F_t}] \\\\\n&=h(t) \\mathbb{E}[F(1)|\\mathcal{F_t}] \\\\\n&=h(t) F(t)\n\\end{aligned}\n\\]\nPor último, esta martingala \\(F(t)\\) es la solución de la ecuación diferencial (estocástica) \\(dF(t) = h(t)F(t)dB_t\\), cuando \\(F(0)=1=\\mathbb{E}[F]\\). Reemplazando con la expresión anterior obtenemos:\n\\[\n\\begin{aligned}\nF(t) &= \\mathbb{E}[F] + \\int_0^1  h(t)F(t) dB_t \\\\\n&= \\mathbb{E}[F] + \\int_0^1 \\mathbb{E}[D_t F | \\mathcal{F_t}] dB_t\n\\end{aligned}\n\\]\nEsta es la fórmula de Clark-Ocone en todo su esplendor. Nos permite calcular en forma explícita lo que el Teorema de Representación en Martingala indicaba que debía existir. La derivada de Malliavin es el ingrediente clave para tener una expresión analítica y es la razón principal por la que a uno le interesaría. La expresión nos afirma que cualquier variable aleatoria indexada por el tiempo \\(F_t\\) se puede dividir en una suma de una parte “determinista” (su esperanza matemática), y una martingala que fluctúa alrededor de ella.\nPodemos aplicar esto al proceso de Ornstein-Uhlenbeck para nuestra población de truchas. Sabemos de antes que \\(D_rN_t = \\sigma\\,e^{-\\theta(t-r)}\\). Vemos que no hay \\(W_t\\), por lo que la esperanza es la derivada de Malliavin, directamente. Podríamos estimar el valor de \\(\\mathbb{E}[N]\\) o intentar resolver la ecuación diferencial (estocástica), pero dado que el proceso ya tiene una solución conocida, voy a ahorrarnos el esfuerzo y usarla directamente. Aquí está la aplicación de Clark-Ocone para un proceso de Ornstein-Uhlenbeck:\n\\[\n\\begin{aligned}\nN(t) &= \\mathbb{E}[N] + \\int_0^t \\mathbb{E_r}[D_r N_t] dW_r \\\\\n&= \\underbrace{X_0e^{-\\theta t} + \\mu(1-e^{-\\theta t})}_{Determinístico} + \\underbrace{\\int_0^t \\sigma\\,e^{-\\theta(t-r)}\\,dW_r}_{Martingala} \\\\\n\\end{aligned}\n\\]\n¿Por qué nos importa esto? Bueno, si quisiéramos simular diferentes trayectorias de nuestra población de truchas \\(N\\), solo necesitamos simular la martingala, y la parte determinista solo se calcula una vez. En segundo lugar, podemos usar la fórmula de Clark-Ocone para calcular directamente la varianza para \\(N\\), sin conocer la solución analítica completa que usamos arriba. Recordemos que \\(\\mathbb{Var}[N]=\\mathbb{E}[N-\\mathbb{E}[N]]^2\\), entonces, usando la isometría de Ito:\n\\[\n\\begin{aligned}\n\\mathbb{Var}[N]&=\\mathbb{E}\\left[\\left(\\int_0^t \\mathbb{E_r}[D_r N_t] dW_r\\right)^2\\right] \\\\\n&=\\mathbb{E}\\left[\\int_0^t \\left(\\sigma\\,e^{-\\theta(t-r)}\\right)^2dr\\right] \\\\\n&=\\sigma^2\\mathbb{E}\\left[\\int_0^t e^{2\\theta(r-t)}dr\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\mathbb{E}\\left[1-e^{-2\\theta t}\\right] \\\\\n&=\\frac{\\sigma^2}{2\\theta}\\left(1-e^{-2\\theta t}\\right)\n\\end{aligned}\n\\]\nTengamos en cuenta que esto funciona para cualquier variable: solo se necesita la derivada de Malliavin para obtener la varianza. Vemos arriba que:\n\nNuestra población de truchas \\(N\\) en el largo plazo (\\(t \\rightarrow \\infty\\)) será un proceso que se mueve alrededor de \\(\\mu\\) con una varianza constante \\(\\frac{\\sigma^2}{2\\theta}\\)\nLa varianza en el momento de la introducción de las truchas al lago (\\(t \\approx 0\\)) es muy pequeña porque el crecimiento de \\(N\\), que intenta alcanzar \\(\\mu\\) lo antes posible, predomina por encima del ruido normal del proceso\nUn \\(\\theta\\) grande no solo hará que la varianza de largo plazo llegue antes, sino que también evitará grandes desviaciones de \\(\\mu\\) en el largo plazo\n\n\n\n\n\n\nAlos, & Lorite, E. 2021. Malliavin Calculus in Finance: Theory and Practice (1st ed.). 1.ª ed. Financial Mathematics Series. Chapman; Hall/CRC. https://doi.org/10.1201/9781003018681.\n\n\nFriz, Peter K. 2002. «An Introduction to Malliavin Calculus». En. https://api.semanticscholar.org/CorpusID:2479628."
  },
  {
    "objectID": "cameronmartin.html",
    "href": "cameronmartin.html",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Uf, demasiada álgebra. Pero necesitábamos introducir espacios vectoriales de dimensión infinita para entender qué es un espacio de Cameron-Martin. Como antes, tomaremos inspiración de Alessandra Lunardi (2015), que tiene un mayor rior matemático, pero que no dudaremos en abandonar en favor de claridad pedagógica. La brecha es bastante grande, y eso se ve al navegar los artículos de Wikipedia sobre el Cálculo de Malliavin, la cantidad de conceptos que hacen falta aprender para entender una oración es difícil. Con suerte, esto dará suficiente información sobre el espacio de Cameron-Martin para continuar con la derivada de Malliavin directamente.\n\n\nMencionamos en el capítulo anterior que resolveríamos el problema de calcular la longitud y la distancia de vectores de dimensión infinita (en particular, funciones) cambiando la medida de Lebesgue por la medida gaussiana. Hay otra razón para esa elección, resumida en Wikipedia contributors (2024). La medida de Lebesgue es la única medida en espacios de dimensión finita que es:\n\nLocalmente finita, es decir, un conjunto alrededor de un punto tiene una medida finita. \\(\\lambda(N_x) &lt; +\\infty\\)\nInvariante a traslaciones, es decir, mover un conjunto en una determinada dirección \\(d\\) mantiene intacto el valor de la medida. \\(\\lambda(\\{N_x\\}=\\lambda(\\{N_x \"+\" d\\})\\)\nEstrictamente positiva, es decir, si \\(A \\neq \\emptyset\\), entonces \\(\\lambda(A)&gt;0\\)\n\nPara dimensiones infinitas, no hay equivalente1, y la medida localmente finita e invariante a la traslación es la medida trivial \\(\\mu(A)=0, \\forall A\\) .\nDebido a esto, pasamos a usar la medida gaussiana, que tiene colas con decaimiento exponencial y pueden aplastar los valores de la función si están muy lejos del centro2. Esto también significa que tenemos que abordar otros problemas. En particular, el hecho de que no es invariante a la traslación.\n\n\n\nPara ilustrar mejor este problema, supongamos una integral de Riemann como la siguiente:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx\n\\]\nA continuación, hacemos un cambio de variable debido a una traslación \\(x \\rightarrow x +h\\). El área bajo la curva no habrá cambiado, solo se habrá desplazado hacia un lado:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx = \\int_{-\\infty}^{+\\infty}f(x+h)dx\n\\]\nEsto está respaldado por la medida de Lebesgue subyacente, que también es invariante bajo una translación arbitraria:\n\\[\n\\lambda([a+h,b+h])=(b-h)-(a-h)=b-a=\\lambda([a,b])\n\\]\nY finalmente se confirma visualmente. Mirá estas funciones con forma de fantasmas. Independientemente del cambio, tienen la misma área bajo la curva:\n\n\nCódigo\nlibrary(ggplot2)\n\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\ny_1 &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h\n)\n\n# ggplot(data = df, mapping = aes(time)) +\n#   geom_area(mapping = aes(y=density_y, color=\"green\"), alpha = 0.5, show.legend = FALSE) +\n#   geom_area(mapping = aes(y=density_y_plus), alpha = 0.5, show.legend = FALSE)\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=density_y, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=density_y_plus, fill=\"f(X+5)\"), alpha = 0.5) +\n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\"))\n\n\n\n\n\nDesafortunadamente, la medida gaussiana no permite esto. Recordemos los casos n-dimensionales o unidimensionales para una medida gaussiana centrada y estándar.\n\\[\n\\begin{aligned}\n\\gamma^{n}(A) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x) \\\\\n\\gamma(A) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{A} \\exp \\left( - \\frac{1}{2} x^{2} \\right) \\, \\mathrm{d} \\lambda (x)\n\\end{aligned}\n\\]\nUsemos la medida gaussiana (o con un factor de ponderación) para las funciones anteriores y veamos cómo modifican el área bajo ambas funciones:\n\n\nCódigo\nlibrary(ggplot2)\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\nweight &lt;- dnorm(x)\ny &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_weighted &lt;- y * weight\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\ny_plus_h_weighted &lt;- y_plus_h * weight\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h,\n  weight=weight\n)\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=y_weighted, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=y_plus_h_weighted, fill=\"f(X+5)\"), alpha = 0.5) + \n  geom_line(mapping = aes(y=weight, colour=\"Weight\"),linetype = 2) + \n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\")) + \n  scale_colour_manual(\"\",values=c(\"black\"),labels=c(\"Weight\"))\n\n\n\n\n\nCódigo\n  #theme(legend.position = \"none\")\n\n\nComo se puede ver, la primera función tenía mucha área en el medio del ponderador, por lo que la conserva bastante. La función desplazada, en cambio, se ha achicado. Ahora bien, aunque el área ha cambiado, en teoría podríamos recuperar el factor por el cual ha cambiado. Esto es fácil de calcular con dimensiones finitas, pero es desafiante o imposible en dimensiones infinitas.\nLa idea fundamental es que se puede realizar una traslación en dimensiones infinitas y llegar a un cálculo. El único requisito es que la traslación sea por un vector que provenga de un espacio “más pequeño”, el espacio de Cameron-Martin, y solo esas traslaciones tienen sentido y están permitidas.\n\n\n\nAunque suene misterioso, en realidad es bastante sencillo y se puede seguir el enfoque de Wikipedia contributors (2023) y Alessandra Lunardi (2015). Regresemos al producto interno en lugar de usar la norma para entender qué está pasando, y usaremos un espacio finito de \\(n\\) dimensiones para ejemplificar:\n\\[\n\\gamma^{n}(A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx\n\\]\nAhora bien, podemos reemplazar \\(A\\) con una \\(A-h\\) desplazada y ver qué sucede:\n\\[\n\\begin{aligned}\n\\gamma^{n}(A-h) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x-h,x-h \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) * \\exp \\left( - \\frac{1}{2} \\left(-2\\langle x,h \\rangle_{\\mathbb{R}^{n}} + \\langle h,h \\rangle_{\\mathbb{R}^{n}}\\right) \\right)\\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\underbrace{\\exp \\left( - \\frac{1}{2} \\| x \\|^2_{\\mathbb{R}^{n}} \\right)}_{\\text{Medida gaussiana}} * \\underbrace{\\exp \\left(  \\langle x,h \\rangle_{\\mathbb{R}^{n}} - \\frac{1}{2} \\| h \\|^2_{\\mathbb{R}^{n}}\\right)}_{\\text{\"Cambio de variable\"}} \\, dx \\\\\n\\end{aligned}\n\\]\nEs decir, una medida gaussiana para un conjunto trasladado es la medida del conjunto original, multiplicada por un factor adicional para realizar el “cambio de variable”. Ese factor adicional se denomina derivada de Radon-Nikodym porque expresa cuánto cambia la medida de un conjunto cuando cambia otra medida. En este caso, transforma la medida gaussiana centrada a la medida gaussiana con una traslación de \\(h\\) y se simboliza con \\(\\frac{\\partial(T_h)_*(\\gamma)}{d\\gamma}(x)\\)\nRecordemos que, si hay un espacio \\(E\\) y una medida \\(\\mu\\) que es localmente finita e igual a sí misma después de cualquier traslación por “cambio de variables”, entonces o bien \\(E\\) es de dimensión finita, como dijimos más arriba, o bien \\(\\mu\\) es la medida trivial \\(\\mu(A) = 0,\\, \\forall A\\). Esto ya se puede ver en la expresión anterior, donde si \\(h\\) es de dimensión infinita, entonces existe el potencial de hacer que esta integral tienda a infinito. Afortunadamente para nosotros, también sabemos que podemos evitar problemas si esperamos equivalencia bajo algunas traslaciones, es decir, traslaciones que son elementos de un espacio de Cameron-Martin, también llamadas direcciones de Cameron-Martin.\nPartimos de un espacio de dimensión infinita \\(H\\), nuestro espacio de Cameron-Martin. Tendremos \\(h \\in H\\), con una función \\(i(h):H\\rightarrow E\\), y \\(i(H) \\subseteq E\\). Estas \\(i(H)\\) serán nuestras direcciones de Cameron-Martin. Impondremos restricciones adicionales a \\(h\\). Para empezar, y basándonos en la derivada de Radon-Nikodym que vemos arriba, necesitamos al menos que \\(\\|h\\|^2_H &lt; \\infty\\). Luego, necesitamos decidir qué significa \\(\\langle h, x \\rangle\\) y qué hacer con esa expresión. De hecho, este no es un verdadero producto interno porque \\(h \\in H\\) y \\(x \\in E\\) . Acordate, ¡El objetivo de \\(H\\) es reducir el espacio vectorial!. En pocas palabras, lo que ocurre con ese falso producto interno es que hay una correspondencia entre cada \\(h\\) y una función en el espacio de funciones \\(I(h): H \\rightarrow L^2\\), y \\(I(h)(x)\\) es lo que cuenta como el “producto interno” \\(\\langle h, x \\rangle^\\sim\\). 3\n\n\n\nTodo lo anterior fue bastante árido, así que echemos un vistazo a un ejemplo de un espacio de dimensión infinita y su correspondiente espacio de Cameron-Martin. No intentaré explicar cómo se obtuvo este espacio, hay una derivación bastante larga en Alessandra Lunardi (2015) .\n\n\n¿Te acordás del espacio de sucesiones infinitas? Es un espacio de dimensión infinita y lo denotamos \\(\\mathbb{R}^{\\mathbb{N}}:=\\mathbb{R}^{\\infty}\\), con cardinalidad numerable. Ahora, consideremos el espacio de sucesiones que se anulan en el infinito, con el símbolo exótico \\(\\mathbb{R}_c^{\\infty}\\) y sus elementos tendrán el símbolo aún más exótico \\(\\xi\\in\\mathbb{R}_c^{\\infty}\\) . Entonces, por definición, sabemos que \\(\\lim_{k\\rightarrow \\infty}\\xi_k = 0\\).\nAhora, establecemos una correspondencia entre estas sucesiones y funciones, muy sencilla: \\(\\xi \\rightarrow f, \\text{con }f(x) = \\sum^\\infty_{k=1}\\xi_k x_k\\) , y la limitaremos a las sumas que sean finitas, es decir \\(f(x)&lt;\\infty\\) o \\(f(x) \\in L^2\\). Verifiquemos que cuando calculemos la medida para el primer término de esta serie con una medida gaussiana, estaremos simplificando mucho:\n\\[\n\\int_X \\xi_1 x_1 d\\gamma(x_1)=\\xi_1 \\int_{-\\infty}^{+\\infty} x_1d\\gamma(x_1)=\\xi_1 *\\mathbb{E}[\\mathcal{N}(\\mu=0,\\sigma^2=1)]=0\n\\]\nAhora, se puede hacer esto para todos los \\(x_k\\) y encontrar el mismo resultado. Esto no es casualidad, y es la razón por la que utilizamos la medida gaussiana para dimensiones infinitas. De hecho, \\(\\gamma\\) para el caso de dimensión infinita tendrá media \\(\\mu=0\\) y varianza/covarianza \\(B_\\gamma(\\xi,\\xi)=\\|\\xi\\|_{\\ell^2}\\).\nEsta última afirmación también es útil porque podemos utilizarla para obtener el valor de la norma de una función con la medida gaussiana. No lo demostraré ahora, pero \\(\\|f\\|^2_{L^2(X,\\gamma)}=\\|\\xi\\|^2_{\\ell^2}\\). Ahora, si tomamos una \\(h\\in \\mathbb{R}^\\infty\\), podemos demostrar (pero no lo haremos) que con restringir el espacio de traslaciones para las sucesiones a \\(h\\in H = \\ell^2\\) , alcanza para que las funciones anteriores siempre tengan una medida. Entonces, el espacio de Cameron-Martin es \\(\\ell^2\\).\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. «Infinite Dimensional Analysis». 2015. http://www.dm.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nWikipedia contributors. 2023. «Cameron–Martin theorem — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Cameron%E2%80%93Martin_theorem.\n\n\n———. 2024. «Infinite-dimensional Lebesgue measure — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Infinite-dimensional_Lebesgue_measure."
  },
  {
    "objectID": "cameronmartin.html#medidas-gaussianas",
    "href": "cameronmartin.html#medidas-gaussianas",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Mencionamos en el capítulo anterior que resolveríamos el problema de calcular la longitud y la distancia de vectores de dimensión infinita (en particular, funciones) cambiando la medida de Lebesgue por la medida gaussiana. Hay otra razón para esa elección, resumida en Wikipedia contributors (2024). La medida de Lebesgue es la única medida en espacios de dimensión finita que es:\n\nLocalmente finita, es decir, un conjunto alrededor de un punto tiene una medida finita. \\(\\lambda(N_x) &lt; +\\infty\\)\nInvariante a traslaciones, es decir, mover un conjunto en una determinada dirección \\(d\\) mantiene intacto el valor de la medida. \\(\\lambda(\\{N_x\\}=\\lambda(\\{N_x \"+\" d\\})\\)\nEstrictamente positiva, es decir, si \\(A \\neq \\emptyset\\), entonces \\(\\lambda(A)&gt;0\\)\n\nPara dimensiones infinitas, no hay equivalente1, y la medida localmente finita e invariante a la traslación es la medida trivial \\(\\mu(A)=0, \\forall A\\) .\nDebido a esto, pasamos a usar la medida gaussiana, que tiene colas con decaimiento exponencial y pueden aplastar los valores de la función si están muy lejos del centro2. Esto también significa que tenemos que abordar otros problemas. En particular, el hecho de que no es invariante a la traslación."
  },
  {
    "objectID": "cameronmartin.html#invariancia-de-la-traslación",
    "href": "cameronmartin.html#invariancia-de-la-traslación",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Para ilustrar mejor este problema, supongamos una integral de Riemann como la siguiente:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx\n\\]\nA continuación, hacemos un cambio de variable debido a una traslación \\(x \\rightarrow x +h\\). El área bajo la curva no habrá cambiado, solo se habrá desplazado hacia un lado:\n\\[\n\\int_{-\\infty}^{+\\infty}f(x)dx = \\int_{-\\infty}^{+\\infty}f(x+h)dx\n\\]\nEsto está respaldado por la medida de Lebesgue subyacente, que también es invariante bajo una translación arbitraria:\n\\[\n\\lambda([a+h,b+h])=(b-h)-(a-h)=b-a=\\lambda([a,b])\n\\]\nY finalmente se confirma visualmente. Mirá estas funciones con forma de fantasmas. Independientemente del cambio, tienen la misma área bajo la curva:\n\n\nCódigo\nlibrary(ggplot2)\n\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\ny_1 &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h\n)\n\n# ggplot(data = df, mapping = aes(time)) +\n#   geom_area(mapping = aes(y=density_y, color=\"green\"), alpha = 0.5, show.legend = FALSE) +\n#   geom_area(mapping = aes(y=density_y_plus), alpha = 0.5, show.legend = FALSE)\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=density_y, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=density_y_plus, fill=\"f(X+5)\"), alpha = 0.5) +\n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\"))\n\n\n\n\n\nDesafortunadamente, la medida gaussiana no permite esto. Recordemos los casos n-dimensionales o unidimensionales para una medida gaussiana centrada y estándar.\n\\[\n\\begin{aligned}\n\\gamma^{n}(A) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x) \\\\\n\\gamma(A) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{A} \\exp \\left( - \\frac{1}{2} x^{2} \\right) \\, \\mathrm{d} \\lambda (x)\n\\end{aligned}\n\\]\nUsemos la medida gaussiana (o con un factor de ponderación) para las funciones anteriores y veamos cómo modifican el área bajo ambas funciones:\n\n\nCódigo\nlibrary(ggplot2)\nh &lt;- 0.001\nsteps = 1 / h\nx &lt;- seq(from = -5, to = 10, length.out=steps)\nweight &lt;- dnorm(x)\ny &lt;- dnorm(x) + 0.25 * dnorm(x, mean=-3, sd = 0.5)\ny_weighted &lt;- y * weight\ny_plus_h &lt;- dnorm(x, mean = 5) + 0.25 * dnorm(x, mean=2, sd = 0.5)\ny_plus_h_weighted &lt;- y_plus_h * weight\n\ndf &lt;- data.frame(\n  time=x,\n  density_y=y_1,\n  density_y_plus=y_plus_h,\n  weight=weight\n)\n\nggplot(data = df, mapping = aes(x=time), legend=TRUE) +\n  xlim(-5, 10) +\n  xlab('X') +\n  ylab('f(X)') +\n  geom_area(mapping = aes(y=y_weighted, fill=\"f(X)\"), alpha = 0.3) +\n  geom_area(mapping = aes(y=y_plus_h_weighted, fill=\"f(X+5)\"), alpha = 0.5) + \n  geom_line(mapping = aes(y=weight, colour=\"Weight\"),linetype = 2) + \n  scale_fill_manual(\"Functions\",values=c(\"green\", \"blue\")) + \n  scale_colour_manual(\"\",values=c(\"black\"),labels=c(\"Weight\"))\n\n\n\n\n\nCódigo\n  #theme(legend.position = \"none\")\n\n\nComo se puede ver, la primera función tenía mucha área en el medio del ponderador, por lo que la conserva bastante. La función desplazada, en cambio, se ha achicado. Ahora bien, aunque el área ha cambiado, en teoría podríamos recuperar el factor por el cual ha cambiado. Esto es fácil de calcular con dimensiones finitas, pero es desafiante o imposible en dimensiones infinitas.\nLa idea fundamental es que se puede realizar una traslación en dimensiones infinitas y llegar a un cálculo. El único requisito es que la traslación sea por un vector que provenga de un espacio “más pequeño”, el espacio de Cameron-Martin, y solo esas traslaciones tienen sentido y están permitidas."
  },
  {
    "objectID": "cameronmartin.html#el-espacio-de-cameron-martin",
    "href": "cameronmartin.html#el-espacio-de-cameron-martin",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Aunque suene misterioso, en realidad es bastante sencillo y se puede seguir el enfoque de Wikipedia contributors (2023) y Alessandra Lunardi (2015). Regresemos al producto interno en lugar de usar la norma para entender qué está pasando, y usaremos un espacio finito de \\(n\\) dimensiones para ejemplificar:\n\\[\n\\gamma^{n}(A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx\n\\]\nAhora bien, podemos reemplazar \\(A\\) con una \\(A-h\\) desplazada y ver qué sucede:\n\\[\n\\begin{aligned}\n\\gamma^{n}(A-h) &= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x-h,x-h \\rangle_{\\mathbb{R}^{n}} \\right) \\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\langle x,x \\rangle_{\\mathbb{R}^{n}} \\right) * \\exp \\left( - \\frac{1}{2} \\left(-2\\langle x,h \\rangle_{\\mathbb{R}^{n}} + \\langle h,h \\rangle_{\\mathbb{R}^{n}}\\right) \\right)\\, dx \\\\\n&= \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\underbrace{\\exp \\left( - \\frac{1}{2} \\| x \\|^2_{\\mathbb{R}^{n}} \\right)}_{\\text{Medida gaussiana}} * \\underbrace{\\exp \\left(  \\langle x,h \\rangle_{\\mathbb{R}^{n}} - \\frac{1}{2} \\| h \\|^2_{\\mathbb{R}^{n}}\\right)}_{\\text{\"Cambio de variable\"}} \\, dx \\\\\n\\end{aligned}\n\\]\nEs decir, una medida gaussiana para un conjunto trasladado es la medida del conjunto original, multiplicada por un factor adicional para realizar el “cambio de variable”. Ese factor adicional se denomina derivada de Radon-Nikodym porque expresa cuánto cambia la medida de un conjunto cuando cambia otra medida. En este caso, transforma la medida gaussiana centrada a la medida gaussiana con una traslación de \\(h\\) y se simboliza con \\(\\frac{\\partial(T_h)_*(\\gamma)}{d\\gamma}(x)\\)\nRecordemos que, si hay un espacio \\(E\\) y una medida \\(\\mu\\) que es localmente finita e igual a sí misma después de cualquier traslación por “cambio de variables”, entonces o bien \\(E\\) es de dimensión finita, como dijimos más arriba, o bien \\(\\mu\\) es la medida trivial \\(\\mu(A) = 0,\\, \\forall A\\). Esto ya se puede ver en la expresión anterior, donde si \\(h\\) es de dimensión infinita, entonces existe el potencial de hacer que esta integral tienda a infinito. Afortunadamente para nosotros, también sabemos que podemos evitar problemas si esperamos equivalencia bajo algunas traslaciones, es decir, traslaciones que son elementos de un espacio de Cameron-Martin, también llamadas direcciones de Cameron-Martin.\nPartimos de un espacio de dimensión infinita \\(H\\), nuestro espacio de Cameron-Martin. Tendremos \\(h \\in H\\), con una función \\(i(h):H\\rightarrow E\\), y \\(i(H) \\subseteq E\\). Estas \\(i(H)\\) serán nuestras direcciones de Cameron-Martin. Impondremos restricciones adicionales a \\(h\\). Para empezar, y basándonos en la derivada de Radon-Nikodym que vemos arriba, necesitamos al menos que \\(\\|h\\|^2_H &lt; \\infty\\). Luego, necesitamos decidir qué significa \\(\\langle h, x \\rangle\\) y qué hacer con esa expresión. De hecho, este no es un verdadero producto interno porque \\(h \\in H\\) y \\(x \\in E\\) . Acordate, ¡El objetivo de \\(H\\) es reducir el espacio vectorial!. En pocas palabras, lo que ocurre con ese falso producto interno es que hay una correspondencia entre cada \\(h\\) y una función en el espacio de funciones \\(I(h): H \\rightarrow L^2\\), y \\(I(h)(x)\\) es lo que cuenta como el “producto interno” \\(\\langle h, x \\rangle^\\sim\\). 3"
  },
  {
    "objectID": "cameronmartin.html#ejemplo-de-un-espacio-de-cameron-martin",
    "href": "cameronmartin.html#ejemplo-de-un-espacio-de-cameron-martin",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Todo lo anterior fue bastante árido, así que echemos un vistazo a un ejemplo de un espacio de dimensión infinita y su correspondiente espacio de Cameron-Martin. No intentaré explicar cómo se obtuvo este espacio, hay una derivación bastante larga en Alessandra Lunardi (2015) .\n\n\n¿Te acordás del espacio de sucesiones infinitas? Es un espacio de dimensión infinita y lo denotamos \\(\\mathbb{R}^{\\mathbb{N}}:=\\mathbb{R}^{\\infty}\\), con cardinalidad numerable. Ahora, consideremos el espacio de sucesiones que se anulan en el infinito, con el símbolo exótico \\(\\mathbb{R}_c^{\\infty}\\) y sus elementos tendrán el símbolo aún más exótico \\(\\xi\\in\\mathbb{R}_c^{\\infty}\\) . Entonces, por definición, sabemos que \\(\\lim_{k\\rightarrow \\infty}\\xi_k = 0\\).\nAhora, establecemos una correspondencia entre estas sucesiones y funciones, muy sencilla: \\(\\xi \\rightarrow f, \\text{con }f(x) = \\sum^\\infty_{k=1}\\xi_k x_k\\) , y la limitaremos a las sumas que sean finitas, es decir \\(f(x)&lt;\\infty\\) o \\(f(x) \\in L^2\\). Verifiquemos que cuando calculemos la medida para el primer término de esta serie con una medida gaussiana, estaremos simplificando mucho:\n\\[\n\\int_X \\xi_1 x_1 d\\gamma(x_1)=\\xi_1 \\int_{-\\infty}^{+\\infty} x_1d\\gamma(x_1)=\\xi_1 *\\mathbb{E}[\\mathcal{N}(\\mu=0,\\sigma^2=1)]=0\n\\]\nAhora, se puede hacer esto para todos los \\(x_k\\) y encontrar el mismo resultado. Esto no es casualidad, y es la razón por la que utilizamos la medida gaussiana para dimensiones infinitas. De hecho, \\(\\gamma\\) para el caso de dimensión infinita tendrá media \\(\\mu=0\\) y varianza/covarianza \\(B_\\gamma(\\xi,\\xi)=\\|\\xi\\|_{\\ell^2}\\).\nEsta última afirmación también es útil porque podemos utilizarla para obtener el valor de la norma de una función con la medida gaussiana. No lo demostraré ahora, pero \\(\\|f\\|^2_{L^2(X,\\gamma)}=\\|\\xi\\|^2_{\\ell^2}\\). Ahora, si tomamos una \\(h\\in \\mathbb{R}^\\infty\\), podemos demostrar (pero no lo haremos) que con restringir el espacio de traslaciones para las sucesiones a \\(h\\in H = \\ell^2\\) , alcanza para que las funciones anteriores siempre tengan una medida. Entonces, el espacio de Cameron-Martin es \\(\\ell^2\\).\n\n\n\n\n\nAlessandra Lunardi, Diego Pallara, Michele Miranda. 2015. «Infinite Dimensional Analysis». 2015. http://www.dm.unife.it/it/ricerca-dmi/seminari/isem19/lectures/lecture-notes/view.\n\n\nWikipedia contributors. 2023. «Cameron–Martin theorem — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Cameron%E2%80%93Martin_theorem.\n\n\n———. 2024. «Infinite-dimensional Lebesgue measure — Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Infinite-dimensional_Lebesgue_measure."
  },
  {
    "objectID": "cameronmartin.html#footnotes",
    "href": "cameronmartin.html#footnotes",
    "title": "Espacios de Cameron-Martin",
    "section": "",
    "text": "Estrictamente hablando, existe un análogo para dimensiones infinitas, pero el espacio vectorial debe ser no separable y la medida no será sigma-finita. Los espacios con los que tratamos normalmente son separables. En particular, los espacios de Hilbert (espacios con productos internos que son completos bajo la métrica inducida por el producto interno) son separables si tienen una base ortonormal en \\(\\mathbb{N}\\) (siendo potencialmente infinita).↩︎\nEsto es una consecuencia del teorema de Fernique↩︎\nEsto se llama la integral de Paley-Wiener. No necesitaremos mencionarla ni hacer referencia a ella de nuevo porque concuerda con la integral de Ito cuando ambas están definidas, de forma similar a las medidas de Borel y Lebesgue.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prefacio",
    "section": "",
    "text": "Prefacio\nPara entender el Calculo Malliavin, no alcanza con entender las formulas y sus demostraciones. El Calculo Malliavin es la respuesta a una pregunta, y conocer la respuesta y el camino a ella no es suficiente.\nHay que entender la pregunta.\nEste libro fue creado para explicarme el topico a mi mismo y aprenderlo como consecuencia de ello. Si no viste “12 Monos” o “Arrival”, esto va a sonar contraintuitivo. Simplemente segui leyendo y (con suerte) ambos aprenderemos.\nPara crear este libro, use Quarto y RStudio, el ultimo IDE que vas a necesitar en tu vida. Para aprender mas de Quarto books, visita https://quarto.org/docs/books. Para aprender mas de RStudio IDE, visita https://posit.co/products/open-source/rstudio/. Tambien prefiero R sobre Python para topicos de Matematicas y Estadisticas.\nPor ultimo, dedico este trabajo a Pablo Azcue, que su memoria sea una bendicion. Probablemente nunca lo supo, pero fue el quien me hizo amar analisis real y procesos estocasticos."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introducción",
    "section": "",
    "text": "Introducción\nEste ensayo trata sobre el Cálculo Malliavin y la fórmula de Clark-Ocone. Tras meses de estudio y frustración, concluí que el principal obstáculo para entender el tópico es el énfasis en el rigor matemático de las fuentes consultadas, por sobre la claridad pedagógica. Mi esperanza es conectar estos extremos, asumiendo conocimientos básicos de análisis matemático, álgebra, y probabilidad y estadística.\nVoy a empezar desarrollando qué intenta lograr el Calculo Malliavin. Me aproximaré en forma indirecta, meandrosa. Luego de documentar situaciones donde existe un problema, la necesidad de una solución generará una especie de “vacío”. Luego, también indirectamente, pondré las fundaciones paso a paso. Finalmente, el vacío sera llenado.\nElegí Quarto porque el código fuente y sus resultados estarán disponibles. Ayuda mucho ver una pieza de matemáticas y conectarla con instrucciones de código fuente.\nComo dije anteriormente, la claridad pedagógica es el factor primordial. No voy a escribir demostraciones si no pienso que sean importantes. Tomaré atajos con impunidad. Algunas partes tal vez no lleven a ningún lado y solo estén ahí para redondear un concepto. Incluso puede que me declare ignorante sobre un tema y lo deje ahí.\nLa verdad es que no soy un profesional de las matemáticas, estadísticas o economía. Simplemente estoy tratando de entender un tópico muy árido y oscuro.\nY, ahora, es el momento de empezar."
  },
  {
    "objectID": "measuretheory.html",
    "href": "measuretheory.html",
    "title": "Teoría de la Medida",
    "section": "",
    "text": "Después del cálculo de variaciones, necesitamos desviarnos hacia un tema relacionado, de algún modo, con la integración. De lo contrario, algunas partes de este ensayo serán más difíciles de entender.\n\n\nTal vez te hayas acostumbrado a llamar “integración” a algo como \\(\\int_{a}^{b}fdx\\) , pero en realidad esa es solamente la integración de Riemann. Bueno, “solamente” motoriza el 99 % de todas las integraciones en la vida real, pero hay otras integrales especializadas que pueden manejar situaciones especiales como discontinuidades o huecos en \\(f\\), como la integral de Riemann-Stieltjes, la integral de Henstock-Kurzweil y la integral de Lebesgue. La última es en la que nos concentraremos más.\nVamos a empezar con un problema que aparentemente no tiene nada que ver: el tamaño de un conjunto. Digamos que tenemos un conjunto de números naturales \\(\\mathbb{N}\\) y queremos saber qué tan grande es. Podemos, por ejemplo, simplemente contar cuántos elementos hay en el conjunto:\n\\[\n\\begin{aligned}\n&\\#\\{\\pi,e,25\\} = 3\\\\\n&\\#\\{\\} = 0 \\\\\n&\\#\\{1,2,3,..\\} = \\infty\n\\end{aligned}\n\\]\nEn cierto modo, \\(\\#\\) es una función que recibe un conjunto como entrada una combinación de elementos de \\(\\mathbb{N}\\) y produce un valor numérico. En la literatura, los elementos pertenecen a un conjunto \\(\\Omega\\) y las combinaciones de esos elementos pertenecen a un conjunto de conjuntos \\(\\Sigma\\) , también llamado sigma álgebra. Más formalmente, \\(\\# : \\Sigma \\to \\mathbb{N}\\).\n\\(\\#\\) es lo que se conoce como una medida. Para definir medidas se usa normalmente \\(\\mu\\) y cumplen, grosso modo, dos condiciones:\n\n\\(\\mu(s) \\ge 0 ,\\, \\forall s \\in \\Sigma\\), es decir, siempre son positivas. Esta condición, de todos modos, se puede relajar para obtener “medidas con signo”.\nIf \\(A_1 \\cap A_2 = \\{\\} \\implies {\\mu (A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)}\\). Esto significa que el “tamaño” de un conjunto es el mismo que la suma de los tamaños de sus subconjuntos.\n\nHay muchas medidas, y cada una presenta diferentes propiedades. Las medidas se definen sobre un “conjunto medible”, es decir, sobre el par \\((\\Omega,\\Sigma)\\). Ya conocés la medida de conteo. La medida de Borel, que utilizaremos indistintamente con la medida de Lebesgue1, se puede definir como:\n\\[\n\\lambda((a,b])=b-a\n\\]\nSi el conjunto es una composición de intervalos, se puede descomponer en tantas sumas como hagan falta, por lo que:\n\\[\n\\lambda([0,2]\\cup(12,20))=\\lambda([0,2])+\\lambda((12,20))=(2-0)+(20-12)=10\n\\]\nTambién se puede extender en forma razonable a casos multidimensionales:\n\\[\n\\lambda^2((0,\\pi]\\times(2,4])=\\lambda((0,\\pi])*\\lambda((2,4])=(\\pi-0)*(4-2)=\\pi*2=2\\pi\n\\]\n\n\n\nHagamos ahora algo intrépido: ¿Viste que las integrales definidas trabajan sobre un intervalo (es decir, un conjunto) y el resultado de integrar es un número? Sí, una integral es una medida (con signo)2. Esto va a requerir replantearse qué significa realmente integrar, así como cambiar nuestra notación para la integral.\nEn el mundo que todos conocemos, integramos en el sentido de Riemann, \\(\\int_{a}^{b}fdx\\). Esto significa:\n\n\\(I=\\left[a,b\\right]\\) selecciona la porción a integrar del dominio de la función, \\(\\Omega\\). Usando el lenguaje que establecimos anteriormente, \\(I\\subset \\Omega,\\, I\\in \\Sigma\\)\nDividimos \\(I\\) en particiones, generalmente usando un tamaño de partición único \\(\\Delta x\\), y obtenemos una lista de valores \\(\\left\\{x_0=a, x_1, …, x_n=b\\right\\} \\in I\\)\nPara cada partición \\(x_i\\), la evaluamos haciendo \\(f(x_i)\\) y obtenemos una lista de valores \\(f_0, f_1, ..., f_n\\)\nCalculamos una aproximación de la integral haciendo que cada uno de estos valores sea un rectángulo de altura \\(f_i\\) y ancho predefinido \\(\\Delta x\\), y sumando todos los rectángulos.\nLa integral, si existe, es el límite de esta suma cuando la norma de la partición tiende a cero.\n\nAsí es como se ve:\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(broom)\n\nf &lt;- function(x) x^3 - 3*x^2 + x +4\n\n# Define the interval [a, b] for integration\na &lt;- 0\nb &lt;- 3\n\n# Number of rectangles for approximation\nn &lt;- 24\n\n# Generate x values and corresponding function values\nx_values &lt;- seq(a, b, length.out = n+1)\ny_values &lt;- f(x_values)\n\n# Create a data frame for ggplot\ndf &lt;- data.frame(x = x_values, y = y_values)\n\n# Calculate rectangle heights\ndf$rect_heights &lt;- c(0,f(x_values)[2:length(x_values)])\n\n# Calculate total width of the bars to fill the x-axis\ntotal_width &lt;- b - a\n\n# Create a ggplot with rectangles\np &lt;- ggplot(df, aes(x = x, y = rect_heights)) +\n    geom_col(width=(total_width/n), fill = \"skyblue\", color = \"black\", just = 1, alpha=0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Ejemplo de Integración de Riemann\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\nA pesar de ser tan poderosa, existen limitaciones. Para empezar, solamente podemos integrar intervalos sobre un dominio real, \\(\\Omega =\\mathbb{R}\\) . Para funciones de muchas variables también necesitamos integrar sobre muchos dominios reales, por ejemplo \\(\\int_{x_a}^{x_b}\\int_{y_a}^{y_b}\\int_{z_a}^{z_b}f(x,y,z)\\,dz\\,dy\\,dx\\) .\nAquí podemos darnos cuenta de que podríamos deshacernos de estas restricciones si integrásemos sobre la única línea real que tiene existencia garantizada: la del codominio o imagen. Algo así como una pila de platos, para cada altura medimos el dominio que cae debajo de ella. Esto se llama integración de Lebesgue, se escribe como \\(\\int_{s} f\\, d\\lambda\\) , y significa:\n\n\\(s\\) selecciona una porción del dominio de la función, \\(\\Omega\\) , para integrar. Con el lenguaje que hemos utilizado anteriormente, \\(s\\subset \\Omega,\\, s\\in \\Sigma\\)\nDividimos la imagen de la función \\(f^{-1}\\) en particiones y obtenemos las imágenes \\(f_0,f_1,…,\\infty\\)\nPara cada una de estas particiones, obtenemos el conjunto de valores del dominio que tienen un valor de función al menos a esa altura: \\(f^{-1}_t = \\{\\omega \\in s\\, / \\, f(\\omega) &gt; t\\}\\in\\Sigma\\). Hay que tener en cuenta que estos conjuntos deben ser medibles (parte de la sigma álgebra) y que \\(f_{\\infty} = \\{\\}\\), es decir que la integral esté acotada.\nCalculamos una aproximación de la integral haciendo de cada uno de estos conjuntos un grupo de “volúmenes” de altura predefinida \\(f_t\\) y base \\(\\mu(f^{-1}_t)\\), y sumando sobre todos los rectángulos.\nAl sumar todos los conjuntos medidos, todas las porciones de alturas, obtenemos un valor final, es decir que verdaderamente la integral se comporta como una medida.\nLa integral, si existe, es el supremo de todas las sumas que se pueden obtener al dividir la imagen en particiones cada vez más pequeñas.\n\nAsí es como se ve este embrollo de acabamos de describir:\n\n\nCódigo\nA &lt;- 1\nB &lt;- -3\nC &lt;- 1\nD &lt;- 4\nf &lt;- function(x) A*x^3 + B*x^2 + C*x + D\ndfdx &lt;- function(x) A*3*x^2 + B*2*x + C\n\n# Define the domain [left, right] for integration\nleft &lt;- 0\nright &lt;- 3\n\n# Number of image partitions\nmax_y &lt;- 7\nn &lt;- 28\ndelta_y &lt;- max_y / n\n\n# Generate x values and corresponding function values\ny_values &lt;- seq(0, max_y, length.out = n + 1)\n\n\nfind_real_roots_of_cubic &lt;- function(A, B, C, D, tolerance = 1e-10) {\n  # Find the roots using polyroot()\n  roots &lt;- polyroot(c(D, C, B, A))\n  \n  # Extract real parts of the roots\n  real_parts &lt;- Re(roots)\n  \n  # Filter out complex roots (where the imaginary part is close to zero)\n  real_roots &lt;- real_parts[abs(Im(roots)) &lt; tolerance]\n  \n  return(real_roots)\n}\n\ncalculate_intervals_for_measure &lt;- function(A, B, C, D, lower_bound, upper_bound) {\n  # Find the real roots \n  roots &lt;- find_real_roots_of_cubic(A, B, C, D)\n  roots &lt;- sort(roots)\n  \n  # The first interval should start on the lower bound if the function is decreasing \n  intervals &lt;- data.frame(a = double(), b = double())\n  current_left &lt;- lower_bound\n  \n  # Then, build every pair of (f' &gt; 0, f' &lt; 0).\n  for (i in (1:length(roots))) {\n    # Stop if you have gone beyond the boundary.\n    if (roots[i] &gt; upper_bound) {\n      break;\n    }\n    \n    if (!is.na(current_left)) {\n      possible_right &lt;- roots[i]\n      if (dfdx(possible_right) &lt; 0) {\n        if (current_left &lt; possible_right) {\n          # Add an interval.\n          intervals[nrow(intervals) + 1,] &lt;- c(current_left, possible_right)\n          current_left &lt;- NA\n        } else {\n          # This is closing an interval to the left of the lower bound. Skip.\n        }\n      } else {\n        # Another increasing left would be the start of an interval to the left of the lower bound\n        # or to the right of the lower bound. So, just keep the maximum.\n        # It could also be a missed root in between, but we will disregard this option.\n        current_left &lt;- max(current_left, possible_right)\n      }\n    } else {\n      possible_left &lt;- roots[i]\n      if (dfdx(possible_left) &gt; 0) {\n        if (possible_left &lt; upper_bound) {\n          # The opening of a new interval. As long as it's not beyond the upper bound, use it.\n          current_left &lt;- possible_left\n        }\n      } else {\n        # A decreasing function, without a left boundary, can be discarded\n      }\n    }\n  }\n    \n  # If there's an open interval after processing, close it at the upper bound.\n  if (!is.na(current_left)) {\n    intervals[nrow(intervals) + 1,] &lt;- c(current_left, upper_bound)\n  }\n  \n  return(intervals)\n}\n\n# Create a data frame for ggplot\nrectangles &lt;- data.frame(\n  xmin = double(),\n  xmax = double(),\n  ymin = double(),\n  ymax = double())\n\n# Calculate all rectangles\nfor(y in y_values) {\n  intervals &lt;- calculate_intervals_for_measure(A, B, C, D - y, left, right)\n  for (i in (1:nrow(intervals))) {\n    interval &lt;- intervals[i,]\n    rectangles[nrow(rectangles) + 1,] &lt;- c(interval[1], interval[2], max(0, y - delta_y), y)\n  }\n}\n\n# Create a ggplot with rectangles\np &lt;- ggplot() +\n    geom_rect(data = rectangles,\n          aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n          fill = \"skyblue\",\n          colour = \"darkgrey\",\n          alpha = 0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Ejemplo de Integración de Lebesgue\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\n\n\n\nComo último ejemplo de una medida, la medida gaussiana n-dimensional, con media 0 y desviación estándar 1, se define como:\n\\[\n\\gamma^{n} (A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x)\n\\]\nNuevamente, para cada valor posible de \\(x \\in A\\), medimos todos los conjuntos de preimágenes que resulten de esos valores y sumamos todos los resultados de esas medidas. Esta función en particular es bastante buena porque cuando \\(x\\rightarrow\\pm \\infty\\) la medida sigue siendo un número. También se llama medida de probabilidad porque \\(\\gamma^n(\\Omega)=1\\), es decir, el área bajo la curva para todo el dominio es 1 (o 100%). Si hiciste algo de probabilidad, la función \\(\\mathbb{P}\\) fue siempre una medida de probabilidad, solo que nunca te lo dijeron.\nEsto es mucho para digerir, ya sé. Leelo hasta que tenga sentido. ¡Después de todo, a mí me tomó 3 años de meditación en soledad sobre el tema!"
  },
  {
    "objectID": "measuretheory.html#un-pantallazo-sobre-teoría-de-la-medida",
    "href": "measuretheory.html#un-pantallazo-sobre-teoría-de-la-medida",
    "title": "Teoría de la Medida",
    "section": "",
    "text": "Tal vez te hayas acostumbrado a llamar “integración” a algo como \\(\\int_{a}^{b}fdx\\) , pero en realidad esa es solamente la integración de Riemann. Bueno, “solamente” motoriza el 99 % de todas las integraciones en la vida real, pero hay otras integrales especializadas que pueden manejar situaciones especiales como discontinuidades o huecos en \\(f\\), como la integral de Riemann-Stieltjes, la integral de Henstock-Kurzweil y la integral de Lebesgue. La última es en la que nos concentraremos más.\nVamos a empezar con un problema que aparentemente no tiene nada que ver: el tamaño de un conjunto. Digamos que tenemos un conjunto de números naturales \\(\\mathbb{N}\\) y queremos saber qué tan grande es. Podemos, por ejemplo, simplemente contar cuántos elementos hay en el conjunto:\n\\[\n\\begin{aligned}\n&\\#\\{\\pi,e,25\\} = 3\\\\\n&\\#\\{\\} = 0 \\\\\n&\\#\\{1,2,3,..\\} = \\infty\n\\end{aligned}\n\\]\nEn cierto modo, \\(\\#\\) es una función que recibe un conjunto como entrada una combinación de elementos de \\(\\mathbb{N}\\) y produce un valor numérico. En la literatura, los elementos pertenecen a un conjunto \\(\\Omega\\) y las combinaciones de esos elementos pertenecen a un conjunto de conjuntos \\(\\Sigma\\) , también llamado sigma álgebra. Más formalmente, \\(\\# : \\Sigma \\to \\mathbb{N}\\).\n\\(\\#\\) es lo que se conoce como una medida. Para definir medidas se usa normalmente \\(\\mu\\) y cumplen, grosso modo, dos condiciones:\n\n\\(\\mu(s) \\ge 0 ,\\, \\forall s \\in \\Sigma\\), es decir, siempre son positivas. Esta condición, de todos modos, se puede relajar para obtener “medidas con signo”.\nIf \\(A_1 \\cap A_2 = \\{\\} \\implies {\\mu (A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)}\\). Esto significa que el “tamaño” de un conjunto es el mismo que la suma de los tamaños de sus subconjuntos.\n\nHay muchas medidas, y cada una presenta diferentes propiedades. Las medidas se definen sobre un “conjunto medible”, es decir, sobre el par \\((\\Omega,\\Sigma)\\). Ya conocés la medida de conteo. La medida de Borel, que utilizaremos indistintamente con la medida de Lebesgue1, se puede definir como:\n\\[\n\\lambda((a,b])=b-a\n\\]\nSi el conjunto es una composición de intervalos, se puede descomponer en tantas sumas como hagan falta, por lo que:\n\\[\n\\lambda([0,2]\\cup(12,20))=\\lambda([0,2])+\\lambda((12,20))=(2-0)+(20-12)=10\n\\]\nTambién se puede extender en forma razonable a casos multidimensionales:\n\\[\n\\lambda^2((0,\\pi]\\times(2,4])=\\lambda((0,\\pi])*\\lambda((2,4])=(\\pi-0)*(4-2)=\\pi*2=2\\pi\n\\]"
  },
  {
    "objectID": "measuretheory.html#conexión-entre-medidas-e-integrales",
    "href": "measuretheory.html#conexión-entre-medidas-e-integrales",
    "title": "Teoría de la Medida",
    "section": "",
    "text": "Hagamos ahora algo intrépido: ¿Viste que las integrales definidas trabajan sobre un intervalo (es decir, un conjunto) y el resultado de integrar es un número? Sí, una integral es una medida (con signo)2. Esto va a requerir replantearse qué significa realmente integrar, así como cambiar nuestra notación para la integral.\nEn el mundo que todos conocemos, integramos en el sentido de Riemann, \\(\\int_{a}^{b}fdx\\). Esto significa:\n\n\\(I=\\left[a,b\\right]\\) selecciona la porción a integrar del dominio de la función, \\(\\Omega\\). Usando el lenguaje que establecimos anteriormente, \\(I\\subset \\Omega,\\, I\\in \\Sigma\\)\nDividimos \\(I\\) en particiones, generalmente usando un tamaño de partición único \\(\\Delta x\\), y obtenemos una lista de valores \\(\\left\\{x_0=a, x_1, …, x_n=b\\right\\} \\in I\\)\nPara cada partición \\(x_i\\), la evaluamos haciendo \\(f(x_i)\\) y obtenemos una lista de valores \\(f_0, f_1, ..., f_n\\)\nCalculamos una aproximación de la integral haciendo que cada uno de estos valores sea un rectángulo de altura \\(f_i\\) y ancho predefinido \\(\\Delta x\\), y sumando todos los rectángulos.\nLa integral, si existe, es el límite de esta suma cuando la norma de la partición tiende a cero.\n\nAsí es como se ve:\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(broom)\n\nf &lt;- function(x) x^3 - 3*x^2 + x +4\n\n# Define the interval [a, b] for integration\na &lt;- 0\nb &lt;- 3\n\n# Number of rectangles for approximation\nn &lt;- 24\n\n# Generate x values and corresponding function values\nx_values &lt;- seq(a, b, length.out = n+1)\ny_values &lt;- f(x_values)\n\n# Create a data frame for ggplot\ndf &lt;- data.frame(x = x_values, y = y_values)\n\n# Calculate rectangle heights\ndf$rect_heights &lt;- c(0,f(x_values)[2:length(x_values)])\n\n# Calculate total width of the bars to fill the x-axis\ntotal_width &lt;- b - a\n\n# Create a ggplot with rectangles\np &lt;- ggplot(df, aes(x = x, y = rect_heights)) +\n    geom_col(width=(total_width/n), fill = \"skyblue\", color = \"black\", just = 1, alpha=0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Ejemplo de Integración de Riemann\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\nA pesar de ser tan poderosa, existen limitaciones. Para empezar, solamente podemos integrar intervalos sobre un dominio real, \\(\\Omega =\\mathbb{R}\\) . Para funciones de muchas variables también necesitamos integrar sobre muchos dominios reales, por ejemplo \\(\\int_{x_a}^{x_b}\\int_{y_a}^{y_b}\\int_{z_a}^{z_b}f(x,y,z)\\,dz\\,dy\\,dx\\) .\nAquí podemos darnos cuenta de que podríamos deshacernos de estas restricciones si integrásemos sobre la única línea real que tiene existencia garantizada: la del codominio o imagen. Algo así como una pila de platos, para cada altura medimos el dominio que cae debajo de ella. Esto se llama integración de Lebesgue, se escribe como \\(\\int_{s} f\\, d\\lambda\\) , y significa:\n\n\\(s\\) selecciona una porción del dominio de la función, \\(\\Omega\\) , para integrar. Con el lenguaje que hemos utilizado anteriormente, \\(s\\subset \\Omega,\\, s\\in \\Sigma\\)\nDividimos la imagen de la función \\(f^{-1}\\) en particiones y obtenemos las imágenes \\(f_0,f_1,…,\\infty\\)\nPara cada una de estas particiones, obtenemos el conjunto de valores del dominio que tienen un valor de función al menos a esa altura: \\(f^{-1}_t = \\{\\omega \\in s\\, / \\, f(\\omega) &gt; t\\}\\in\\Sigma\\). Hay que tener en cuenta que estos conjuntos deben ser medibles (parte de la sigma álgebra) y que \\(f_{\\infty} = \\{\\}\\), es decir que la integral esté acotada.\nCalculamos una aproximación de la integral haciendo de cada uno de estos conjuntos un grupo de “volúmenes” de altura predefinida \\(f_t\\) y base \\(\\mu(f^{-1}_t)\\), y sumando sobre todos los rectángulos.\nAl sumar todos los conjuntos medidos, todas las porciones de alturas, obtenemos un valor final, es decir que verdaderamente la integral se comporta como una medida.\nLa integral, si existe, es el supremo de todas las sumas que se pueden obtener al dividir la imagen en particiones cada vez más pequeñas.\n\nAsí es como se ve este embrollo de acabamos de describir:\n\n\nCódigo\nA &lt;- 1\nB &lt;- -3\nC &lt;- 1\nD &lt;- 4\nf &lt;- function(x) A*x^3 + B*x^2 + C*x + D\ndfdx &lt;- function(x) A*3*x^2 + B*2*x + C\n\n# Define the domain [left, right] for integration\nleft &lt;- 0\nright &lt;- 3\n\n# Number of image partitions\nmax_y &lt;- 7\nn &lt;- 28\ndelta_y &lt;- max_y / n\n\n# Generate x values and corresponding function values\ny_values &lt;- seq(0, max_y, length.out = n + 1)\n\n\nfind_real_roots_of_cubic &lt;- function(A, B, C, D, tolerance = 1e-10) {\n  # Find the roots using polyroot()\n  roots &lt;- polyroot(c(D, C, B, A))\n  \n  # Extract real parts of the roots\n  real_parts &lt;- Re(roots)\n  \n  # Filter out complex roots (where the imaginary part is close to zero)\n  real_roots &lt;- real_parts[abs(Im(roots)) &lt; tolerance]\n  \n  return(real_roots)\n}\n\ncalculate_intervals_for_measure &lt;- function(A, B, C, D, lower_bound, upper_bound) {\n  # Find the real roots \n  roots &lt;- find_real_roots_of_cubic(A, B, C, D)\n  roots &lt;- sort(roots)\n  \n  # The first interval should start on the lower bound if the function is decreasing \n  intervals &lt;- data.frame(a = double(), b = double())\n  current_left &lt;- lower_bound\n  \n  # Then, build every pair of (f' &gt; 0, f' &lt; 0).\n  for (i in (1:length(roots))) {\n    # Stop if you have gone beyond the boundary.\n    if (roots[i] &gt; upper_bound) {\n      break;\n    }\n    \n    if (!is.na(current_left)) {\n      possible_right &lt;- roots[i]\n      if (dfdx(possible_right) &lt; 0) {\n        if (current_left &lt; possible_right) {\n          # Add an interval.\n          intervals[nrow(intervals) + 1,] &lt;- c(current_left, possible_right)\n          current_left &lt;- NA\n        } else {\n          # This is closing an interval to the left of the lower bound. Skip.\n        }\n      } else {\n        # Another increasing left would be the start of an interval to the left of the lower bound\n        # or to the right of the lower bound. So, just keep the maximum.\n        # It could also be a missed root in between, but we will disregard this option.\n        current_left &lt;- max(current_left, possible_right)\n      }\n    } else {\n      possible_left &lt;- roots[i]\n      if (dfdx(possible_left) &gt; 0) {\n        if (possible_left &lt; upper_bound) {\n          # The opening of a new interval. As long as it's not beyond the upper bound, use it.\n          current_left &lt;- possible_left\n        }\n      } else {\n        # A decreasing function, without a left boundary, can be discarded\n      }\n    }\n  }\n    \n  # If there's an open interval after processing, close it at the upper bound.\n  if (!is.na(current_left)) {\n    intervals[nrow(intervals) + 1,] &lt;- c(current_left, upper_bound)\n  }\n  \n  return(intervals)\n}\n\n# Create a data frame for ggplot\nrectangles &lt;- data.frame(\n  xmin = double(),\n  xmax = double(),\n  ymin = double(),\n  ymax = double())\n\n# Calculate all rectangles\nfor(y in y_values) {\n  intervals &lt;- calculate_intervals_for_measure(A, B, C, D - y, left, right)\n  for (i in (1:nrow(intervals))) {\n    interval &lt;- intervals[i,]\n    rectangles[nrow(rectangles) + 1,] &lt;- c(interval[1], interval[2], max(0, y - delta_y), y)\n  }\n}\n\n# Create a ggplot with rectangles\np &lt;- ggplot() +\n    geom_rect(data = rectangles,\n          aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n          fill = \"skyblue\",\n          colour = \"darkgrey\",\n          alpha = 0.5) +\n    geom_function(fun = f, color = \"red\", linewidth = 1.25) +\n    labs(title = \"Ejemplo de Integración de Lebesgue\",\n         x = \"x\", y = \"f(x)\")\n\n# Print the plot\nprint(p)"
  },
  {
    "objectID": "measuretheory.html#medidas-gaussianas",
    "href": "measuretheory.html#medidas-gaussianas",
    "title": "Teoría de la Medida",
    "section": "",
    "text": "Como último ejemplo de una medida, la medida gaussiana n-dimensional, con media 0 y desviación estándar 1, se define como:\n\\[\n\\gamma^{n} (A) = \\frac{1}{({2 \\pi})^{n/2}} \\int_{A} \\exp \\left( - \\frac{1}{2} \\| x \\|_{\\mathbb{R}^{n}}^{2} \\right) \\, \\mathrm{d} \\lambda^{n} (x)\n\\]\nNuevamente, para cada valor posible de \\(x \\in A\\), medimos todos los conjuntos de preimágenes que resulten de esos valores y sumamos todos los resultados de esas medidas. Esta función en particular es bastante buena porque cuando \\(x\\rightarrow\\pm \\infty\\) la medida sigue siendo un número. También se llama medida de probabilidad porque \\(\\gamma^n(\\Omega)=1\\), es decir, el área bajo la curva para todo el dominio es 1 (o 100%). Si hiciste algo de probabilidad, la función \\(\\mathbb{P}\\) fue siempre una medida de probabilidad, solo que nunca te lo dijeron.\nEsto es mucho para digerir, ya sé. Leelo hasta que tenga sentido. ¡Después de todo, a mí me tomó 3 años de meditación en soledad sobre el tema!"
  },
  {
    "objectID": "measuretheory.html#footnotes",
    "href": "measuretheory.html#footnotes",
    "title": "Teoría de la Medida",
    "section": "",
    "text": "La medida exterior de Lebesgue tiene una definición más compleja que evita algunos resultados patológicos que tiene la medida de Borel en ciertos conjuntos medibles. Para conjuntos “razonables”, donde la medida de Borel está bien definida, esta coincide con la medida de Lebesgue.↩︎\nEl recíproco, que cualquier medida (con signo) es siempre una integral, también es cierto bajo ciertas condiciones. Esta es la consecuencia del teorema de Radon-Nikodym.↩︎"
  },
  {
    "objectID": "question.html",
    "href": "question.html",
    "title": "La pregunta",
    "section": "",
    "text": "Como dije antes, el Cálculo Malliavin no se relaciona fácilmente con cosas cotidianas. La mayoría de los autores que consulté no detallan demasiado por qué un objeto como este existe, o por qué existe la fórmula de Clark-Ocone. En cambio, les interesa profundizar sobre la condición de Hormander (?).\nDijimos antes que el Cálculo Malliavin es la extensión del cálculo de variaciones a los procesos estocásticos. Ha llegado el momento de explorar el tópico de procesos estocásticos y martingalas.\n\n\nPodemos pensar los procesos estocásticos como una sucesión de variables aleatorias indexadas por tiempo. Comenzaré con un caso muy simple, el paseo aleatorio unidimensional (también conocido como la caminata de borracho):\n\\[\n\\begin{aligned}\n\\mathbb{P}(\\{&X_i=+1\\})=0.5 \\\\\n\\mathbb{P}(\\{&X_i=-1\\})=0.5 \\\\\n&X_0=0 \\\\\n&Z_n=\\sum^{n}_{i=1}X_i \\\\\n\\end{aligned}\n\\]\nEsto es muy simple: en el momento \\(i\\), después de que haya transcurrido un tiempo \\(\\Delta t\\), el borracho da un paso \\(X_i\\), que puede ser hacia arriba o hacia abajo en la calle con la misma probabilidad. La posición \\(Z\\) en \\(t\\) es simplemente la ubicación final, luego de todos los pasos que el borracho dio. Con esta forma de plantear el problema, cada movimiento “hacia arriba” puede considerarse un “éxito”, por lo que esta suma sigue una distribución binomial centrada en \\(0\\).\nPensemos otro caso: dejemos que el recorrido aleatorio dé pasos más frecuentes y más cortos. Usando los símbolos de arriba, \\(\\Delta t\\) y \\(X_i\\) se hacen más pequeños. A medida que los pasos se vuelven infinitesimales, el proceso se vuelve continuo. Así es como se vería una caminata cuando \\(\\Delta t=0.1,\\,0.01,\\,0.001\\):\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Left\nh &lt;- 0.01\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nCódigo\n# Middle\nh &lt;- 0.001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nCódigo\n# Right\nh &lt;- 0.0001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nUna caminata aleatoria unidimensional de \\(0\\) a \\(t\\), de manera similar al Teorema del Límite Central, converge a una variable normal:\n\\[\nZ_t\\sim \\mathcal{N}(\\mu=0,\\sigma^2=t)\n\\]\nEstos procesos estocásticos de tiempo continuo se denominan movimientos brownianos o procesos de Wiener. Se denotan como \\(B_t\\) o \\(W_t\\) y cumplen un conjunto de condiciones:\n\n\\(B_0 = 0\\)\nLos incrementos son independientes, es decir, \\((B_{t+s} - B_t)\\) no depende de valores anteriores \\(B_r, \\, r &lt; t\\)\nLos incrementos siguen una distribución normal, es decir, \\((B_{t+s} - B_t) \\sim \\mathcal{N}(\\mu=0,\\sigma^2=s)\\)\n\\(B_t\\) es continua en \\(t\\). Un poco circular, ya sé.\n\nSin embargo, hay un problema. Aunque son continuas, estas funciones no son diferenciables. Se puede ver en los gráficos de trayectorias de más arriba, con lo irregulares que se vuelven a medida que los índices (o pasos) se achican. También tiene sentido si pensás en la forma en que construimos el proceso: cuando estás en un punto en el tiempo \\(t\\), no sabés de dónde viniste aleatoriamente. ¿Llegaste desde un valor más alto o más bajo en \\(t-\\Delta t\\)? No tiene sentido hablar de \\(\\frac{\\partial Z_t}{\\partial t}\\).\n\n\nLa caminata de borracho es un caso muy simple de un proceso estocástico. ¿Qué pasa con variables aleatorias más interesantes, o con funciones variables aleatorias?\nEmpezamos con una sustitución sencilla: no podemos hacer \\(\\frac{\\partial Z_t}{\\partial t}\\) pero “podemos” pasar el \\(dt\\) multiplicando, como hacemos con las derivadas totales, y referirnos solo a \\(dZ_t\\). En general, nos gustaría expresar un cambio minúsculo en la variable aleatoria como una suma entre un cambio asociado al tiempo y un cambio asociado a un “ruido”. En resumen, algo como esto:\n\\[\ndZ_t = a(.)dt + b(.)dB_t\n\\]\nPara empezar, supondremos que las funciones \\(a\\) y \\(b\\) solamente dependen del tiempo. Entonces, integramos a lo largo del tiempo y llegamos a la definición de un proceso de Ito:\n\\[\n\\begin{aligned}\n\\int_0^tdZ_t &= Z_t - Z_0 = \\int_0^t\\mu_sds + \\int_0^t\\sigma_sdB_s \\\\\n\\end{aligned}\n\\]\nEsta representación es buena porque muestra directamente que la variable aleatoria \\(Z_t\\) tiene una media o tendencia ligada al tiempo, y una varianza o dispersión ligada al ruido. Dicho esto, necesitamos poder trabajar más fácilmente con \\(dB_t\\). Para ello, vamos a suponer algo simple: que en lugar de un continuo de \\(dB_t\\), hay una lista de \\(t_i\\), con incrementos \\(\\Delta B_{t_i}\\). La expresión de arriba nos queda ahora:\n\\[\n\\sigma_{t_{i}} * (B_{t_i}-B_{t_{i-1}})\n\\]\nPodemos calcular esta expresión porque una diferencia de movimientos brownianos se puede reemplazar con una distribución normal que podemos manipular. Para demostrar cómo esto nos ayuda, podemos hacer el siguiente cálculo y confirmar que el valor esperado de \\(Z\\) sólo depende del primer término:\n\\[\n\\mathbb{E}\\left[ \\int_0^t \\sigma_s \\, dB_s\\right]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[B_{t_{i}}-B_{t_{i-1}}\\right ]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[\\mathcal{N}(0,t_{i}-t_{i-1})\\right ]=\n0\n\\]\nUsando este enfoque, podemos demostrar que los procesos de Ito satisfacen:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[X_t \\right]&=\\int_0^t\\mu_s\\,ds\\\\\n\\mathbb{Var}\\left[X_t \\right]&=\\int_0^t\\sigma_s^2\\,ds\\\\\n\\end{aligned}\n\\]\nOtra forma de manipular estos \\(B_t\\) es con la isometría de Ito, que permite intercambiar el \\(dB_t\\) por un \\(dt\\) más amigable de integrar:\n\\[\n\\mathbb{E}\\left[ \\left(\\int_0^t X_s \\, dB_s\\right)^2\\right]=\\mathbb{E} \\left[ \\int_0^t X_s^2\\,ds\\right ]\n\\]\nCon estas herramientas, ya podemos calcular una media y una varianza para cada punto en el tiempo de un proceso. Pero hay una herramienta aún más poderosa en nuestro arsenal: el lema de Ito o fórmula de Ito. Comenzamos su presentación con un proceso de Ito para una variable aleatoria, digamos \\(X_t\\):\n\\[\n\\begin{aligned}\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_t \\\\\nX_t &= X_0 + \\int_0^t\\mu_s\\,ds + \\int_0^t\\sigma_s\\,dB_s \\\\\n\\end{aligned}\n\\]\nAhora, queremos plantear algo más complejo. Algo como:\n\\[\n\\begin{aligned}\nY_t&=f(t,X_t) \\\\\\\\\ndY_t &= a(t,X_t)\\,dt + b(t,X_t)\\,dB_t \\\\\\\\\nwith&\\\\\\\\\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_s \\\\\n\\end{aligned}\n\\]\nNuestro proceso ya no depende solo del tiempo, sino de una variable aleatoria que sigue un proceso de Ito. De nuevo, no podemos simplemente hacer la regla de la cadena típica del cálculo. Es decir, todavía no podemos hacer algo como:\n\\[\n\\frac{\\partial Y_t}{\\partial t}=\\frac{\\partial Y_t}{\\partial X_t}\\frac{\\partial X_t}{\\partial t}\n\\]\nPero se puede demostrar que existe una regla de la cadena alternativa que podemos aplicar: el lema de Ito:\n\\[\n\\begin{aligned}\ndf(t,X_t) &=\\frac{\\partial f}{\\partial t}\\,dt + \\mu_t \\frac{\\partial f}{\\partial x}\\,dt+\\sigma_t \\frac{\\partial f}{\\partial x}\\,dB_t + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\,dt\\\\\ndf(t,X_t) &=\\underbrace{\\left(\\frac{\\partial f}{\\partial t} + \\mu_t \\frac{\\partial f}{\\partial x} + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\right)}_{a(t,X_t)}dt+ \\underbrace{\\left(\\sigma_t \\frac{\\partial f}{\\partial x}\\right)}_{b(t,X_t)}dB_t\\\\\n\\end{aligned}\n\\]\nLa primera ecuación casi parece una expansión en serie de Taylor hasta la 2ª derivada, y de hecho es lo que sucede en demostraciones informales. La segunda ecuación muestra las expresiones explícitas para las funciones \\(a(t,X_t)\\) y \\(b(t,X_t)\\) que mencionamos antes. Esto es genial porque todavía podemos separar el componente de “tendencia” y el componente de “ruido” para procesos aleatorios más complicados. Esto también significa que la “tendencia” se ve afectada por la intensidad del “ruido”. Por último, se puede verificar que una función no aleatoria con \\(\\sigma_t=0\\) se convierte en una derivada total clásica, con la regla de la cadena que ya conocemos.\n\n\n\nAlgunos procesos estocásticos presentan propiedades adicionales. Uno de ellos son las martingalas. Las martingalas son procesos de tiempo discretos o continuo que satisfacen:\n\n\\(\\mathbb{E}[|X_t|]&lt;\\infty, \\forall t \\ge 0\\) . Esto significa que el proceso siempre tiene un valor finito.\n\\(\\mathbb{E}[X_{t+s}|X_t]=X_t, \\forall t \\le s\\). Esto significa que la esperanza matemática para futuras realizaciones del proceso es el valor que tenga en el momento presente.\n\nLa caminata de borracho es un ejemplo de martingala: en cualquier momento, es igualmente probable que suba o baje por la calle, por lo que la esperanza es dondequiera que esté en ese momento. Los movimientos brownianos también son martingalas: los incrementos siguen una distribución normal, por lo que la esperanza del incremento es \\(0\\). Otros ejemplos de martingalas típicas son apostar al negro o al rojo en la ruleta, o el precio de una acción en el corto plazo.\nExiste un lema llamado el Teorema de Representación en Martingala, que establece que cualquier variable aleatoria \\(X\\) puede escribirse en términos de otro proceso \\(C\\), con valores conocidos de antemano, de la siguiente manera:\n\\[\nX = \\mathbb{E}\\left[X\\right] + \\int_0^\\infty C_s\\,dB_s\n\\]\nEsto es valioso para la gente de finanzas porque significa que cualquier estrategia de inversión (que es un proceso aleatorio) puede replicarse con una estrategia de inversión diferente (otro proceso), pero con menor volatilidad (con un costo inicial más alto). Este teorema es menos valioso porque no proporciona ninguna forma de calcularla: no podemos aplicar una derivada y hacer cambios de variable para extraer ese \\(dB_t\\)\nUna segunda forma de expresar martingalas, de Rogers y Williams (2000), es como integrales de Ito:\n\\[\nM_t = M_0 + \\int_0^t \\alpha_s\\,dB_s\n\\]\nEn un sentido acotado, \\(\\alpha_t\\) puede considerarse como una especie de \\(\\frac{\\partial M_t}{\\partial t}\\) porque si integramos hasta \\(t\\) recuperamos el punto final, pero no es exactamente lo que estamos buscando.\nTodo esto es frustrante. Estamos tratando de encontrar una forma de calcular derivadas en estos procesos aleatorios, movimientos brownianos y martingalas todo el tiempo, pero la respuesta nos esquiva. Y el caso es que sabemos que es posible. De hecho, volvamos a nuestro primer proceso estocástico continuo, el proceso de Wiener unidimensional o caminata de borracho. Habíamos llegado al punto en el que podíamos decir que \\(W_t\\) tenía una distribución normal. Entonces, nada nos impide tomar una derivada sobre eso, ¿verdad?\n\\[\n\\begin{aligned}\nW_t& \\sim \\mathcal{N}(0,t) \\\\\nW(x, t)& = \\frac{1}{\\sqrt{2 \\pi t}} e^{-x^2/(2t)} \\\\\n\\frac{\\partial W}{\\partial t}& = \\frac{e^{-x^2/(2t)}\\,t^{-5/2} \\left(x^2-t\\right)}{2\\sqrt{2 \\pi }}\n\\end{aligned}\n\\]\nY ahí la tenemos. No sabemos si es útil, y la expresión se ve fea, pero podemos tener una derivada de la densidad de una variable aleatoria con respecto al tiempo. Dibujemos tanto la densidad como la derivada en 3D.\n\n\nCódigo\noptions(rgl.useNULL=TRUE)\nrgl::setupKnitr(autoprint = TRUE)\nh = 200\nWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)/sqrt(2*pi*t))\n  }\n}\ndWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)*t^(-5/2)*(x^2-t)/sqrt(8*pi))\n  }\n}\nWt &lt;- Vectorize(Wt)\ndWt &lt;- Vectorize(dWt)\n\ntimes &lt;- seq(from=0, to=5, length.out=h)\nxes &lt;- seq(from=-5, to=5, length.out=h)\n\nW &lt;- outer(xes, times, Wt)\n# persp(xes, times, W, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\n# open3d(windowRect=c(50,50,800,800))\npalette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\")) \ncol.table &lt;- palette(256)\ncol.ind &lt;- cut(W, 256)\npersp3d(x=xes, y=times, z=W, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Tiempo\", zlab=\"Densidad\")\n\n\n\n\n\n\n\nCódigo\n# rglwidget()\n\ndW &lt;- outer(xes, times, dWt)\n# persp(xes, times, dW, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\ncol.ind &lt;- cut(dW, 256)\npersp3d(x=xes, y=times, z=dW, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Tiempo\", zlab=\"Derivada de la Densidad\")\n\n\n\n\n\n\nCódigo\n# rglwidget()\n\n\n\n\n\n\nA estas alturas, ya hemos visto suficiente. Sabemos lo que queremos: una forma de calcular derivadas sobre variables aleatorias y procesos de Wiener que, además, sirva para algo. Eso es lo que el Cálculo de Malliavin pretende.\n\n\n\n\n\nRogers, L. C. G., y David Williams. 2000. Diffusions, Markov Processes and Martingales. 2.ª ed. Vol. 2. Cambridge Mathematical Library. Cambridge University Press. https://doi.org/10.1017/CBO9780511805141."
  },
  {
    "objectID": "question.html#procesos-estocásticos",
    "href": "question.html#procesos-estocásticos",
    "title": "La pregunta",
    "section": "",
    "text": "Podemos pensar los procesos estocásticos como una sucesión de variables aleatorias indexadas por tiempo. Comenzaré con un caso muy simple, el paseo aleatorio unidimensional (también conocido como la caminata de borracho):\n\\[\n\\begin{aligned}\n\\mathbb{P}(\\{&X_i=+1\\})=0.5 \\\\\n\\mathbb{P}(\\{&X_i=-1\\})=0.5 \\\\\n&X_0=0 \\\\\n&Z_n=\\sum^{n}_{i=1}X_i \\\\\n\\end{aligned}\n\\]\nEsto es muy simple: en el momento \\(i\\), después de que haya transcurrido un tiempo \\(\\Delta t\\), el borracho da un paso \\(X_i\\), que puede ser hacia arriba o hacia abajo en la calle con la misma probabilidad. La posición \\(Z\\) en \\(t\\) es simplemente la ubicación final, luego de todos los pasos que el borracho dio. Con esta forma de plantear el problema, cada movimiento “hacia arriba” puede considerarse un “éxito”, por lo que esta suma sigue una distribución binomial centrada en \\(0\\).\nPensemos otro caso: dejemos que el recorrido aleatorio dé pasos más frecuentes y más cortos. Usando los símbolos de arriba, \\(\\Delta t\\) y \\(X_i\\) se hacen más pequeños. A medida que los pasos se vuelven infinitesimales, el proceso se vuelve continuo. Así es como se vería una caminata cuando \\(\\Delta t=0.1,\\,0.01,\\,0.001\\):\n\n\nCódigo\nlibrary(ggplot2)\nlibrary(rgl)\n\n# Left\nh &lt;- 0.01\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nCódigo\n# Middle\nh &lt;- 0.001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nCódigo\n# Right\nh &lt;- 0.0001\nsteps = 1 / h\nxl &lt;- seq(from = 0, to = 1, length.out=steps)\nyl &lt;- (rbinom(steps-1,1,0.5)*2-1)*sqrt(h)/2\nzl &lt;- c(0,cumsum(yl))\nggplot(mapping = aes(x = xl), legend=TRUE) +\n  geom_line(mapping = aes(y=zl, fill=\"f(X)\")) +\n  xlab('Tiempo') +\n  ylab('Z')\n\n\n\n\n\nUna caminata aleatoria unidimensional de \\(0\\) a \\(t\\), de manera similar al Teorema del Límite Central, converge a una variable normal:\n\\[\nZ_t\\sim \\mathcal{N}(\\mu=0,\\sigma^2=t)\n\\]\nEstos procesos estocásticos de tiempo continuo se denominan movimientos brownianos o procesos de Wiener. Se denotan como \\(B_t\\) o \\(W_t\\) y cumplen un conjunto de condiciones:\n\n\\(B_0 = 0\\)\nLos incrementos son independientes, es decir, \\((B_{t+s} - B_t)\\) no depende de valores anteriores \\(B_r, \\, r &lt; t\\)\nLos incrementos siguen una distribución normal, es decir, \\((B_{t+s} - B_t) \\sim \\mathcal{N}(\\mu=0,\\sigma^2=s)\\)\n\\(B_t\\) es continua en \\(t\\). Un poco circular, ya sé.\n\nSin embargo, hay un problema. Aunque son continuas, estas funciones no son diferenciables. Se puede ver en los gráficos de trayectorias de más arriba, con lo irregulares que se vuelven a medida que los índices (o pasos) se achican. También tiene sentido si pensás en la forma en que construimos el proceso: cuando estás en un punto en el tiempo \\(t\\), no sabés de dónde viniste aleatoriamente. ¿Llegaste desde un valor más alto o más bajo en \\(t-\\Delta t\\)? No tiene sentido hablar de \\(\\frac{\\partial Z_t}{\\partial t}\\).\n\n\nLa caminata de borracho es un caso muy simple de un proceso estocástico. ¿Qué pasa con variables aleatorias más interesantes, o con funciones variables aleatorias?\nEmpezamos con una sustitución sencilla: no podemos hacer \\(\\frac{\\partial Z_t}{\\partial t}\\) pero “podemos” pasar el \\(dt\\) multiplicando, como hacemos con las derivadas totales, y referirnos solo a \\(dZ_t\\). En general, nos gustaría expresar un cambio minúsculo en la variable aleatoria como una suma entre un cambio asociado al tiempo y un cambio asociado a un “ruido”. En resumen, algo como esto:\n\\[\ndZ_t = a(.)dt + b(.)dB_t\n\\]\nPara empezar, supondremos que las funciones \\(a\\) y \\(b\\) solamente dependen del tiempo. Entonces, integramos a lo largo del tiempo y llegamos a la definición de un proceso de Ito:\n\\[\n\\begin{aligned}\n\\int_0^tdZ_t &= Z_t - Z_0 = \\int_0^t\\mu_sds + \\int_0^t\\sigma_sdB_s \\\\\n\\end{aligned}\n\\]\nEsta representación es buena porque muestra directamente que la variable aleatoria \\(Z_t\\) tiene una media o tendencia ligada al tiempo, y una varianza o dispersión ligada al ruido. Dicho esto, necesitamos poder trabajar más fácilmente con \\(dB_t\\). Para ello, vamos a suponer algo simple: que en lugar de un continuo de \\(dB_t\\), hay una lista de \\(t_i\\), con incrementos \\(\\Delta B_{t_i}\\). La expresión de arriba nos queda ahora:\n\\[\n\\sigma_{t_{i}} * (B_{t_i}-B_{t_{i-1}})\n\\]\nPodemos calcular esta expresión porque una diferencia de movimientos brownianos se puede reemplazar con una distribución normal que podemos manipular. Para demostrar cómo esto nos ayuda, podemos hacer el siguiente cálculo y confirmar que el valor esperado de \\(Z\\) sólo depende del primer término:\n\\[\n\\mathbb{E}\\left[ \\int_0^t \\sigma_s \\, dB_s\\right]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[B_{t_{i}}-B_{t_{i-1}}\\right ]=\n\\sum_{i=1}^n \\sigma_{t_{i}}\\mathbb{E} \\left[\\mathcal{N}(0,t_{i}-t_{i-1})\\right ]=\n0\n\\]\nUsando este enfoque, podemos demostrar que los procesos de Ito satisfacen:\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[X_t \\right]&=\\int_0^t\\mu_s\\,ds\\\\\n\\mathbb{Var}\\left[X_t \\right]&=\\int_0^t\\sigma_s^2\\,ds\\\\\n\\end{aligned}\n\\]\nOtra forma de manipular estos \\(B_t\\) es con la isometría de Ito, que permite intercambiar el \\(dB_t\\) por un \\(dt\\) más amigable de integrar:\n\\[\n\\mathbb{E}\\left[ \\left(\\int_0^t X_s \\, dB_s\\right)^2\\right]=\\mathbb{E} \\left[ \\int_0^t X_s^2\\,ds\\right ]\n\\]\nCon estas herramientas, ya podemos calcular una media y una varianza para cada punto en el tiempo de un proceso. Pero hay una herramienta aún más poderosa en nuestro arsenal: el lema de Ito o fórmula de Ito. Comenzamos su presentación con un proceso de Ito para una variable aleatoria, digamos \\(X_t\\):\n\\[\n\\begin{aligned}\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_t \\\\\nX_t &= X_0 + \\int_0^t\\mu_s\\,ds + \\int_0^t\\sigma_s\\,dB_s \\\\\n\\end{aligned}\n\\]\nAhora, queremos plantear algo más complejo. Algo como:\n\\[\n\\begin{aligned}\nY_t&=f(t,X_t) \\\\\\\\\ndY_t &= a(t,X_t)\\,dt + b(t,X_t)\\,dB_t \\\\\\\\\nwith&\\\\\\\\\ndX_t &= \\mu_t\\,dt + \\sigma_t\\,dB_s \\\\\n\\end{aligned}\n\\]\nNuestro proceso ya no depende solo del tiempo, sino de una variable aleatoria que sigue un proceso de Ito. De nuevo, no podemos simplemente hacer la regla de la cadena típica del cálculo. Es decir, todavía no podemos hacer algo como:\n\\[\n\\frac{\\partial Y_t}{\\partial t}=\\frac{\\partial Y_t}{\\partial X_t}\\frac{\\partial X_t}{\\partial t}\n\\]\nPero se puede demostrar que existe una regla de la cadena alternativa que podemos aplicar: el lema de Ito:\n\\[\n\\begin{aligned}\ndf(t,X_t) &=\\frac{\\partial f}{\\partial t}\\,dt + \\mu_t \\frac{\\partial f}{\\partial x}\\,dt+\\sigma_t \\frac{\\partial f}{\\partial x}\\,dB_t + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\,dt\\\\\ndf(t,X_t) &=\\underbrace{\\left(\\frac{\\partial f}{\\partial t} + \\mu_t \\frac{\\partial f}{\\partial x} + \\frac{\\sigma_t^2}{2}\\frac{\\partial^2f}{\\partial x^2}\\right)}_{a(t,X_t)}dt+ \\underbrace{\\left(\\sigma_t \\frac{\\partial f}{\\partial x}\\right)}_{b(t,X_t)}dB_t\\\\\n\\end{aligned}\n\\]\nLa primera ecuación casi parece una expansión en serie de Taylor hasta la 2ª derivada, y de hecho es lo que sucede en demostraciones informales. La segunda ecuación muestra las expresiones explícitas para las funciones \\(a(t,X_t)\\) y \\(b(t,X_t)\\) que mencionamos antes. Esto es genial porque todavía podemos separar el componente de “tendencia” y el componente de “ruido” para procesos aleatorios más complicados. Esto también significa que la “tendencia” se ve afectada por la intensidad del “ruido”. Por último, se puede verificar que una función no aleatoria con \\(\\sigma_t=0\\) se convierte en una derivada total clásica, con la regla de la cadena que ya conocemos.\n\n\n\nAlgunos procesos estocásticos presentan propiedades adicionales. Uno de ellos son las martingalas. Las martingalas son procesos de tiempo discretos o continuo que satisfacen:\n\n\\(\\mathbb{E}[|X_t|]&lt;\\infty, \\forall t \\ge 0\\) . Esto significa que el proceso siempre tiene un valor finito.\n\\(\\mathbb{E}[X_{t+s}|X_t]=X_t, \\forall t \\le s\\). Esto significa que la esperanza matemática para futuras realizaciones del proceso es el valor que tenga en el momento presente.\n\nLa caminata de borracho es un ejemplo de martingala: en cualquier momento, es igualmente probable que suba o baje por la calle, por lo que la esperanza es dondequiera que esté en ese momento. Los movimientos brownianos también son martingalas: los incrementos siguen una distribución normal, por lo que la esperanza del incremento es \\(0\\). Otros ejemplos de martingalas típicas son apostar al negro o al rojo en la ruleta, o el precio de una acción en el corto plazo.\nExiste un lema llamado el Teorema de Representación en Martingala, que establece que cualquier variable aleatoria \\(X\\) puede escribirse en términos de otro proceso \\(C\\), con valores conocidos de antemano, de la siguiente manera:\n\\[\nX = \\mathbb{E}\\left[X\\right] + \\int_0^\\infty C_s\\,dB_s\n\\]\nEsto es valioso para la gente de finanzas porque significa que cualquier estrategia de inversión (que es un proceso aleatorio) puede replicarse con una estrategia de inversión diferente (otro proceso), pero con menor volatilidad (con un costo inicial más alto). Este teorema es menos valioso porque no proporciona ninguna forma de calcularla: no podemos aplicar una derivada y hacer cambios de variable para extraer ese \\(dB_t\\)\nUna segunda forma de expresar martingalas, de Rogers y Williams (2000), es como integrales de Ito:\n\\[\nM_t = M_0 + \\int_0^t \\alpha_s\\,dB_s\n\\]\nEn un sentido acotado, \\(\\alpha_t\\) puede considerarse como una especie de \\(\\frac{\\partial M_t}{\\partial t}\\) porque si integramos hasta \\(t\\) recuperamos el punto final, pero no es exactamente lo que estamos buscando.\nTodo esto es frustrante. Estamos tratando de encontrar una forma de calcular derivadas en estos procesos aleatorios, movimientos brownianos y martingalas todo el tiempo, pero la respuesta nos esquiva. Y el caso es que sabemos que es posible. De hecho, volvamos a nuestro primer proceso estocástico continuo, el proceso de Wiener unidimensional o caminata de borracho. Habíamos llegado al punto en el que podíamos decir que \\(W_t\\) tenía una distribución normal. Entonces, nada nos impide tomar una derivada sobre eso, ¿verdad?\n\\[\n\\begin{aligned}\nW_t& \\sim \\mathcal{N}(0,t) \\\\\nW(x, t)& = \\frac{1}{\\sqrt{2 \\pi t}} e^{-x^2/(2t)} \\\\\n\\frac{\\partial W}{\\partial t}& = \\frac{e^{-x^2/(2t)}\\,t^{-5/2} \\left(x^2-t\\right)}{2\\sqrt{2 \\pi }}\n\\end{aligned}\n\\]\nY ahí la tenemos. No sabemos si es útil, y la expresión se ve fea, pero podemos tener una derivada de la densidad de una variable aleatoria con respecto al tiempo. Dibujemos tanto la densidad como la derivada en 3D.\n\n\nCódigo\noptions(rgl.useNULL=TRUE)\nrgl::setupKnitr(autoprint = TRUE)\nh = 200\nWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)/sqrt(2*pi*t))\n  }\n}\ndWt &lt;- function(x, t) {\n  if (t == 0) {\n    return(0)\n  } else {\n    return(exp(-x^2/2/t)*t^(-5/2)*(x^2-t)/sqrt(8*pi))\n  }\n}\nWt &lt;- Vectorize(Wt)\ndWt &lt;- Vectorize(dWt)\n\ntimes &lt;- seq(from=0, to=5, length.out=h)\nxes &lt;- seq(from=-5, to=5, length.out=h)\n\nW &lt;- outer(xes, times, Wt)\n# persp(xes, times, W, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\n# open3d(windowRect=c(50,50,800,800))\npalette &lt;- colorRampPalette(c(\"blue\", \"green\", \"yellow\", \"red\")) \ncol.table &lt;- palette(256)\ncol.ind &lt;- cut(W, 256)\npersp3d(x=xes, y=times, z=W, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Tiempo\", zlab=\"Densidad\")\n\n\n\n\n\n\n\nCódigo\n# rglwidget()\n\ndW &lt;- outer(xes, times, dWt)\n# persp(xes, times, dW, col='white', shade=.1, theta = 150, phi = 15, ticktype='detailed', xlab = \"X\", ylab = \"T\", zlab = \"N\", d = 2, expand = 1.0, border=\"darkgrey\")\ncol.ind &lt;- cut(dW, 256)\npersp3d(x=xes, y=times, z=dW, col=col.table[col.ind],\n        xlab=\"X\", ylab=\"Tiempo\", zlab=\"Derivada de la Densidad\")\n\n\n\n\n\n\nCódigo\n# rglwidget()"
  },
  {
    "objectID": "question.html#conclusión",
    "href": "question.html#conclusión",
    "title": "La pregunta",
    "section": "",
    "text": "A estas alturas, ya hemos visto suficiente. Sabemos lo que queremos: una forma de calcular derivadas sobre variables aleatorias y procesos de Wiener que, además, sirva para algo. Eso es lo que el Cálculo de Malliavin pretende.\n\n\n\n\n\nRogers, L. C. G., y David Williams. 2000. Diffusions, Markov Processes and Martingales. 2.ª ed. Vol. 2. Cambridge Mathematical Library. Cambridge University Press. https://doi.org/10.1017/CBO9780511805141."
  }
]